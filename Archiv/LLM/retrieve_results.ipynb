{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_20176\\1548500953.py:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  batches_to_keys = batches_to_keys.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load the CSV file\n",
    "batches_to_keys = pd.read_csv(\"batches_OpenAI.csv\")\n",
    "\n",
    "# strip all whitespace from the values\n",
    "batches_to_keys = batches_to_keys.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "test = batches_to_keys[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response: Unterminated string starting at: line 6 column 9 (char 215)\n"
     ]
    }
   ],
   "source": [
    "# Iterate through each row in the CSV file\n",
    "all_reviews = pd.DataFrame(columns=[\"food_sentences\", \"service_sentences\", \"atmosphere_sentences\", \"price_sentences\"]) # Initialize an empty DataFrame to store the results\n",
    "\n",
    "for _, row in test.iterrows():\n",
    "    batch_job_id = row['batch_job_id']\n",
    "    api_key = row['api_key']\n",
    "    \n",
    "    # Create the OpenAI client\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    \n",
    "    try:\n",
    "        # Get the results file ID for the batch job (assuming this comes from an API or prior step)\n",
    "        result_file_id = client.batches.retrieve(batch_job_id).output_file_id\n",
    "        \n",
    "        # Download the results file\n",
    "        result_content = client.files.content(result_file_id).content\n",
    "        result_file_name = \"batch_results.jsonl\"\n",
    "        with open(result_file_name, 'wb') as file:\n",
    "            file.write(result_content)  # Save the content to a file\n",
    "\n",
    "        # Parse the results\n",
    "        results = []\n",
    "        with open(result_file_name, 'r') as file:\n",
    "            for line in file:\n",
    "                results.append(json.loads(line.strip()))\n",
    "        results = pd.DataFrame(results)\n",
    "\n",
    "        # Extract the sentences for each topic\n",
    "        def extract_sentences(response):\n",
    "            try:\n",
    "                # Parse the assistant's message content\n",
    "                content = json.loads(response['body']['choices'][0]['message']['content'])\n",
    "                return {\n",
    "                    \"food_sentences\": \" \".join(content.get(\"food_sentences\", [])),\n",
    "                    \"service_sentences\": \" \".join(content.get(\"service_sentences\", [])),\n",
    "                    \"atmosphere_sentences\": \" \".join(content.get(\"atmosphere_sentences\", [])),\n",
    "                    \"price_sentences\": \" \".join(content.get(\"price_sentences\", [])),\n",
    "                }\n",
    "            except Exception as e:\n",
    "                print(f\"Error parsing response: {e}\")\n",
    "                return {\n",
    "                    \"food_sentences\": None,\n",
    "                    \"service_sentences\": None,\n",
    "                    \"atmosphere_sentences\": None,\n",
    "                    \"price_sentences\": None,\n",
    "                }\n",
    "\n",
    "        # Apply the extraction to the 'response' column\n",
    "        category_data = results['response'].apply(extract_sentences)\n",
    "\n",
    "        # Create a new DataFrame with the extracted category sentences\n",
    "        category_df = pd.DataFrame(category_data.tolist())\n",
    "\n",
    "        # Combine 'custom_id' and extracted category sentences\n",
    "        category_df['custom_id'] = results['custom_id']\n",
    "        # Rename custom_id to review_id\n",
    "        category_df.rename(columns={\"custom_id\": \"review_id\"}, inplace=True)\n",
    "\n",
    "        # Append the results for this batch to the collection\n",
    "        all_reviews = pd.concat([all_reviews, category_df], ignore_index=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch_job_id {batch_job_id}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4471\n",
      "12774\n"
     ]
    }
   ],
   "source": [
    "print(min(category_df[\"review_id\"].astype(int)))\n",
    "print(max(category_df[\"review_id\"].astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final DataFrame to a CSV file\n",
    "all_reviews.to_csv(\"extracted_category_subset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Food Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "batches_to_keys = pd.read_csv(\"batches_sentiment_OpenAI.csv\")\n",
    "\n",
    "# strip all whitespace from the values\n",
    "batches_to_keys = batches_to_keys.applymap(lambda x: x.strip() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each row in the CSV file\n",
    "food_ratings = pd.DataFrame(columns=[\"food_rating\"])  # Initialize an empty DataFrame to store the results\n",
    "\n",
    "for _, row in batches_to_keys.iterrows():\n",
    "    batch_job_id = row['batch_job_id']\n",
    "    api_key = row['api_key']\n",
    "    batch_file_name = row.get('batch_file_name', '')  # Retrieve the batch_file_name column\n",
    "\n",
    "    # Process only if the batch_file_name contains the word \"food\"\n",
    "    if \"food\" not in batch_file_name.lower():\n",
    "        continue  # Skip this row if \"food\" is not in the batch_file_name\n",
    "\n",
    "    # Create the OpenAI client\n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    try:\n",
    "        # Get the results file ID for the batch job (assuming this comes from an API or prior step)\n",
    "        result_file_id = client.batches.retrieve(batch_job_id).output_file_id\n",
    "\n",
    "        # Download the results file\n",
    "        result_content = client.files.content(result_file_id).content\n",
    "        result_file_name = \"batch_results.jsonl\"\n",
    "        with open(result_file_name, 'wb') as file:\n",
    "            file.write(result_content)  # Save the content to a file\n",
    "\n",
    "        # Parse the results\n",
    "        results = []\n",
    "        with open(result_file_name, 'r') as file:\n",
    "            for line in file:\n",
    "                results.append(json.loads(line.strip()))\n",
    "        results = pd.DataFrame(results)\n",
    "\n",
    "        # Extract 'rating' from the 'response' column\n",
    "        def extract_rating(response):\n",
    "            try:\n",
    "                # Parse the assistant's JSON content\n",
    "                content = json.loads(response['body']['choices'][0]['message']['content'])\n",
    "                return content.get('rating', None)\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting rating: {e}\")\n",
    "                return None\n",
    "\n",
    "        # Apply the function to extract the rating\n",
    "        results['food_rating'] = results['response'].apply(extract_rating)\n",
    "\n",
    "        # Keep only 'custom_id' and 'food_rating'\n",
    "        results = results[['custom_id', 'food_rating']]\n",
    "\n",
    "        # Rename custom_id to review_id\n",
    "        results.rename(columns={\"custom_id\": \"review_id\"}, inplace=True)\n",
    "\n",
    "        # Change data type of review_id to int64\n",
    "        results['review_id'] = results['review_id'].astype('int64')\n",
    "\n",
    "        # Combine 'custom_id' and extracted category sentences\n",
    "        category_df['custom_id'] = results['custom_id']\n",
    "        # Rename custom_id to review_id\n",
    "        category_df.rename(columns={\"custom_id\": \"review_id\"}, inplace=True)\n",
    "\n",
    "        # Append the results for this batch to the collection\n",
    "        food_ratings = pd.concat([food_ratings, category_df], ignore_index=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch_job_id {batch_job_id}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Service Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each row in the CSV file\n",
    "service_ratings = pd.DataFrame(columns=[\"service_rating\"]) # Initialize an empty DataFrame to store the results\n",
    "\n",
    "for _, row in batches_to_keys.iterrows():\n",
    "    batch_job_id = row['batch_job_id']\n",
    "    api_key = row['api_key']\n",
    "    batch_file_name = row.get('batch_file_name', '')  # Retrieve the batch_file_name column\n",
    "    \n",
    "    # Process only if the batch_file_name contains the word \"service\"\n",
    "    if \"service\" not in batch_file_name.lower():\n",
    "        continue  # Skip this row if \"service\" is not in the batch_file_name\n",
    "    \n",
    "    # Create the OpenAI client\n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    try:\n",
    "        # Get the results file ID for the batch job (assuming this comes from an API or prior step)\n",
    "        result_file_id = client.batches.retrieve(batch_job_id).output_file_id\n",
    "        \n",
    "        # Download the results file\n",
    "        result_content = client.files.content(result_file_id).content\n",
    "        result_file_name = \"batch_results.jsonl\"\n",
    "        with open(result_file_name, 'wb') as file:\n",
    "            file.write(result_content)  # Save the content to a file\n",
    "\n",
    "        # Parse the results\n",
    "        results = []\n",
    "        with open(result_file_name, 'r') as file:\n",
    "            for line in file:\n",
    "                results.append(json.loads(line.strip()))\n",
    "        results = pd.DataFrame(results)\n",
    "\n",
    "        # Extract 'rating' from the 'response' column\n",
    "        def extract_rating(response):\n",
    "            try:\n",
    "                # Parse the assistant's JSON content\n",
    "                content = json.loads(response['body']['choices'][0]['message']['content'])\n",
    "                return content.get('rating', None)\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting rating: {e}\")\n",
    "                return None\n",
    "\n",
    "        # Apply the function to extract the rating\n",
    "        results['service_rating'] = results['response'].apply(extract_rating)\n",
    "\n",
    "        # Keep only 'custom_id' and 'service_rating'\n",
    "        results = results[['custom_id', 'service_rating']]\n",
    "\n",
    "        # rename custom_id to review_id\n",
    "        results.rename(columns={\"custom_id\": \"review_id\"}, inplace=True)\n",
    "\n",
    "        # change data type of review_id to int64\n",
    "        results['review_id'] = results['review_id'].astype('int64')\n",
    "\n",
    "        # Combine 'custom_id' and extracted category sentences\n",
    "        category_df['custom_id'] = results['custom_id']\n",
    "        # Rename custom_id to review_id\n",
    "        category_df.rename(columns={\"custom_id\": \"review_id\"}, inplace=True)\n",
    "\n",
    "        # Append the results for this batch to the collection\n",
    "        service_ratings = pd.concat([service_ratings, category_df], ignore_index=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch_job_id {batch_job_id}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atmosphere Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each row in the CSV file\n",
    "atmosphere_ratings = pd.DataFrame(columns=[\"atmosphere_rating\"]) # Initialize an empty DataFrame to store the results\n",
    "\n",
    "for _, row in batches_to_keys.iterrows():\n",
    "    batch_job_id = row['batch_job_id']\n",
    "    api_key = row['api_key']\n",
    "    batch_file_name = row.get('batch_file_name', '')  # Retrieve the batch_file_name column\n",
    "    \n",
    "    # Process only if the batch_file_name contains the word \"atmosphere\"\n",
    "    if \"atmosphere\" not in batch_file_name.lower():\n",
    "        continue  # Skip this row if \"atmosphere\" is not in the batch_file_name\n",
    "    \n",
    "    # Create the OpenAI client\n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    try:\n",
    "        # Get the results file ID for the batch job (assuming this comes from an API or prior step)\n",
    "        result_file_id = client.batches.retrieve(batch_job_id).output_file_id\n",
    "        \n",
    "        # Download the results file\n",
    "        result_content = client.files.content(result_file_id).content\n",
    "        result_file_name = \"batch_results.jsonl\"\n",
    "        with open(result_file_name, 'wb') as file:\n",
    "            file.write(result_content)  # Save the content to a file\n",
    "\n",
    "        # Parse the results\n",
    "        results = []\n",
    "        with open(result_file_name, 'r') as file:\n",
    "            for line in file:\n",
    "                results.append(json.loads(line.strip()))\n",
    "        results = pd.DataFrame(results)\n",
    "\n",
    "        # Extract 'rating' from the 'response' column\n",
    "        def extract_rating(response):\n",
    "            try:\n",
    "                # Parse the assistant's JSON content\n",
    "                content = json.loads(response['body']['choices'][0]['message']['content'])\n",
    "                return content.get('rating', None)\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting rating: {e}\")\n",
    "                return None\n",
    "\n",
    "        # Apply the function to extract the rating\n",
    "        results['atmosphere_rating'] = results['response'].apply(extract_rating)\n",
    "\n",
    "        # Keep only 'custom_id' and 'atmosphere_rating'\n",
    "        results = results[['custom_id', 'atmosphere_rating']]\n",
    "\n",
    "        # rename custom_id to review_id\n",
    "        results.rename(columns={\"custom_id\": \"review_id\"}, inplace=True)\n",
    "\n",
    "        # change data type of review_id to int64\n",
    "        results['review_id'] = results['review_id'].astype('int64')\n",
    "\n",
    "        # Combine 'custom_id' and extracted category sentences\n",
    "        category_df['custom_id'] = results['custom_id']\n",
    "        # Rename custom_id to review_id\n",
    "        category_df.rename(columns={\"custom_id\": \"review_id\"}, inplace=True)\n",
    "\n",
    "        # Append the results for this batch to the collection\n",
    "        atmosphere_ratings = pd.concat([atmosphere_ratings, category_df], ignore_index=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch_job_id {batch_job_id}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
