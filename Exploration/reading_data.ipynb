{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from urllib.parse import urlencode\n",
    "#import googlemaps\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_basics = pd.read_csv(\"C:/Users/admin/Downloads/API_Basics.csv\")\n",
    "API_general = pd.read_csv(\"C:/Users/admin/Downloads/API_General.csv\")\n",
    "API_additional = pd.read_csv(\"C:/Users/admin/Downloads/API_Additional.csv\")\n",
    "\n",
    "# API_basics = pd.read_csv(\"C:/Users/Theresa/Downloads/API_Basics.csv\")\n",
    "# API_general = pd.read_csv(\"C:/Users/Theresa/Downloads/API_General.csv\")\n",
    "# API_additional = pd.read_csv(\"C:/Users/Theresa/Downloads/API_Additional.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting information for the cities\n",
    "was already done, no need to change anda lso no need to run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API_basics[\"city\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# api_key = \"AIzaSyCmU1xOszaGFTFecpdG8aEb7AGOGDOvB9c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to get the city boundaries\n",
    "# def get_city_boundaries(city_name):\n",
    "#     # Initialize the Google Maps client\n",
    "#     gmaps = googlemaps.Client(key=api_key) # googlemaps package\n",
    "    \n",
    "#     # Get the city boundaries\n",
    "#     geocode_result = gmaps.geocode(city_name)\n",
    "\n",
    "#     # save the boundaries\n",
    "#     low_lat = geocode_result[0]['geometry']['bounds']['southwest']['lat']\n",
    "#     low_long = geocode_result[0]['geometry']['bounds']['southwest']['lng']\n",
    "#     high_lat = geocode_result[0]['geometry']['bounds']['northeast']['lat']\n",
    "#     high_long = geocode_result[0]['geometry']['bounds']['northeast']['lng']\n",
    "\n",
    "    \n",
    "#     return low_lat, low_long, high_lat, high_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cities = pd.DataFrame(columns=['city_id', 'name', 'country', 'low_lat_value', 'low_long_value', 'high_lat_value', 'high_long_value', 'number_restaurants'])\n",
    "\n",
    "# for index, city in enumerate(API_basics[\"city\"].unique(), start=0):\n",
    "#     low_lat, low_long, high_lat, high_long = get_city_boundaries(city)\n",
    "    \n",
    "#     city_df = pd.DataFrame({\n",
    "#         'city_id': [index],\n",
    "#         'name': [city],\n",
    "#         'country': 'Germany',  # Assuming country is Germany\n",
    "#         'low_lat_value': [low_lat],\n",
    "#         'low_long_value': [low_long],\n",
    "#         'high_lat_value': [high_lat],\n",
    "#         'high_long_value': [high_long],\n",
    "#         'number_restaurants': [None]\n",
    "#     })\n",
    "\n",
    "#     cities = pd.concat([cities, city_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cities['name'] = cities['name'].str.replace('ü', 'ue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, row in cities.iterrows():\n",
    "#     city_id = row['city_id']\n",
    "#     filtered_df = API_basics[API_basics['city_id'] == city_id]\n",
    "#     unique_restaurants_count = filtered_df['id'].nunique()\n",
    "#     cities.at[index, 'number_restaurants'] = unique_restaurants_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cities.to_csv('cities.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing API Tables for input into the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Basics\n",
    "- getting lat and long data works \n",
    "- we don't need the primarytypeDisplayName as we have the primaryType\n",
    "- I have not yet figured out, how to get the name from the json... :( maybe we can cut it after text and before languageCode? I think that will be the easiest solution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current structure of the table in the database\n",
    "# CREATE TABLE Restaurant_Basics (\n",
    "#     restaurant_id VARCHAR PRIMARY KEY,\n",
    "#     city_id INT REFERENCES Cities(city_id),\n",
    "#     name VARCHAR,\n",
    "#     primary_type VARCHAR,\n",
    "#     types VARCHAR,\n",
    "#     business_status VARCHAR,\n",
    "#     pure_service_area BOOLEAN,\n",
    "#     address VARCHAR,\n",
    "#     lat_value FLOAT,\n",
    "#     long_value FLOAT\n",
    "# );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the city name into an id\n",
    "cities = pd.read_csv('cities.csv')\n",
    "city_dict = pd.Series(cities.city_id.values, index=cities.name).to_dict()\n",
    "\n",
    "API_basics['city'] = API_basics['city'].str.replace('ü', 'ue')\n",
    "API_basics['city_id'] = API_basics['city'].map(city_dict)\n",
    "API_basics.drop(\"city\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting lat and long data\n",
    "for index, row in API_basics.iterrows():\n",
    "    location_value = json.loads(row['location'].replace(\"'\", '\"'))\n",
    "    API_basics.at[index, 'lat_value'] = location_value['latitude']\n",
    "    API_basics.at[index, 'long_value'] = location_value['longitude']\n",
    "\n",
    "API_basics.drop(\"location\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the primaryTypeDisplayName\n",
    "API_basics.drop(\"primaryTypeDisplayName\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming the column name to better understand that this is not the \"finished\" name but rather the json file with the name in it\n",
    "API_basics.rename(columns = {'name': 'name_json', 'id': 'restaurant_id'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply json.dumps to each element in the 'name_transformed' column\n",
    "API_basics['name_string'] = API_basics['name_json'].apply(\n",
    "    lambda x: json.dumps(x, ensure_ascii=False) if isinstance(x, dict) else str(x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract 'text' and 'languageCode' in separate columns\n",
    "API_basics['name'] = API_basics['name_string'].str.extract(r\"'text': ?['\\\"](.*)['\\\"].*'languageCode':\")\n",
    "API_basics['language_code'] = API_basics['name_string'].str.extract(r\"'languageCode': ['\\\"]([^'\\\"]*)['\\\"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping duplicates (important as there are some!)\n",
    "duplicates = API_basics[API_basics.duplicated(subset=['name'], keep=False)]\n",
    "API_basics = API_basics.drop_duplicates(subset=['restaurant_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming columns to match the database, database columns are named in snake_case NOT camelCase \n",
    "API_basics = API_basics.rename(columns={'id': 'restaurant_id', 'primaryType': 'primary_type', 'primaryTypeDisplayName': 'primary_type_display', \n",
    "                                        'businessStatus': 'business_status', 'pureServiceAreaBusiness': 'pure_service_area',\n",
    "                                        'formattedAddress': 'address'})\n",
    "API_basics = API_basics[['restaurant_id', 'city_id', 'name', 'primary_type', 'types', 'business_status', \n",
    "                        'pure_service_area', 'address', 'lat_value', 'long_value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['restaurant_id', 'city_id', 'name', 'primary_type', 'types',\n",
       "       'business_status', 'pure_service_area', 'address', 'lat_value',\n",
       "       'long_value'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "API_basics.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_basics.to_csv('csv files/API_basics.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API general\n",
    "the only thing that is missing here are the opening hours, every other column is already processed and uploaded at the database (it would the best to save the opening hours as a json as we can then just input them in the table without changing its structure)\n",
    "\n",
    "\n",
    "-> my problem was that I didn't know which day corresponds to which as there are only 6 in the json..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current structure of the table in the database\n",
    "# CREATE TABLE restaurant_general (\n",
    "#     restaurant_id VARCHAR PRIMARY KEY,\n",
    "#     containing_places BOOLEAN,\n",
    "#     phone_number VARCHAR,\n",
    "#     website_uri VARCHAR,\n",
    "#     summary JSON,\n",
    "#     opening_hours JSON,\n",
    "#     price_level VARCHAR,\n",
    "#     price_range JSON,\n",
    "#     google_rating FLOAT,\n",
    "#     google_user_rating_count FLOAT\n",
    "# );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract string from json\n",
    "API_general['opening_hours_json'] = API_general['regularOpeningHours'].apply(json.dumps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular expression to extract the opening and closing times\n",
    "pattern = re.compile(r\"'open':\\s*\\{'day':\\s*(\\d),\\s*'hour':\\s*(\\d+),\\s*'minute':\\s*(\\d+)\\},\\s*'close':\\s*\\{'day':\\s*\\d,\\s*'hour':\\s*(\\d+),\\s*'minute':\\s*(\\d+)\\}\")\n",
    "\n",
    "# Days of the week for reference (0 = Monday, 1 = Tuesday, ..., 6 = Sunday)\n",
    "days_of_week = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "# Iterate over each entry in the Series and extract opening hours\n",
    "opening_hours_json = []\n",
    "\n",
    "for entry in API_general['opening_hours_json']:\n",
    "    matches = pattern.findall(entry)\n",
    "\n",
    "    # Initialize a dictionary to hold the opening hours for each weekday\n",
    "    weekly_hours = {}\n",
    "\n",
    "    for match in matches:\n",
    "        # Convert the minute values to integers and format them correctly\n",
    "        open_time = f\"{int(match[1])}:{int(match[2]):02d}\"\n",
    "        close_time = f\"{int(match[3])}:{int(match[4]):02d}\"\n",
    "        day_name = days_of_week[int(match[0])]  # Convert open_day to day name\n",
    "\n",
    "        # Store the opening hours for each day\n",
    "        weekly_hours[day_name] = {'open': open_time, 'close': close_time}\n",
    "    \n",
    "    # Add the result to the list\n",
    "    opening_hours_json.append(json.dumps(weekly_hours))  # Store as JSON\n",
    "\n",
    "API_general['opening_hours'] = opening_hours_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'startPrice': {'currencyCode': 'EUR', 'units': '1'},\n",
       " 'endPrice': {'currencyCode': 'EUR', 'units': '10'}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(API_general['priceRange'][0].replace(\"'\", '\"'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_to_json(string):\n",
    "    if pd.notna(string):\n",
    "        try: \n",
    "            json_value = json.loads(string.replace(\"'\", '\"'))\n",
    "            return json_value\n",
    "        except Exception as e:\n",
    "            print(\"Fehler:\", e)\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Laid-back hotel featuring a bar, a restaurant & a terrace, plus meeting & event space.',\n",
       " 'languageCode': 'en'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_to_json(API_general['editorialSummary'][23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehler: Expecting ',' delimiter: line 1 column 98 (char 97)\n",
      "Fehler: Expecting ',' delimiter: line 1 column 97 (char 96)\n",
      "Fehler: Expecting ',' delimiter: line 1 column 101 (char 100)\n",
      "Fehler: Expecting ',' delimiter: line 1 column 69 (char 68)\n",
      "Fehler: Expecting ',' delimiter: line 1 column 81 (char 80)\n",
      "Fehler: Expecting ',' delimiter: line 1 column 97 (char 96)\n",
      "Fehler: Expecting ',' delimiter: line 1 column 100 (char 99)\n",
      "Fehler: Expecting ',' delimiter: line 1 column 44 (char 43)\n",
      "Fehler: Expecting ',' delimiter: line 1 column 98 (char 97)\n",
      "Fehler: Expecting ',' delimiter: line 1 column 98 (char 97)\n",
      "Fehler: Expecting ',' delimiter: line 1 column 17 (char 16)\n"
     ]
    }
   ],
   "source": [
    "API_general[\"price_range\"] = API_general[\"priceRange\"].apply(make_to_json)\n",
    "API_general[\"editorial_summary\"] = API_general[\"editorialSummary\"].apply(make_to_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(API_general[\"price_range\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['restaurant_id', 'containing_places', 'phone_number', 'website_uri',\n",
       "       'opening_hours', 'price_level', 'price_range', 'google_rating',\n",
       "       'google_user_rating_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "API_general.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming columns to match the database\n",
    "API_general = API_general.rename(columns={'id': 'restaurant_id', 'containingPlaces': 'containing_places', 'internationalPhoneNumber': 'phone_number', \n",
    "                                        'placesWebsiteUri': 'website_uri', 'priceLevel': 'price_level', \n",
    "                                        'userRatingCount': 'google_user_rating_count', 'rating': 'google_rating'})\n",
    "API_general = API_general[['restaurant_id', 'containing_places', 'phone_number', 'website_uri', 'opening_hours', \n",
    "                           'price_level', 'price_range', 'google_rating', 'google_user_rating_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_general.to_csv('csv files/API_general.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API additional\n",
    "should be all done and is already uploaded to the database on the server, but you can have a look at it whether it is correct or I made a mistake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current structure of the table in the database\n",
    "# CREATE TABLE public.restaurant_additional (\n",
    "#     restaurant_id character varying NOT NULL,\n",
    "#     curbside_pickup boolean,\n",
    "#     delivery boolean,\n",
    "#     dine_in boolean,\n",
    "#     live_music boolean,\n",
    "#     outdoor_seating boolean,\n",
    "#     reservable boolean,\n",
    "#     restroom boolean,\n",
    "#     serves_beer boolean,\n",
    "#     serves_breakfast boolean,\n",
    "#     serves_brunch boolean,\n",
    "#     serves_cocktails boolean,\n",
    "#     serves_coffee boolean,\n",
    "#     serves_dessert boolean,\n",
    "#     serves_dinner boolean,\n",
    "#     serves_lunch boolean,\n",
    "#     serves_vegetarian_food boolean,\n",
    "#     serves_wine boolean,\n",
    "#     takeout boolean,\n",
    "#     allows_dogs boolean,\n",
    "#     good_for_children boolean,\n",
    "#     good_for_groups boolean,\n",
    "#     good_for_watching_sports boolean,\n",
    "#     menu_for_children boolean,\n",
    "#     free_parking_lot boolean,\n",
    "#     paid_parking_lot boolean,\n",
    "#     free_street_parking boolean,\n",
    "#     paid_street_parking boolean,\n",
    "#     free_garage_parking boolean,\n",
    "#     paid_garage_parking boolean,\n",
    "#     valet_parking boolean,\n",
    "#     accepts_debit_cards boolean,\n",
    "#     accepts_credit_cards boolean,\n",
    "#     accepts_cash_only boolean,\n",
    "#     accepts_nfc boolean,\n",
    "#     wheelchair_accessible_restroom boolean,\n",
    "#     wheelchair_accessible_entrance boolean,\n",
    "#     wheelchair_accessible_parking boolean,\n",
    "#     wheelchair_accessible_seating boolean,\n",
    "#     PRIMARY KEY (restaurant_id)\n",
    "# );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'wheelchairAccessibleParking': True, 'wheelchairAccessibleEntrance': True, 'wheelchairAccessibleRestroom': True, 'wheelchairAccessibleSeating': True}\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "API_additional['accessibilityOptions'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'freeGarageParking', 'valetParking', 'freeStreetParking', 'paidParkingLot', 'freeParkingLot', 'paidGarageParking', 'paidStreetParking'}\n"
     ]
    }
   ],
   "source": [
    "# getting all of the keys in parking Options:\n",
    "all_keys = set()\n",
    "\n",
    "for entry in API_additional['parkingOptions']:\n",
    "    if not pd.isna(entry):  # Wenn der Eintrag nicht None oder leer ist\n",
    "        try:\n",
    "            # Lade den JSON-String in ein Dictionary\n",
    "            json_string = entry.replace(\"'\", '\"').replace(\"True\", \"true\").replace(\"False\", \"false\")\n",
    "            parking_dict = json.loads(json_string)\n",
    "            \n",
    "            # Füge die Schlüssel des Dictionaries zum Set hinzu\n",
    "            all_keys.update(parking_dict.keys())\n",
    "        except (json.JSONDecodeError, TypeError) as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "\n",
    "print(all_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_parking_info(parking_options_string):\n",
    "    try:\n",
    "        if not pd.isna(parking_options_string):\n",
    "            json_string = parking_options_string.replace(\"'\", '\"').replace(\"True\", \"true\").replace(\"False\", \"false\")\n",
    "            parking_dict = json.loads(json_string)\n",
    "    \n",
    "            # Extrahiere relevante Informationen, Standardwert False falls der Schlüssel nicht vorhanden ist\n",
    "            free_parking_lot = parking_dict.get('freeParkingLot', np.nan)\n",
    "            paid_parking_lot = parking_dict.get('paidParkingLot', np.nan)\n",
    "            free_street_parking = parking_dict.get('freeStreetParking', np.nan)\n",
    "            paid_street_parking = parking_dict.get('paidStreetParking', np.nan)\n",
    "            free_garage_parking = parking_dict.get('freeGarageParking', np.nan)\n",
    "            paid_garage_parking = parking_dict.get('paidGarageParking', np.nan)\n",
    "            valet_parking = parking_dict.get('valetParking', np.nan)\n",
    "\n",
    "        else:\n",
    "            free_parking_lot = np.nan\n",
    "            paid_parking_lot = np.nan\n",
    "            free_street_parking = np.nan\n",
    "            paid_street_parking = np.nan\n",
    "            free_garage_parking = np.nan\n",
    "            paid_garage_parking = np.nan\n",
    "            valet_parking = np.nan\n",
    "            \n",
    "    \n",
    "    except (json.JSONDecodeError, TypeError) as e:\n",
    "        print(f\"Error decoding JSON: {e}\")\n",
    "        return (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan)   \n",
    "    \n",
    "    return (free_parking_lot, paid_parking_lot, free_street_parking, paid_street_parking, free_garage_parking, paid_garage_parking, valet_parking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying method to get all options\n",
    "API_additional[['free_parking_lot', 'paid_parking_lot', 'free_street_parking', 'paid_street_parking', 'free_garage_parking', 'paid_garage_parking', 'valet_parking']] = API_additional['parkingOptions'].apply(extract_parking_info).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acceptsCreditCards', 'acceptsDebitCards', 'acceptsCashOnly', 'acceptsNfc'}\n"
     ]
    }
   ],
   "source": [
    "# getting all of the keys in parking Options:\n",
    "all_keys = set()\n",
    "\n",
    "for entry in API_additional['paymentOptions']:\n",
    "    if not pd.isna(entry):  \n",
    "        try:\n",
    "            # loading the json-string to a dict\n",
    "            json_string = entry.replace(\"'\", '\"').replace(\"True\", \"true\").replace(\"False\", \"false\")\n",
    "            parking_dict = json.loads(json_string)\n",
    "            \n",
    "            # adding the keys of the dict to the set\n",
    "            all_keys.update(parking_dict.keys())\n",
    "        except (json.JSONDecodeError, TypeError) as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "\n",
    "print(all_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_payment_info(payment_options_string):\n",
    "    try:\n",
    "        if not pd.isna(payment_options_string):\n",
    "            json_string = payment_options_string.replace(\"'\", '\"').replace(\"True\", \"true\").replace(\"False\", \"false\")\n",
    "            parking_dict = json.loads(json_string)\n",
    "    \n",
    "            # extract relevant information, nan if key is not there\n",
    "            accepts_debit_cards = parking_dict.get('acceptsDebitCards', np.nan)\n",
    "            accepts_credit_cards = parking_dict.get('acceptsCreditCards', np.nan)\n",
    "            accepts_cash_only = parking_dict.get('acceptsCashOnly', np.nan)\n",
    "            accepts_nfc = parking_dict.get('acceptsNfc', np.nan)\n",
    "\n",
    "        else:\n",
    "            accepts_debit_cards = np.nan\n",
    "            accepts_credit_cards = np.nan\n",
    "            accepts_cash_only = np.nan\n",
    "            accepts_nfc = np.nan\n",
    "            \n",
    "    \n",
    "    except (json.JSONDecodeError, TypeError) as e:\n",
    "        print(f\"Error decoding JSON: {e}\")\n",
    "        return (np.nan, np.nan, np.nan, np.nan)   \n",
    "    \n",
    "    return (accepts_debit_cards, accepts_credit_cards, accepts_cash_only, accepts_nfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying method to get all options\n",
    "API_additional[['accepts_debit_cards', 'accepts_credit_cards', 'accepts_cash_only', 'accepts_nfc']] = API_additional['paymentOptions'].apply(extract_payment_info).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wheelchairAccessibleRestroom', 'wheelchairAccessibleEntrance', 'wheelchairAccessibleParking', 'wheelchairAccessibleSeating'}\n"
     ]
    }
   ],
   "source": [
    "# getting all of the keys in accessibility Options:\n",
    "all_keys = set()\n",
    "\n",
    "for entry in API_additional['accessibilityOptions']:\n",
    "    if not pd.isna(entry):  # Wenn der Eintrag nicht None oder leer ist\n",
    "        try:\n",
    "            # loading the json-string to a dict\n",
    "            json_string = entry.replace(\"'\", '\"').replace(\"True\", \"true\").replace(\"False\", \"false\")\n",
    "            parking_dict = json.loads(json_string)\n",
    "            \n",
    "            # adding the keys of the dict to the set\n",
    "            all_keys.update(parking_dict.keys())\n",
    "        except (json.JSONDecodeError, TypeError) as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "\n",
    "print(all_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_accessibility_info(accessibility_options_string):\n",
    "    try:\n",
    "        if not pd.isna(accessibility_options_string):\n",
    "            json_string = accessibility_options_string.replace(\"'\", '\"').replace(\"True\", \"true\").replace(\"False\", \"false\")\n",
    "            parking_dict = json.loads(json_string)\n",
    "    \n",
    "            # extract relevant information, nan if key is not there\n",
    "            wheelchair_accessible_restroom = parking_dict.get('wheelchairAccessibleRestroom', np.nan)\n",
    "            wheelchair_accessible_entrance = parking_dict.get('wheelchairAccessibleEntrance', np.nan)\n",
    "            wheelchair_accessible_parking = parking_dict.get('wheelchairAccessibleParking', np.nan)\n",
    "            wheelchair_accessible_seating = parking_dict.get('wheelchairAccessibleSeating', np.nan)\n",
    "\n",
    "        else:\n",
    "            wheelchair_accessible_restroom = np.nan\n",
    "            wheelchair_accessible_entrance = np.nan\n",
    "            wheelchair_accessible_parking = np.nan\n",
    "            wheelchair_accessible_seating = np.nan\n",
    "            \n",
    "    \n",
    "    except (json.JSONDecodeError, TypeError) as e:\n",
    "        print(f\"Error decoding JSON: {e}\")\n",
    "        return (np.nan, np.nan, np.nan, np.nan)   \n",
    "    \n",
    "    return (wheelchair_accessible_restroom, wheelchair_accessible_entrance, wheelchair_accessible_parking, wheelchair_accessible_seating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying method to get all options\n",
    "API_additional[['wheelchair_accessible_restroom', 'wheelchair_accessible_entrance', 'wheelchair_accessible_parking', 'wheelchair_accessible_seating']] = API_additional['accessibilityOptions'].apply(extract_accessibility_info).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_additional.drop(\"parkingOptions\", axis=1, inplace=True)\n",
    "API_additional.drop(\"paymentOptions\", axis=1, inplace=True)\n",
    "API_additional.drop(\"accessibilityOptions\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['restaurant_id', 'curbside_pickup', 'delivery', 'dine_in', 'live_music',\n",
       "       'outdoor_seating', 'reservable', 'restroom', 'serves_beer',\n",
       "       'serves_breakfast', 'serves_brunch', 'serves_cocktails',\n",
       "       'serves_coffee', 'serves_dessert', 'serves_dinner', 'serves_lunch',\n",
       "       'serves_vegetarian_food', 'serves_wine', 'takeout', 'allows_dogs',\n",
       "       'good_for_children', 'good_for_groups', 'good_for_watching_sports',\n",
       "       'menu_for_children', 'free_parking_lot', 'paid_parking_lot',\n",
       "       'free_street_parking', 'paid_street_parking', 'free_garage_parking',\n",
       "       'paid_garage_parking', 'valet_parking', 'accepts_debit_cards',\n",
       "       'accepts_credit_cards', 'accepts_cash_only', 'accepts_nfc',\n",
       "       'wheelchair_accessible_restroom', 'wheelchair_accessible_entrance',\n",
       "       'wheelchair_accessible_parking', 'wheelchair_accessible_seating'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "API_additional.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming columns to match the database\n",
    "API_additional = API_additional.rename(columns={'id': 'restaurant_id', 'curbsidePickup': 'curbside_pickup', 'dineIn': 'dine_in', \n",
    "                                        'liveMusic': 'live_music', 'outdoorSeating': 'outdoor_seating', 'servesBeer': 'serves_beer', \n",
    "                                        'servesBreakfast': 'serves_breakfast', 'servesBrunch': 'serves_brunch', \n",
    "                                        'servesCocktails': 'serves_cocktails', 'servesCoffee': 'serves_coffee', 'servesDessert': 'serves_dessert', \n",
    "                                        'servesDinner': 'serves_dinner', 'servesLunch': 'serves_lunch',\n",
    "                                        'servesVegetarianFood': 'serves_vegetarian_food', 'servesWine': 'serves_wine', 'allowsDogs': 'allows_dogs',\n",
    "                                        'goodForChildren': 'good_for_children', 'goodForGroups': 'good_for_groups',\n",
    "                                        'goodForWatchingSports': 'good_for_watching_sports', 'menuForChildren': 'menu_for_children'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting duplicates\n",
    "API_additional = API_additional.drop_duplicates(subset=['restaurant_id'])\n",
    "\n",
    "# changing np.nan to NULL\n",
    "API_additional = API_additional.where(pd.notna(API_additional), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_additional.to_csv('csv files/API_additional.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
