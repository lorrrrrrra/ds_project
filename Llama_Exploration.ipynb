{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ex4bdubzLzao"
   },
   "source": [
    "# Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dxN-UzjUOa1O",
    "outputId": "34d539fb-79d4-430d-fb71-910cc3f43479"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.0/139.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.7/413.7 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.45.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.1+cu121)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (4.12.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.16.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "### Colab preparations\n",
    "!pip install -q torch transformers datasets peft accelerate bitsandbytes py7zr\n",
    "!pip install -U bitsandbytes\n",
    "\n",
    "from google.colab import userdata\n",
    "from huggingface_hub import login\n",
    "huggingface_token = userdata.get('HF_TOKEN')\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!ls /content/drive/MyDrive/'Colab Notebooks'/DSP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For BW Uni Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### for working on the BwCluster\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Replace with your Hugging Face token\n",
    "huggingface_token = \"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\"\n",
    "\n",
    "# Log in\n",
    "login(token=huggingface_token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6SN6h0l2MCVM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-18 17:18:38.837117: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-18 17:18:39.451295: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-18 17:18:39.451338: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-18 17:18:39.451368: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-18 17:18:39.564168: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-18 17:18:54.025300: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, BitsAndBytesConfig, DataCollatorForLanguageModeling\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bdb0i6QlMBLy"
   },
   "source": [
    "## Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "kHXdDGOzL6fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   review_id                restaurant_id      review_date scraping_date  \\\n",
      "0       4471  ChIJ_VWb4xn6mUcRH4NujtHMKJI    vor 8 Monaten    2025-01-06   \n",
      "1       4472  ChIJ_VWb4xn6mUcRH4NujtHMKJI   vor 11 Monaten    2025-01-06   \n",
      "2       4473  ChIJ_VWb4xn6mUcRH4NujtHMKJI   vor einem Jahr    2025-01-06   \n",
      "5       4476  ChIJ_VWb4xn6mUcRH4NujtHMKJI  vor einem Monat    2025-01-06   \n",
      "8       4479  ChIJ_VWb4xn6mUcRH4NujtHMKJI   vor einem Jahr    2025-01-06   \n",
      "\n",
      "   stars  dining_stars_food  dining_stars_service  dining_stars_atmosphere  \\\n",
      "0    2.0                3.0                   3.0                      2.0   \n",
      "1    4.0                4.0                   4.0                      3.0   \n",
      "2    1.0                1.0                   4.0                      4.0   \n",
      "5    5.0                5.0                   5.0                      5.0   \n",
      "8    1.0                1.0                   3.0                      3.0   \n",
      "\n",
      "                                         review_text  \n",
      "0  Also ich hab da gerade gefrühstückt!!!\\nIch fü...  \n",
      "1  Ein schönes Café für den kurzen Zwischenstopp....  \n",
      "2  Zum Start von unserer Urlaubsreise haben wir u...  \n",
      "5  Tolles Kaffe gute Backwaren ,l.die Mädels schm...  \n",
      "8  Die Erfahrung mit der Bäckerei Schmidt in Duss...  \n"
     ]
    }
   ],
   "source": [
    "### Prepare dataset to test and fine-tune the model\n",
    "import pandas as pd\n",
    "\n",
    "# read in extract from the google maps reviews webscraping (from 10.01.2025)\n",
    "additional_reviews = pd.read_csv(\"reviews_additional_selected.csv\")\n",
    "general_reviews = pd.read_csv(\"reviews_general_selected.csv\")\n",
    "\n",
    "# keep only necessary information\n",
    "subratings = general_reviews[['review_id','restaurant_id', 'review_date', 'scraping_date', 'review_text', 'stars']]\n",
    "\n",
    "# add information about the subratings to the additional reviews\n",
    "subratings = additional_reviews.merge(subratings, on='review_id', how='left')\n",
    "\n",
    "# keep only relevant columns\n",
    "subratings.rename(columns={'restaurant_id_x': 'restaurant_id'}, inplace=True) # rename one of the restaurant_id columns\n",
    "subratings = subratings[['review_id', 'restaurant_id', 'review_date', 'scraping_date', 'stars', 'dining_stars_food', 'dining_stars_service', 'dining_stars_atmosphere', 'review_text']]\n",
    "\n",
    "# drop all missings\n",
    "subratings = subratings.dropna()\n",
    "\n",
    "# save the data\n",
    "subratings.to_csv(\"subratings_data.csv\", index=False)\n",
    "print(subratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "3fgVmcmeNraU"
   },
   "outputs": [],
   "source": [
    "### Split the dataset into train and test set\n",
    "# Load the dataset as a single split\n",
    "#dataset = load_dataset(\"csv\", data_files=\"/content/drive/MyDrive/Colab Notebooks/DSP/subratings_data.csv\", split=\"train\")\n",
    "dataset = load_dataset(\"csv\", data_files=\"subratings_data.csv\", split=\"train\")\n",
    "\n",
    "# Shuffle and split the dataset\n",
    "shuffled_dataset = dataset.shuffle(seed=42)\n",
    "split_dataset = shuffled_dataset.train_test_split(test_size=0.02, seed=42)\n",
    "\n",
    "# Access the training and testing subsets\n",
    "train_dataset = split_dataset[\"train\"]\n",
    "test_dataset = split_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tuJDwIE4QiA1",
    "outputId": "59cd674c-68f8-4604-f4a9-a7f8ed2e2781"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['review_id', 'restaurant_id', 'review_date', 'scraping_date', 'stars', 'dining_stars_food', 'dining_stars_service', 'dining_stars_atmosphere', 'review_text'],\n",
       "    num_rows: 23290\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qvdsAKNXQkHF",
    "outputId": "5c500574-4282-4ebb-c62b-8af9c7722570"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['review_id', 'restaurant_id', 'review_date', 'scraping_date', 'stars', 'dining_stars_food', 'dining_stars_service', 'dining_stars_atmosphere', 'review_text'],\n",
       "    num_rows: 476\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tolles Restaurant mit typisch badischen Gerichten. Sehr freundliche und liebenswerte Wirtsleute. Die Einrichtung ist traditionell mit warmem Ofen. Auch Sonderwünsche werden nach Möglichkeit erfüllt. Immer ein Besuch wert. Egal ob im Sommer draußen oder mit einer größeren Gruppe im Nebenraum,  oder zu einem gemütlichen Essen zu zweit.\n"
     ]
    }
   ],
   "source": [
    "review_1 = test_dataset['review_text'][0]\n",
    "print(review_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1hRyeKmANsz0"
   },
   "source": [
    "# 1. Task: Generate subratings for different categories\n",
    "## LLama 3.2 3B \n",
    "### Zero-shot classification pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef78e98e22754372ae1a575c58946915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/844 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87346e3794e641f2a37ebb6357c7e201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edd258eb43164713bc6f140e3a7356a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2f38d9dcad043d5b9e277b46ce76b0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22901049111f48e7a8820ef5912c85c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c10dd78046eb4a11a1f2cc5f80979948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.2-3B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24790bb29a5d4ab58ce1eb0de9bbfeea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/50.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36b41a17ab084cefae1263f5add2353e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b3fa36b282747e0ad58acacbce3c11a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/301 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "Tokenizer was not supporting padding necessary for zero-shot, attempting to use  `pad_token=eos_token`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 'Essen sehr lecker. Ambiente und Service könnte man als „authentisch asiatisch“ bezeichnen ;)', 'labels': ['very bar', 'very good', 'bad', 'good', 'neutral'], 'scores': [0.3407549560070038, 0.20040936768054962, 0.1997615098953247, 0.13645637035369873, 0.12261777371168137]}\n"
     ]
    }
   ],
   "source": [
    "model_id = \"meta-llama/Llama-3.2-3B\"\n",
    "classifier = pipeline('zero-shot-classification',\n",
    "                      model_id, \n",
    "                      device_map=\"auto\")\n",
    "candidate_labels = [\"very good\", \"good\", \"neutral\", \"bad\", \"very bar\"]\n",
    "result = classifier(review_1, candidate_labels=candidate_labels)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 'Essen sehr lecker. Ambiente und Service könnte man als „authentisch asiatisch“ bezeichnen ;)', 'labels': ['very bad', 'bad', 'neutral', 'good', 'very good'], 'scores': [0.2663605511188507, 0.2596096098423004, 0.1675957888364792, 0.15392141044139862, 0.1525125503540039]}\n"
     ]
    }
   ],
   "source": [
    "candidate_labels = [\"very good\", \"good\", \"neutral\", \"bad\", \"very bad\"]\n",
    "\n",
    "# Use a custom hypothesis template\n",
    "hypothesis_template = \"The food quality is {}.\"\n",
    "\n",
    "# Classify\n",
    "result = classifier(\n",
    "    review_1,\n",
    "    candidate_labels=candidate_labels,\n",
    "    hypothesis_template=hypothesis_template\n",
    ")\n",
    "\n",
    "# Print the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Em1NGpDOAvo"
   },
   "source": [
    "What this means:\n",
    "LLaMA 3.2-3B does not natively include a classification head (LlamaForSequenceClassification)\n",
    "Hugging Face has automatically added a classification head (e.g., score.weight) to the model so it can handle text classification\n",
    "\n",
    "--> not usueful for our task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b4854cc51641bca98452536fdd0d91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True,\n",
    "                                         bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "                                         bnb_4bit_use_double_quant=True,\n",
    "                                         bnb_4bit_quant_type= \"nf4\"\n",
    "                                         )\n",
    "\n",
    "quantized_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, device_map=\"auto\", torch_dtype=torch.bfloat16, quantization_config=quantization_config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rating reviews: 100%|██████████| 2/2 [01:31<00:00, 45.51s/it]\n"
     ]
    }
   ],
   "source": [
    "def get_rating(review_text: str, category: str) -> int:\n",
    "    \"\"\"\n",
    "    Given a review text and a category, return a rating from 1 to 5.\n",
    "    Categories: 'food', 'service', 'atmosphere'.\n",
    "    \"\"\"\n",
    "    # Define prompts for different categories\n",
    "    prompts = {\n",
    "        'food': \"Based on the following review, rate the food quality on a scale from 1 (very bad) to 5 (very good):\\n\\nReview: {review_text}\\n\\nPlease only provide a numeric rating from 1 to 5 without any additional text:\",\n",
    "        'service': \"Based on the following review, rate the service quality on a scale from 1 (very bad) to 5 (very good):\\n\\nReview: {review_text}\\n\\nPlease only provide a numeric rating from 1 to 5 without any additional text:\",\n",
    "        'atmosphere': \"Based on the following review, rate the atmosphere quality on a scale from 1 (very bad) to 5 (very good):\\n\\nReview: {review_text}\\n\\nPlease only provide a numeric rating from 1 to 5 without any additional text:\"\n",
    "    }\n",
    "\n",
    "    # Get the appropriate prompt for the category\n",
    "    prompt = prompts.get(category, \"\").format(review_text=review_text)\n",
    "    \n",
    "    # Tokenize the input and set the pad_token_id explicitly\n",
    "    inputs = tokenizer(\n",
    "        prompt, \n",
    "        return_tensors=\"pt\"  # Explicitly set the pad_token_id here\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    # Check if pad_token is None, if so, use eos_token as pad_token (by default LLama 3.1 padding token None)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token  # Use EOS token as padding\n",
    "\n",
    "    # Generate the response, explicitly set pad_token_id during generation\n",
    "    outputs = quantized_model.generate(\n",
    "        **inputs, \n",
    "        max_new_tokens=2, \n",
    "        temperature=0.7, \n",
    "        pad_token_id=tokenizer.convert_tokens_to_ids(tokenizer.pad_token)  # Explicitly setting pad_token_id during generation\n",
    "    )\n",
    "\n",
    "    generated_text = tokenizer.decode(outputs[0][inputs['input_ids'].shape[-1]:], skip_special_tokens=True)\n",
    "\n",
    "    try:\n",
    "        # Ensure the output is a numeric value\n",
    "        rating = int(generated_text.strip())\n",
    "        return rating\n",
    "    except ValueError:\n",
    "        # Fallback if the output is not a valid integer\n",
    "        return None\n",
    "\n",
    "# Initialize lists to store ratings and true ratings\n",
    "predicted_food_ratings = []\n",
    "predicted_service_ratings = []\n",
    "predicted_atmosphere_ratings = []\n",
    "true_food_ratings = test_dataset['dining_stars_food']\n",
    "true_service_ratings = test_dataset['dining_stars_service']\n",
    "true_atmosphere_ratings = test_dataset['dining_stars_atmosphere']\n",
    "\n",
    "batch_size = 65  # adjust the batch size depending on your GPU memory\n",
    "for i in tqdm(range(0, len(test_dataset['review_text']), batch_size), desc=\"Rating reviews\"):\n",
    "    batch_reviews = test_dataset['review_text'][i:i+batch_size]\n",
    "    \n",
    "    # For each batch, generate ratings for food, service, and atmosphere\n",
    "    for review_text in batch_reviews:\n",
    "        # Initialize ratings for each category\n",
    "        food_rating = get_rating(review_text, 'food')\n",
    "        service_rating = get_rating(review_text, 'service')\n",
    "        atmosphere_rating = get_rating(review_text, 'atmosphere')\n",
    "        \n",
    "        # Append the generated ratings to the lists\n",
    "        predicted_food_ratings.append(food_rating)\n",
    "        predicted_service_ratings.append(service_rating)\n",
    "        predicted_atmosphere_ratings.append(atmosphere_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 5, 4, 4, 4, 4, 3, 3, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 5, 4, 4, 5, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 1, 1, 4, 4, 5, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 5, 4, 4, 4, 4, 4, 1, 4, 4, 3, 2, 4, 5, 3, 4, 4, 4, 4, 4, 5, 4, 3, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 3, 4, 4, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_food_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Food rating accuracy: 26.89%\n",
      "Service rating accuracy: 31.93%\n",
      "Atmosphere rating accuracy: 27.73%\n",
      "Food rating MAE: 0.86\n",
      "Service rating MAE: 0.82\n",
      "Atmosphere rating MAE: 0.84\n"
     ]
    }
   ],
   "source": [
    "# Now compare the predicted ratings with the true ratings\n",
    "def compare_ratings(true_ratings, predicted_ratings):\n",
    "    \"\"\"\n",
    "    Compare true and predicted ratings and compute performance metrics.\n",
    "    \"\"\"\n",
    "    correct_predictions = sum([1 for true, pred in zip(true_ratings, predicted_ratings) if true == pred])\n",
    "    accuracy = correct_predictions / len(true_ratings) * 100\n",
    "    return accuracy\n",
    "\n",
    "# Compare the predicted ratings with the true ratings\n",
    "food_accuracy = compare_ratings(true_food_ratings, predicted_food_ratings)\n",
    "service_accuracy = compare_ratings(true_service_ratings, predicted_service_ratings)\n",
    "atmosphere_accuracy = compare_ratings(true_atmosphere_ratings, predicted_atmosphere_ratings)\n",
    "\n",
    "print(f\"Food rating accuracy: {food_accuracy:.2f}%\")\n",
    "print(f\"Service rating accuracy: {service_accuracy:.2f}%\")\n",
    "print(f\"Atmosphere rating accuracy: {atmosphere_accuracy:.2f}%\")\n",
    "\n",
    "def calculate_mae(true_ratings, predicted_ratings):\n",
    "    \"\"\"\n",
    "    Compute the Mean Absolute Error (MAE) between true and predicted ratings.\n",
    "    \"\"\"\n",
    "    mae = sum(abs(true - pred) for true, pred in zip(true_ratings, predicted_ratings)) / len(true_ratings)\n",
    "    return mae\n",
    "\n",
    "# Compute MAE for each category\n",
    "food_mae = calculate_mae(true_food_ratings, predicted_food_ratings)\n",
    "service_mae = calculate_mae(true_service_ratings, predicted_service_ratings)\n",
    "atmosphere_mae = calculate_mae(true_atmosphere_ratings, predicted_atmosphere_ratings)\n",
    "\n",
    "print(f\"Food rating MAE: {food_mae:.2f}\")\n",
    "print(f\"Service rating MAE: {service_mae:.2f}\")\n",
    "print(f\"Atmosphere rating MAE: {atmosphere_mae:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama 3.1 8B \n",
    "### 4-bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75dc6aaa1f4f4ddcb0faf4d1cfa8866f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True,\n",
    "                                         bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "                                         bnb_4bit_use_double_quant=True,\n",
    "                                         bnb_4bit_quant_type= \"nf4\"\n",
    "                                         )\n",
    "\n",
    "quantized_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, device_map=\"auto\", torch_dtype=torch.bfloat16, quantization_config=quantization_config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['review_id', 'dining_stars_food', 'dining_stars_service', 'dining_stars_atmosphere', 'review_text'],\n",
      "    num_rows: 2377\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5\n"
     ]
    }
   ],
   "source": [
    "### food rating\n",
    "prompt = f\"Based on the following review, rate the food quality on a scale from 1 (very bad) to 5 (very good):\\n\\nReview: {review_1}\\n\\nPlease only provide a numeric rating from 1 to 5 without any additional text:\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "outputs = quantized_model.generate(**inputs, max_new_tokens=2, temperature=0.7, pad_token_id=tokenizer.eos_token_id)\n",
    "generated_text = tokenizer.decode(outputs[0][inputs['input_ids'].shape[-1]:], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5\n"
     ]
    }
   ],
   "source": [
    "### atmosphere rating\n",
    "prompt = f\"Based on the following review, rate the atmosphere on a scale from 1 (very bad) to 5 (very good):\\n\\nReview: {review_1}\\n\\nPlease only provide a numeric rating from 1 to 5 without any additional text:\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "outputs = quantized_model.generate(**inputs, max_new_tokens=2, temperature=0.7, pad_token_id=tokenizer.eos_token_id)\n",
    "generated_text = tokenizer.decode(outputs[0][inputs['input_ids'].shape[-1]:], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5\n"
     ]
    }
   ],
   "source": [
    "### service rating\n",
    "prompt = f\"Based on the following review, rate the service on a scale from 1 (very bad) to 5 (very good):\\n\\nReview: {review_1}\\n\\nPlease only provide a numeric rating from 1 to 5 without any additional text:\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "outputs = quantized_model.generate(**inputs, max_new_tokens=2, temperature=0.7, pad_token_id=tokenizer.eos_token_id)\n",
    "generated_text = tokenizer.decode(outputs[0][inputs['input_ids'].shape[-1]:], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dertermine the appropriate length of the input\n",
    "review_lengths = [len(tokenizer(sample['review_text'])['input_ids']) for sample in train_dataset]\n",
    "\n",
    "# Inspect the distribution of token lengths\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(review_lengths, bins=50)\n",
    "plt.xlabel('Review Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Token Lengths in the reviews')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating for food: 5\n",
      "Rating for service: 4\n",
      "Rating for atmosphere: 4\n"
     ]
    }
   ],
   "source": [
    "### all categories in one\n",
    "\n",
    "def get_rating(review_text: str, category: str) -> int:\n",
    "    \"\"\"\n",
    "    Given a review text and a category, return a rating from 1 to 5.\n",
    "    Categories: 'food', 'service', 'atmosphere'.\n",
    "    \"\"\"\n",
    "    # Define prompts for different categories\n",
    "    prompts = {\n",
    "        'food': \"Based on the following review, rate the food quality on a scale from 1 (very bad) to 5 (very good):\\n\\nReview: {review_text}\\n\\nPlease only provide a numeric rating from 1 to 5 without any additional text:\",\n",
    "        'service': \"Based on the following review, rate the service quality on a scale from 1 (very bad) to 5 (very good):\\n\\nReview: {review_text}\\n\\nPlease only provide a numeric rating from 1 to 5 without any additional text:\",\n",
    "        'atmosphere': \"Based on the following review, rate the atmosphere quality on a scale from 1 (very bad) to 5 (very good):\\n\\nReview: {review_text}\\n\\nPlease only provide a numeric rating from 1 to 5 without any additional text:\"\n",
    "    }\n",
    "    \n",
    "    # Get the appropriate prompt for the category\n",
    "    prompt = prompts.get(category, \"\").format(review_text=review_text)\n",
    "    \n",
    "    # Tokenize the input\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=500).to(\"cuda\")\n",
    "    \n",
    "    # Generate the response\n",
    "    outputs = quantized_model.generate(**inputs, max_new_tokens=2, temperature=0.7, pad_token_id=tokenizer.eos_token_id)\n",
    "    \n",
    "    # Decode the generated text\n",
    "    generated_text = tokenizer.decode(outputs[0][inputs['input_ids'].shape[-1]:], skip_special_tokens=True)\n",
    "    \n",
    "    try:\n",
    "        # Ensure the output is a numeric value\n",
    "        rating = int(generated_text.strip())\n",
    "        return rating\n",
    "    except ValueError:\n",
    "        # Fallback if the output is not a valid integer\n",
    "        return None\n",
    "\n",
    "\n",
    "# List of categories to process\n",
    "categories = ['food', 'service', 'atmosphere']\n",
    "\n",
    "# Loop through each category and get the rating for review_1\n",
    "for category in categories:\n",
    "    rating = get_rating(review_1, category)\n",
    "    print(f\"Rating for {category}: {rating}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New restaurant\n",
      "Rating for food: 4\n",
      "Rating for service: 5\n",
      "Rating for atmosphere: 5\n",
      "New restaurant\n",
      "Rating for food: 5\n",
      "Rating for service: 5\n",
      "Rating for atmosphere: 5\n",
      "New restaurant\n",
      "Rating for food: 5\n",
      "Rating for service: 5\n",
      "Rating for atmosphere: 4\n",
      "New restaurant\n",
      "Rating for food: 3\n",
      "Rating for service: 5\n",
      "Rating for atmosphere: 4\n",
      "New restaurant\n",
      "Rating for food: 5\n",
      "Rating for service: 4\n",
      "Rating for atmosphere: 2\n"
     ]
    }
   ],
   "source": [
    "### all categories in one and looping through restaurants\n",
    "# Loop through each category and get the rating for reviews\n",
    "for review in test_dataset['review_text'][:5]:\n",
    "    print(\"New restaurant\")\n",
    "    for category in categories:\n",
    "        rating = get_rating(review, category)\n",
    "        print(f\"Rating for {category}: {rating}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rating(review_text: str, category: str) -> int:\n",
    "    \"\"\"\n",
    "    Given a review text and a category, return a rating from 1 to 5.\n",
    "    Categories: 'food', 'service', 'atmosphere'.\n",
    "    \"\"\"\n",
    "    # Define prompts for different categories\n",
    "    prompts = {\n",
    "        'food': \"Based on the following review, rate the food quality on a scale from 1 (very bad) to 5 (very good):\\n\\nReview: {review_text}\\n\\nPlease only provide a numeric rating from 1 to 5 without any additional text:\",\n",
    "        'service': \"Based on the following review, rate the service quality on a scale from 1 (very bad) to 5 (very good):\\n\\nReview: {review_text}\\n\\nPlease only provide a numeric rating from 1 to 5 without any additional text:\",\n",
    "        'atmosphere': \"Based on the following review, rate the atmosphere quality on a scale from 1 (very bad) to 5 (very good):\\n\\nReview: {review_text}\\n\\nPlease only provide a numeric rating from 1 to 5 without any additional text:\"\n",
    "    }\n",
    "\n",
    "    # Get the appropriate prompt for the category\n",
    "    prompt = prompts.get(category, \"\").format(review_text=review_text)\n",
    "    \n",
    "    # Tokenize the input and set the pad_token_id explicitly\n",
    "    inputs = tokenizer(\n",
    "        prompt, \n",
    "        return_tensors=\"pt\"  # Explicitly set the pad_token_id here\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    # Check if pad_token is None, if so, use eos_token as pad_token (by default LLama 3.1 padding token None)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token  # Use EOS token as padding\n",
    "\n",
    "    # Generate the response, explicitly set pad_token_id during generation\n",
    "    outputs = quantized_model.generate(\n",
    "        **inputs, \n",
    "        max_new_tokens=2, \n",
    "        temperature=0.7, \n",
    "        pad_token_id=tokenizer.convert_tokens_to_ids(tokenizer.pad_token)  # Explicitly setting pad_token_id during generation\n",
    "    )\n",
    "\n",
    "    generated_text = tokenizer.decode(outputs[0][inputs['input_ids'].shape[-1]:], skip_special_tokens=True)\n",
    "\n",
    "    try:\n",
    "        # Ensure the output is a numeric value\n",
    "        rating = int(generated_text.strip())\n",
    "        return rating\n",
    "    except ValueError:\n",
    "        # Fallback if the output is not a valid integer\n",
    "        return None\n",
    "\n",
    "# Initialize lists to store ratings and true ratings\n",
    "predicted_food_ratings = []\n",
    "predicted_service_ratings = []\n",
    "predicted_atmosphere_ratings = []\n",
    "true_food_ratings = test_dataset['dining_stars_food']\n",
    "true_service_ratings = test_dataset['dining_stars_service']\n",
    "true_atmosphere_ratings = test_dataset['dining_stars_atmosphere']\n",
    "\n",
    "batch_size = 65  # adjust the batch size depending on your GPU memory\n",
    "for i in tqdm(range(0, len(test_dataset['review_text']), batch_size), desc=\"Rating reviews\"):\n",
    "    batch_reviews = test_dataset['review_text'][i:i+batch_size]\n",
    "    \n",
    "    # For each batch, generate ratings for food, service, and atmosphere\n",
    "    for review_text in batch_reviews:\n",
    "        # Initialize ratings for each category\n",
    "        food_rating = get_rating(review_text, 'food')\n",
    "        service_rating = get_rating(review_text, 'service')\n",
    "        atmosphere_rating = get_rating(review_text, 'atmosphere')\n",
    "        \n",
    "        # Append the generated ratings to the lists\n",
    "        predicted_food_ratings.append(food_rating)\n",
    "        predicted_service_ratings.append(service_rating)\n",
    "        predicted_atmosphere_ratings.append(atmosphere_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 5, 5, 5, 3, 5, 5, 4, 4, 5, 5, 5, 5, 2, 4, 2, 5, 5, 3, 5, 5, 3, 4, 4, 5, 3, 5, 5, 5, 5, 5, 2, 5, 5, 4, 4, 5, 5, 4, 5, 4, 5, 4, 4, 4, 2, 5, 2, 1, 5, 3, 5, 4, 5, 4, 5, 4, 5, 5, 5, 4, 4, 5, 2, 4, 5, 5, 5, 5, 4, 4, 5, 5, 4, 5, 5, 5, 5, 4, 5, 5, 4, 4, 5, 4, 1, 5, 5, 3, 2, 5, 5, 4, 5, 4, 4, 5, 3, 5, 4, 4, 5, 5, 5, 4, 2, 5, 5, 4, 5, 4, 4, 5, 5, 2, 3, 2, 5, 5, 3, 4, 4, 5, 2, 3, 4, 4, 5, 5, 5, 4, 5, 2, 5, 5, 5, 4, 5, 5, 4, 4, 3, 4, 2, 4, 4, 2, 5, 1, 1, 5, 3, 5, 4, 5, 4, 5, 4, 5, 5, 5, 5, 4, 5, 1, 2, 5, 4, 5, 5, 5, 4, 5, 5, 4, 5, 5, 5, 5, 4, 5, 5, 4, 5, 5, 4, 1, 5, 5, 4, 1, 5, 5, 2, 5, 5, 4, 4, 2, 4, 5, 4, 5, 4, 3, 4, 5, 4, 5, 4, 2, 4, 4, 5, 4, 2, 4, 4, 5, 5, 5, 5, 5, 4]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_atmosphere_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 5, 5, 5, 4, 5, 5, 4, 5, 4, 5, 5, 5, 2, 5, 2, 5, 5, 4, 5, 4, 5, 4, 5, 5, 4, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 4, 4, 4, 5, 3, 4, 5, 2, 5, 1, 1, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 4, 5, 5, 4, 4, 5, 5, 2, 5, 5, 4, 2, 5, 5, 3, 5, 5, 5, 5, 3, 5, 5, 4, 5, 5, 5, 5, 4, 5, 5, 4, 5, 4, 5, 5, 5, 2, 5, 3, 4, 5, 4, 4, 4, 4, 3, 5, 5, 3, 5, 5, 5, 5, 5, 2, 5, 5, 4, 4, 5, 5, 4, 5, 4, 5, 4, 5, 5, 2, 5, 2, 1, 5, 3, 5, 5, 5, 4, 5, 4, 5, 5, 4, 5, 5, 5, 2, 2, 5, 5, 5, 5, 5, 4, 5, 5, 4, 5, 5, 5, 5, 4, 5, 5, 4, 5, 5, 5, 2, 5, 4, 4, 2, 5, 5, 3, 5, 5, 5, 5, 3, 5, 4, 4, 5, 4, 4, 5, 5, 5, 5, 4, 2, 4, 5, 5, 5, 2, 5, 3, 5, 5, 4, 5, 5, 4]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_service_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Food rating accuracy: 67.23%\n",
      "Service rating accuracy: 68.07%\n",
      "Atmosphere rating accuracy: 52.10%\n",
      "Food rating MAE: 0.40\n",
      "Service rating MAE: 0.39\n",
      "Atmosphere rating MAE: 0.57\n"
     ]
    }
   ],
   "source": [
    "# Now compare the predicted ratings with the true ratings\n",
    "def compare_ratings(true_ratings, predicted_ratings):\n",
    "    \"\"\"\n",
    "    Compare true and predicted ratings and compute performance metrics.\n",
    "    \"\"\"\n",
    "    correct_predictions = sum([1 for true, pred in zip(true_ratings, predicted_ratings) if true == pred])\n",
    "    accuracy = correct_predictions / len(true_ratings) * 100\n",
    "    return accuracy\n",
    "\n",
    "# Compare the predicted ratings with the true ratings\n",
    "food_accuracy = compare_ratings(true_food_ratings, predicted_food_ratings)\n",
    "service_accuracy = compare_ratings(true_service_ratings, predicted_service_ratings)\n",
    "atmosphere_accuracy = compare_ratings(true_atmosphere_ratings, predicted_atmosphere_ratings)\n",
    "\n",
    "print(f\"Food rating accuracy: {food_accuracy:.2f}%\")\n",
    "print(f\"Service rating accuracy: {service_accuracy:.2f}%\")\n",
    "print(f\"Atmosphere rating accuracy: {atmosphere_accuracy:.2f}%\")\n",
    "\n",
    "def calculate_mae(true_ratings, predicted_ratings):\n",
    "    \"\"\"\n",
    "    Compute the Mean Absolute Error (MAE) between true and predicted ratings.\n",
    "    \"\"\"\n",
    "    mae = sum(abs(true - pred) for true, pred in zip(true_ratings, predicted_ratings)) / len(true_ratings)\n",
    "    return mae\n",
    "\n",
    "# Compute MAE for each category\n",
    "food_mae = calculate_mae(true_food_ratings, predicted_food_ratings)\n",
    "service_mae = calculate_mae(true_service_ratings, predicted_service_ratings)\n",
    "atmosphere_mae = calculate_mae(true_atmosphere_ratings, predicted_atmosphere_ratings)\n",
    "\n",
    "print(f\"Food rating MAE: {food_mae:.2f}\")\n",
    "print(f\"Service rating MAE: {service_mae:.2f}\")\n",
    "print(f\"Atmosphere rating MAE: {atmosphere_mae:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama 3.1 70B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-shot classification \n",
    "https://huggingface.co/docs/transformers/v4.48.0/en/main_classes/pipelines#transformers.ZeroShotClassificationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484,
     "referenced_widgets": [
      "73b2960179ae40daa46bb1dea2551080",
      "a1f9f92c249e4e6a96ef60074bddfc04",
      "327c05b0155b42f38061122bc16c5e50",
      "e4fe3eab8c3044ea8fe1e02d69125492",
      "7dbd8e3ad5bf4252a9cfc2b505b32fa2",
      "8f6b881af8294dacbccbddd1d8c53be0",
      "19a699d80d1c4233970826f3ea2fde34",
      "91cba1cd42dd436a848aaa912756d36c",
      "a138cb49ea804529b462f40bb1ec1af8",
      "aaeadd9b686c49f7aa2f54ecbeecdfea",
      "099b20ed821c40c3911a76c663daa7b2",
      "24ce5ca3e5524181b78cae7237614eda",
      "7439c11284b44c56bea1123781c97d90",
      "0e03999ca54b4ef5b46d379ef0141c7b",
      "28e4119d09894c53bc97a83efc898d48",
      "6749dfa47a3441d5b16690dec4f816f0",
      "3432a4e55e6348a0baafe4c1ad0b5952",
      "43b1588cf28247bcad8e5e78f9710bb5",
      "a3990f4831a14dad838d6ebeaafb9e72",
      "e36c9513168f4b32b0c6edb0f280b18a",
      "79f24ab6897140a6b06e1bf334b0352d",
      "5234b3e43e2b4fcebf1d397b1e5f98c4",
      "323161c342a84e2db638dd772daa17f5",
      "a0a020f2ebb5444a9821f65f7e31b220",
      "e08c7c75f7154da6887cdc30f7c188a1",
      "269ab6a0eb104a46b413c2e8259c0bf0",
      "b87ee5abe1fd44c1a566e83274355863",
      "3668246921d84969ab877c7b473c0d33",
      "73b8f74c5b884053804b87104f613868",
      "e843f87a95c44b61b841bbc4691222e1",
      "b016686e506143c3ac6c43a858c429f3",
      "5ab60fff4219468eb90d6b28b579da16",
      "b7e98040e8b2496f9af2a0f7bb9fbfb9",
      "0a671424bb654d3190564714ff784ab9",
      "f393910623374e07b041b203364d2c81",
      "eb5d974e1dcc4e8cb7c022c5abb66782",
      "b607c62d8c0547c2ae55131e95e9df7f",
      "4067165cb6224763af3317082e99ba7a",
      "ef8f609a18884779ba2a672f92050415",
      "2efe232b648e43aaaeb1d50d53a4d4d3",
      "91911dafb3ed41528bcb9eac0a8bb265",
      "3bd7d596bab44f3299a3cfef64baf3db",
      "c98199ddb6094335aa8b0f7fac2e47d7",
      "c6beac62ed1542a08b67a9083f7e589a"
     ]
    },
    "id": "eJGCRCz8Rlpe",
    "outputId": "84cc40d4-6907-41ae-e59b-699b991a6ea3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c96314d1e9094f9a86e7a0093622ed6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4df98b1375c46fdbf7a20737543f1da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00024-of-00030.safetensors:  11%|#1        | 556M/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "496cbc73971f40168abd7b9ce95cd404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00025-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b84fbc29ad5b4702845e0fc1c796a18d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00026-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a38e824a244f5d90a65646612df07e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00027-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aa70a7c94df4d178b21071809d42fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00028-of-00030.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "847d1690b89846428fa8ef2e423477ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00029-of-00030.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d1660c2ed954468bf6211a71d4ed3b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00030-of-00030.safetensors:   0%|          | 0.00/2.10G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3348e87455c45e49788e6540d89a84a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.1-70B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b033755c50491fa5ff3d9e8be4aa26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/50.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "174201842eb74b87a762b0248af14f2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5747ea0fc2d478db5a0e7e1684150b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/301 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "model_id = \"meta-llama/Llama-3.1-70B\"\n",
    "\n",
    "pipe = pipeline(task=\"zero-shot-classification\",\n",
    "                model=model_id,\n",
    "                torch_dtype=torch.bfloat16,\n",
    "                device_map=\"auto\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "S2heigWbSS6r"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'review_id': 109467, 'dining_stars_food': 1.0, 'dining_stars_service': 1.0, 'dining_stars_atmosphere': 1.0, 'review_text': 'Hackfleischdrehspiess, dessen Abschnitt im Warmhaltebehälter aufbewahrt wird. Brot aus dem Grosshandel und unfreundlicher Service'}\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hackfleischdrehspiess, dessen Abschnitt im Warmhaltebehälter aufbewahrt wird. Brot aus dem Grosshandel und unfreundlicher Service\n"
     ]
    }
   ],
   "source": [
    "print(review_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your candidate labels (ratings)\n",
    "#candidate_labels = [\"1\", \"2\", \"3\", \"4\", \"5\"]\n",
    "candidate_labels = [\"very bad\", \"bad\", \"neutral\", \"good\", \"very good\"]\n",
    "\n",
    "hypothesis_template = \"The food quality is {}.\"\n",
    "\n",
    "result = pipe(\n",
    "    sequences=review_1,\n",
    "    candidate_labels=candidate_labels,\n",
    "    hypothesis_template=hypothesis_template\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hackfleischdrehspiess, dessen Abschnitt im Warmhaltebehälter aufbewahrt wird. Brot aus dem Grosshandel und unfreundlicher Service\n",
      "1.0\n",
      "{'sequence': 'Hackfleischdrehspiess, dessen Abschnitt im Warmhaltebehälter aufbewahrt wird. Brot aus dem Grosshandel und unfreundlicher Service', 'labels': ['neutral', 'good', 'very good', 'very bad', 'bad'], 'scores': [0.32081472873687744, 0.20392225682735443, 0.1827947348356247, 0.1638561189174652, 0.12861214578151703]}\n",
      "Am Freitagabend, ohne Reservierung, kurz vor dem Verhungern, erscheine ich zusammen mit einem Freund 😄. Chef und Personal waren super nett und haben es geschafft für uns ein Tisch zu finden.\n",
      "Kurze Zusammenfassung: Essen, Getränke, Service, Ambiente sind top.\n",
      "5.0\n",
      "{'sequence': 'Am Freitagabend, ohne Reservierung, kurz vor dem Verhungern, erscheine ich zusammen mit einem Freund 😄. Chef und Personal waren super nett und haben es geschafft für uns ein Tisch zu finden.\\nKurze Zusammenfassung: Essen, Getränke, Service, Ambiente sind top.', 'labels': ['neutral', 'good', 'very bad', 'very good', 'bad'], 'scores': [0.4506005644798279, 0.24118904769420624, 0.10702700912952423, 0.10373413562774658, 0.09744919836521149]}\n",
      "A very mixed bag. After we ordered a 4 course menu, we had to wait for over a hour for the first dish, despite restaurant having very few guests.\n",
      "\n",
      "The dish was fine, nothing really special. After that we had to wait another 40 min for the second and another 30 for the third, forth only took 25. The ambience was nice, but we been not overly excited waiting for couple of hours for our food, which was just ok.  Out of 4 courses only one was really good, rest was something you could get in any ordinary  european low - mid price restaurant , just less nicely arranged on the plate.\n",
      "\n",
      "We felt like Caros is trying to bite more of than they can chew. It tries to be higher class restaurant which is reflected by the high prices and the nice arrangements of the dishes. Most of the food served was really nothing special and the service with abysmal wait times is a no go. Maybe we have been unlucky with the menu and the service speed that day, but it sure didn't feel right leaving over 150 eur there.\n",
      "\n",
      "Maybe we pay them another visit one day, but for now I feel like you will have far more fun in much cheaper Krumme Bruecke nearby or in Stern.\n",
      "3.0\n",
      "{'sequence': \"A very mixed bag. After we ordered a 4 course menu, we had to wait for over a hour for the first dish, despite restaurant having very few guests.\\n\\nThe dish was fine, nothing really special. After that we had to wait another 40 min for the second and another 30 for the third, forth only took 25. The ambience was nice, but we been not overly excited waiting for couple of hours for our food, which was just ok.  Out of 4 courses only one was really good, rest was something you could get in any ordinary  european low - mid price restaurant , just less nicely arranged on the plate.\\n\\nWe felt like Caros is trying to bite more of than they can chew. It tries to be higher class restaurant which is reflected by the high prices and the nice arrangements of the dishes. Most of the food served was really nothing special and the service with abysmal wait times is a no go. Maybe we have been unlucky with the menu and the service speed that day, but it sure didn't feel right leaving over 150 eur there.\\n\\nMaybe we pay them another visit one day, but for now I feel like you will have far more fun in much cheaper Krumme Bruecke nearby or in Stern.\", 'labels': ['neutral', 'bad', 'good', 'very good', 'very bad'], 'scores': [0.2730967402458191, 0.216037318110466, 0.1967042237520218, 0.1967042237520218, 0.11745746433734894]}\n",
      "Die Stimmung war sehr gut und der Service war super. Die Pizza schmeckt auch gut. Ich mag die online Bestellen nicht so gern, aber die Leute war sehr hilfreich und nett.\n",
      "4.0\n",
      "{'sequence': 'Die Stimmung war sehr gut und der Service war super. Die Pizza schmeckt auch gut. Ich mag die online Bestellen nicht so gern, aber die Leute war sehr hilfreich und nett.', 'labels': ['neutral', 'very bad', 'very good', 'good', 'bad'], 'scores': [0.28462696075439453, 0.26738229393959045, 0.17263497412204742, 0.16732355952262878, 0.1080322116613388]}\n",
      "Mein Essen (Seafood) war leider ziemlich versalzen, das Essen meiner Kollegen war allerdings okay, wenn auch nichts besonderes (ich beziehe die 2 Punkte für das Essen auf mein Gericht). Der Kellner nimmt alles richtig auf und bringt es irgendwann, dann wird man aber komplett allein gelassen und man muss richtig auf sich aufmerksam machen, wenn man zahlen will.\n",
      "2.0\n",
      "{'sequence': 'Mein Essen (Seafood) war leider ziemlich versalzen, das Essen meiner Kollegen war allerdings okay, wenn auch nichts besonderes (ich beziehe die 2 Punkte für das Essen auf mein Gericht). Der Kellner nimmt alles richtig auf und bringt es irgendwann, dann wird man aber komplett allein gelassen und man muss richtig auf sich aufmerksam machen, wenn man zahlen will.', 'labels': ['very good', 'good', 'very bad', 'neutral', 'bad'], 'scores': [0.407515287399292, 0.29931142926216125, 0.11675507575273514, 0.11584647744894028, 0.06057173013687134]}\n",
      "Hochwertige, qualitative Produkte, schön persentiert und hervorragende abgeschmeckt!:) Uns hat der Besuch in Caro's Restaurant sehr gefallen ! Weiterzuempfehlen!:)\n",
      "5.0\n",
      "{'sequence': \"Hochwertige, qualitative Produkte, schön persentiert und hervorragende abgeschmeckt!:) Uns hat der Besuch in Caro's Restaurant sehr gefallen ! Weiterzuempfehlen!:)\", 'labels': ['very bad', 'neutral', 'bad', 'very good', 'good'], 'scores': [0.38001468777656555, 0.31015893816947937, 0.2002536505460739, 0.0736692026257515, 0.03590350225567818]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ein wundervolles Restaurant mitten in der Altstadt von Tübingen gelegen. Plätze sowohl draußen,  als auch drinnen .\n",
      "\n",
      "Sehr gute Auswahl an typisch schwäbischen Gerichten, aber auch Mainstream.\n",
      "\n",
      "Sehr leckeres Essen, vom extrem aufmerksamen und jederzeit freundlichen Personal serviert.\n",
      "\n",
      "Wir haben uns rund um wohlgefühlt und kommen gerne wieder.\n",
      "5.0\n",
      "{'sequence': 'Ein wundervolles Restaurant mitten in der Altstadt von Tübingen gelegen. Plätze sowohl draußen,  als auch drinnen .\\n\\nSehr gute Auswahl an typisch schwäbischen Gerichten, aber auch Mainstream.\\n\\nSehr leckeres Essen, vom extrem aufmerksamen und jederzeit freundlichen Personal serviert.\\n\\nWir haben uns rund um wohlgefühlt und kommen gerne wieder.', 'labels': ['neutral', 'good', 'very good', 'bad', 'very bad'], 'scores': [0.43066442012786865, 0.18814337253570557, 0.15117743611335754, 0.12930890917778015, 0.10070587694644928]}\n",
      "Tolles Restaurant und gutes Essen. Wir haben Pad Thai Gung und Ped Pad Gaprau (gebratene Ente mit Basilikum) bestellt, die wirklich sehr lecker waren. Die Dekoration des Restaurants war schön und der Service war schnell und prompt. Das Servicepersonal war freundlich. Außerdem waren die Preise für die Speisen angemessen und passten zur Portion. Es wäre empfehlenswert, im Voraus zu reservieren, da die Tische meist voll sind.\n",
      "5.0\n",
      "{'sequence': 'Tolles Restaurant und gutes Essen. Wir haben Pad Thai Gung und Ped Pad Gaprau (gebratene Ente mit Basilikum) bestellt, die wirklich sehr lecker waren. Die Dekoration des Restaurants war schön und der Service war schnell und prompt. Das Servicepersonal war freundlich. Außerdem waren die Preise für die Speisen angemessen und passten zur Portion. Es wäre empfehlenswert, im Voraus zu reservieren, da die Tische meist voll sind.', 'labels': ['good', 'very bad', 'very good', 'bad', 'neutral'], 'scores': [0.321877121925354, 0.22824503481388092, 0.21441639959812164, 0.13417835533618927, 0.10128314048051834]}\n",
      "Wir sind durch den Schlemmerblock auf das Gasthaus gekommen. Wir kommen wieder. Essen top, super lecker, sehr gute Qualität… ein echter Geheimtipp. Ambiente ist halt ein Clubhaus aber dafür Preis/Leistung top und super lecker…\n",
      "5.0\n",
      "{'sequence': 'Wir sind durch den Schlemmerblock auf das Gasthaus gekommen. Wir kommen wieder. Essen top, super lecker, sehr gute Qualität… ein echter Geheimtipp. Ambiente ist halt ein Clubhaus aber dafür Preis/Leistung top und super lecker…', 'labels': ['neutral', 'good', 'very good', 'very bad', 'bad'], 'scores': [0.3089885115623474, 0.22606082260608673, 0.19336006045341492, 0.1505889892578125, 0.12100163847208023]}\n",
      "Feiner Flammkuchen mit Rotwein in einem eigenwilligen, aber sehr gemütlichen Ambiente - wir haben uns sehr wohl gefühlt! Vielen Dank an den sympathischen Chef.\n",
      "5.0\n",
      "{'sequence': 'Feiner Flammkuchen mit Rotwein in einem eigenwilligen, aber sehr gemütlichen Ambiente - wir haben uns sehr wohl gefühlt! Vielen Dank an den sympathischen Chef.', 'labels': ['neutral', 'good', 'very good', 'very bad', 'bad'], 'scores': [0.4739338755607605, 0.1945020705461502, 0.12171627581119537, 0.11797146499156952, 0.09187626093626022]}\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    review = test_dataset['review_text'][i]\n",
    "    print(review)\n",
    "    print(test_dataset['dining_stars_food'][i])\n",
    "    result = pipe(\n",
    "        sequences = review,\n",
    "        candidate_labels=candidate_labels,\n",
    "        hypothesis_template=hypothesis_template\n",
    "    )\n",
    "    print(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neutral always received the highest score\n",
    "--> not usueful for our case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1c9061ea5e349d2bd0473f20f796351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"meta-llama/Llama-3.1-70B-Instruct\"\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True,\n",
    "                                         bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "                                         bnb_4bit_use_double_quant=True,\n",
    "                                         bnb_4bit_quant_type= \"nf4\"\n",
    "                                         )\n",
    "\n",
    "quantized_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, device_map=\"auto\", torch_dtype=torch.bfloat16, quantization_config=quantization_config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rating reviews: 100%|██████████| 2/2 [16:39<00:00, 499.55s/it]\n"
     ]
    }
   ],
   "source": [
    "def get_rating(review_text: str, category: str) -> int:\n",
    "    \"\"\"\n",
    "    Given a review text and a category, return a rating from 1 to 5.\n",
    "    Categories: 'food', 'service', 'atmosphere'.\n",
    "    \"\"\"\n",
    "    # Define prompts for different categories\n",
    "    prompts = {\n",
    "        'food': \"Based on the following review, rate the food quality on a scale from 1 (very bad) to 5 (very good):\\n\\nReview: {review_text}\\n\\nPlease only provide a numeric rating from 1 to 5 without any additional text:\",\n",
    "        'service': \"Based on the following review, rate the service quality on a scale from 1 (very bad) to 5 (very good):\\n\\nReview: {review_text}\\n\\nPlease only provide a numeric rating from 1 to 5 without any additional text:\",\n",
    "        'atmosphere': \"Based on the following review, rate the atmosphere quality on a scale from 1 (very bad) to 5 (very good):\\n\\nReview: {review_text}\\n\\nPlease only provide a numeric rating from 1 to 5 without any additional text:\"\n",
    "    }\n",
    "\n",
    "    # Get the appropriate prompt for the category\n",
    "    prompt = prompts.get(category, \"\").format(review_text=review_text)\n",
    "    \n",
    "    # Tokenize the input and set the pad_token_id explicitly\n",
    "    inputs = tokenizer(\n",
    "        prompt, \n",
    "        return_tensors=\"pt\"  # Explicitly set the pad_token_id here\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    # Check if pad_token is None, if so, use eos_token as pad_token (by default LLama 3.1 padding token None)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token  # Use EOS token as padding\n",
    "\n",
    "    # Generate the response, explicitly set pad_token_id during generation\n",
    "    outputs = quantized_model.generate(\n",
    "        **inputs, \n",
    "        max_new_tokens=2, \n",
    "        temperature=0.7, \n",
    "        pad_token_id=tokenizer.convert_tokens_to_ids(tokenizer.pad_token)  # Explicitly setting pad_token_id during generation\n",
    "    )\n",
    "\n",
    "    generated_text = tokenizer.decode(outputs[0][inputs['input_ids'].shape[-1]:], skip_special_tokens=True)\n",
    "\n",
    "    try:\n",
    "        # Ensure the output is a numeric value\n",
    "        rating = int(generated_text.strip())\n",
    "        return rating\n",
    "    except ValueError:\n",
    "        # Fallback if the output is not a valid integer\n",
    "        return None\n",
    "\n",
    "# Initialize lists to store ratings and true ratings\n",
    "predicted_food_ratings = []\n",
    "predicted_service_ratings = []\n",
    "predicted_atmosphere_ratings = []\n",
    "true_food_ratings = test_dataset['dining_stars_food']\n",
    "true_service_ratings = test_dataset['dining_stars_service']\n",
    "true_atmosphere_ratings = test_dataset['dining_stars_atmosphere']\n",
    "\n",
    "batch_size = 65  # adjust the batch size depending on your GPU memory\n",
    "for i in tqdm(range(0, len(test_dataset['review_text']), batch_size), desc=\"Rating reviews\"):\n",
    "    batch_reviews = test_dataset['review_text'][i:i+batch_size]\n",
    "    \n",
    "    # For each batch, generate ratings for food, service, and atmosphere\n",
    "    for review_text in batch_reviews:\n",
    "        # Initialize ratings for each category\n",
    "        food_rating = get_rating(review_text, 'food')\n",
    "        service_rating = get_rating(review_text, 'service')\n",
    "        atmosphere_rating = get_rating(review_text, 'atmosphere')\n",
    "        \n",
    "        # Append the generated ratings to the lists\n",
    "        predicted_food_ratings.append(food_rating)\n",
    "        predicted_service_ratings.append(service_rating)\n",
    "        predicted_atmosphere_ratings.append(atmosphere_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_food_ratings = test_dataset['dining_stars_food']\n",
    "true_service_ratings = test_dataset['dining_stars_service']\n",
    "true_atmosphere_ratings = test_dataset['dining_stars_atmosphere']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only to handle 'None' for the MAE\n",
    "predicted_food_ratings = [0 if x is None else x for x in predicted_food_ratings]\n",
    "predicted_service_ratings = [0 if x is None else x for x in predicted_service_ratings]\n",
    "predicted_atmosphere_ratings = [0 if x is None else x for x in predicted_atmosphere_ratings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Food rating accuracy: 62.18%\n",
      "Service rating accuracy: 72.27%\n",
      "Atmosphere rating accuracy: 53.78%\n",
      "Food rating MAE: 0.66\n",
      "Service rating MAE: 0.37\n",
      "Atmosphere rating MAE: 0.63\n"
     ]
    }
   ],
   "source": [
    "# Now compare the predicted ratings with the true ratings\n",
    "def compare_ratings(true_ratings, predicted_ratings):\n",
    "    \"\"\"\n",
    "    Compare true and predicted ratings and compute performance metrics.\n",
    "    \"\"\"\n",
    "    correct_predictions = sum([1 for true, pred in zip(true_ratings, predicted_ratings) if true == pred])\n",
    "    accuracy = correct_predictions / len(true_ratings) * 100\n",
    "    return accuracy\n",
    "\n",
    "# Compare the predicted ratings with the true ratings\n",
    "food_accuracy = compare_ratings(true_food_ratings, predicted_food_ratings)\n",
    "service_accuracy = compare_ratings(true_service_ratings, predicted_service_ratings)\n",
    "atmosphere_accuracy = compare_ratings(true_atmosphere_ratings, predicted_atmosphere_ratings)\n",
    "\n",
    "print(f\"Food rating accuracy: {food_accuracy:.2f}%\")\n",
    "print(f\"Service rating accuracy: {service_accuracy:.2f}%\")\n",
    "print(f\"Atmosphere rating accuracy: {atmosphere_accuracy:.2f}%\")\n",
    "\n",
    "def calculate_mae(true_ratings, predicted_ratings):\n",
    "    \"\"\"\n",
    "    Compute the Mean Absolute Error (MAE) between true and predicted ratings.\n",
    "    \"\"\"\n",
    "    mae = sum(abs(true - pred) for true, pred in zip(true_ratings, predicted_ratings)) / len(true_ratings)\n",
    "    return mae\n",
    "\n",
    "# Compute MAE for each category\n",
    "food_mae = calculate_mae(true_food_ratings, predicted_food_ratings)\n",
    "service_mae = calculate_mae(true_service_ratings, predicted_service_ratings)\n",
    "atmosphere_mae = calculate_mae(true_atmosphere_ratings, predicted_atmosphere_ratings)\n",
    "\n",
    "print(f\"Food rating MAE: {food_mae:.2f}\")\n",
    "print(f\"Service rating MAE: {service_mae:.2f}\")\n",
    "print(f\"Atmosphere rating MAE: {atmosphere_mae:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Llama models performance on 1. Task\n",
    "**LLama 3.2 3B**\n",
    "Food rating accuracy: 26.89%\n",
    "Service rating accuracy: 31.93%\n",
    "Atmosphere rating accuracy: 27.73%\n",
    "Food rating MAE: 0.86\n",
    "Service rating MAE: 0.82\n",
    "Atmosphere rating MAE: 0.84\n",
    "\n",
    "**LLama 3.1 8B**\n",
    "Food rating accuracy: 67.23%\n",
    "Service rating accuracy: 68.07%\n",
    "Atmosphere rating accuracy: 52.10%\n",
    "Food rating MAE: 0.40\n",
    "Service rating MAE: 0.39\n",
    "Atmosphere rating MAE: 0.57\n",
    "\n",
    "**LLama 3.2 70 B**\n",
    "Food rating accuracy: 62.18%\n",
    "Service rating accuracy: 72.27%\n",
    "Atmosphere rating accuracy: 53.78%\n",
    "Food rating MAE: 0.66\n",
    "Service rating MAE: 0.37\n",
    "Atmosphere rating MAE: 0.63\n",
    "\n",
    "\n",
    "--> With the same prompt construct Llama 3.1 8B performed best since it did not create 'None' in their prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Fine-tuning\n",
    "https://github.com/huggingface/huggingface-llama-recipes/blob/main/fine_tune/peft_finetuning.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Topic recognition\n",
    "## Notizen\n",
    "70B modell war viel besser als 3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_sentences_multi_label(review_text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Categorize sentences from the review into 'food', 'service', and 'atmosphere'.\n",
    "    Allows sentences to belong to multiple categories.\n",
    "    \"\"\"\n",
    "    # Define the multi-label prompt\n",
    "    prompt_template = (\n",
    "        \"For the following sentence, identify all applicable categories: \"\n",
    "        \"'food', 'service', 'atmosphere'. If no category applies, respond 'none'. \"\n",
    "        \"Separate multiple categories with commas.\\n\\n\"\n",
    "        \"Sentence: {sentence}\\n\\n\"\n",
    "        \"Categories:\"\n",
    "    )\n",
    "    \n",
    "    # Split review into sentences\n",
    "    sentences = review_text.split('. ')\n",
    "    \n",
    "    # Initialize result dictionary\n",
    "    categorized_sentences = {'food': [], 'service': [], 'atmosphere': []}\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        prompt = prompt_template.format(sentence=sentence.strip())\n",
    "        \n",
    "        # Tokenize the input and ensure padding token is set\n",
    "        if tokenizer.pad_token is None:\n",
    "            tokenizer.pad_token = tokenizer.eos_token  # Use EOS token as pad token\n",
    "        \n",
    "        inputs = tokenizer(\n",
    "            prompt,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512\n",
    "        ).to(\"cuda\")\n",
    "\n",
    "        # Generate category predictions\n",
    "        outputs = quantized_model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=10,\n",
    "            temperature=0.7,\n",
    "            pad_token_id=tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "        )\n",
    "\n",
    "        # Decode and parse the model's response\n",
    "        generated_text = tokenizer.decode(outputs[0][inputs['input_ids'].shape[-1]:], skip_special_tokens=True).strip().lower()\n",
    "        predicted_categories = [cat.strip() for cat in generated_text.split(',') if cat.strip() in categorized_sentences]\n",
    "\n",
    "        # Add the sentence to all relevant categories\n",
    "        for category in predicted_categories:\n",
    "            categorized_sentences[category].append(sentence.strip())\n",
    "    \n",
    "    return categorized_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Llama 3.1 8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: Tolles Restaurant mit typisch badischen Gerichten. Sehr freundliche und liebenswerte Wirtsleute. Die Einrichtung ist traditionell mit warmem Ofen. Auch Sonderwünsche werden nach Möglichkeit erfüllt. Immer ein Besuch wert. Egal ob im Sommer draußen oder mit einer größeren Gruppe im Nebenraum,  oder zu einem gemütlichen Essen zu zweit.\n",
      "Categorized Sentences:\n",
      "Food: ['Egal ob im Sommer draußen oder mit einer größeren Gruppe im Nebenraum,  oder zu einem gemütlichen Essen zu zweit.']\n",
      "Service: []\n",
      "Atmosphere: []\n",
      "Original text: Restaurant très sympathique !\n",
      "Cuisine excellente, rapport qualité prix vraiment excellent.\n",
      "En plus le personnel est commerçant et offre le digestif pour une table de 6\n",
      "Une très bonne adresse ! A recommander\n",
      "Categorized Sentences:\n",
      "Food: ['Restaurant très sympathique !\\nCuisine excellente, rapport qualité prix vraiment excellent.\\nEn plus le personnel est commerçant et offre le digestif pour une table de 6\\nUne très bonne adresse ! A recommander']\n",
      "Service: ['Restaurant très sympathique !\\nCuisine excellente, rapport qualité prix vraiment excellent.\\nEn plus le personnel est commerçant et offre le digestif pour une table de 6\\nUne très bonne adresse ! A recommander']\n",
      "Atmosphere: ['Restaurant très sympathique !\\nCuisine excellente, rapport qualité prix vraiment excellent.\\nEn plus le personnel est commerçant et offre le digestif pour une table de 6\\nUne très bonne adresse ! A recommander']\n",
      "Original text: Sehr leckeres Essen, ausgesprochen freundlich- und schneller Service!\n",
      "Abwechslungsreiche Karte mit Trends.\n",
      "Categorized Sentences:\n",
      "Food: []\n",
      "Service: []\n",
      "Atmosphere: []\n",
      "Original text: Very good staff\n",
      "Categorized Sentences:\n",
      "Food: []\n",
      "Service: []\n",
      "Atmosphere: []\n",
      "Original text: Sehr schönes dunkles Ambiente. Sehr groß. Freundliche Bedienung. Das Essen kam sehr schnell. Pizzen, Salat und Nachtisch waren sehr lecker. Die Toilette war grausam, da sollte mal jemand sich drum kümmern\n",
      "Categorized Sentences:\n",
      "Food: ['Pizzen, Salat und Nachtisch waren sehr lecker']\n",
      "Service: []\n",
      "Atmosphere: []\n",
      "Original text: Bestes chinesisches Essen in Tübingen und Umgebung! Hat auch immer gute Angebote, Service ist schnell und freundlich. Nur zu Empfehlen.\n",
      "Categorized Sentences:\n",
      "Food: ['Bestes chinesisches Essen in Tübingen und Umgebung! Hat auch immer gute Angebote, Service ist schnell und freundlich']\n",
      "Service: ['Bestes chinesisches Essen in Tübingen und Umgebung! Hat auch immer gute Angebote, Service ist schnell und freundlich']\n",
      "Atmosphere: []\n",
      "Original text: Das Gardens in Tübingen ist nicht das, was man von einem Restaurant am Tennisplatz erwarten würde. Hier findet man gehobene Gastronomie in geschmackvollem Ambiente und mit exzellentem Service. Chapeau!\n",
      "Categorized Sentences:\n",
      "Food: []\n",
      "Service: []\n",
      "Atmosphere: ['Hier findet man gehobene Gastronomie in geschmackvollem Ambiente und mit exzellentem Service']\n",
      "Original text: Essen ist super, aber etwas fertiger! Service ist super freundlich! Bei den selbstgemachten Nudeln könnte gerne noch ein bisschen mehr serviert werden, dann wäre es den Preis auch wert, aber ansonsten gibt's da auch nichts zum Aussetzen!\n",
      "Categorized Sentences:\n",
      "Food: [\"Essen ist super, aber etwas fertiger! Service ist super freundlich! Bei den selbstgemachten Nudeln könnte gerne noch ein bisschen mehr serviert werden, dann wäre es den Preis auch wert, aber ansonsten gibt's da auch nichts zum Aussetzen!\"]\n",
      "Service: [\"Essen ist super, aber etwas fertiger! Service ist super freundlich! Bei den selbstgemachten Nudeln könnte gerne noch ein bisschen mehr serviert werden, dann wäre es den Preis auch wert, aber ansonsten gibt's da auch nichts zum Aussetzen!\"]\n",
      "Atmosphere: [\"Essen ist super, aber etwas fertiger! Service ist super freundlich! Bei den selbstgemachten Nudeln könnte gerne noch ein bisschen mehr serviert werden, dann wäre es den Preis auch wert, aber ansonsten gibt's da auch nichts zum Aussetzen!\"]\n",
      "Original text: Biergarten sehr gemütlich. Essen ( Gyros )sehr gut. Bedienung klasse.\n",
      "Categorized Sentences:\n",
      "Food: []\n",
      "Service: []\n",
      "Atmosphere: []\n",
      "Original text: Ein ganz schöner Burgerladen mit reichlich Platz auch für größere Gruppen. Das Ambiente ist ziemlich gemütlich, der Service sehr gut und die Bedienung freundlich und aufmerksam. Bei den Speisen ist jedoch an manchen Stellen noch Verbesserungspotential vorhanden, beispielsweise bei der Garstufe der Steaks und Patties. Bei den Getränken gibt es nichts zu bemängeln.\n",
      "Categorized Sentences:\n",
      "Food: ['Bei den Speisen ist jedoch an manchen Stellen noch Verbesserungspotential vorhanden, beispielsweise bei der Garstufe der Steaks und Patties']\n",
      "Service: ['Das Ambiente ist ziemlich gemütlich, der Service sehr gut und die Bedienung freundlich und aufmerksam', 'Bei den Speisen ist jedoch an manchen Stellen noch Verbesserungspotential vorhanden, beispielsweise bei der Garstufe der Steaks und Patties']\n",
      "Atmosphere: ['Das Ambiente ist ziemlich gemütlich, der Service sehr gut und die Bedienung freundlich und aufmerksam']\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "for review in test_dataset['review_text'][:10]:\n",
    "    print(\"Original text:\", review)\n",
    "    categorized = categorize_sentences_multi_label(review)\n",
    "    print(\"Categorized Sentences:\")\n",
    "    for category, sentences in categorized.items():\n",
    "        print(f\"{category.capitalize()}: {sentences}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'food': ['Bei den Speisen ist jedoch an manchen Stellen noch Verbesserungspotential vorhanden, beispielsweise bei der Garstufe der Steaks und Patties'], 'service': ['Das Ambiente ist ziemlich gemütlich, der Service sehr gut und die Bedienung freundlich und aufmerksam', 'Bei den Speisen ist jedoch an manchen Stellen noch Verbesserungspotential vorhanden, beispielsweise bei der Garstufe der Steaks und Patties'], 'atmosphere': ['Das Ambiente ist ziemlich gemütlich, der Service sehr gut und die Bedienung freundlich und aufmerksam']}\n"
     ]
    }
   ],
   "source": [
    "print(categorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'original_review': 'Ein ganz schöner Burgerladen mit reichlich Platz auch für größere Gruppen. Das Ambiente ist ziemlich gemütlich, der Service sehr gut und die Bedienung freundlich und aufmerksam. Bei den Speisen ist jedoch an manchen Stellen noch Verbesserungspotential vorhanden, beispielsweise bei der Garstufe der Steaks und Patties. Bei den Getränken gibt es nichts zu bemängeln.', 'food_sentences': 'Ein ganz schöner Burgerladen mit reichlich Platz auch für größere Gruppen. Das Ambiente ist ziemlich gemütlich, der Service sehr gut und die Bedienung freundlich und aufmerksam. Bei den Speisen ist jedoch an manchen Stellen noch Verbesserungspotential vorhanden, beispielsweise bei der Garstufe der Steaks und Patties. Bei den Getränken gibt es nichts zu bemängeln.', 'service_sentences': 'Ein ganz schöner Burgerladen mit reichlich Platz auch für größere Gruppen. Das Ambiente ist ziemlich gemütlich, der Service sehr gut und die Bedienung freundlich und aufmerksam. Bei den Speisen ist jedoch an manchen Stellen noch Verbesserungspotential vorhanden, beispielsweise bei der Garstufe der Steaks und Patties. Bei den Getränken gibt es nichts zu bemängeln.', 'atmosphere_sentences': 'Bei den Getränken gibt es nichts zu bemängeln.'}\n"
     ]
    }
   ],
   "source": [
    "print(test_reviews_with_topics[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing reviews in batches: 100%|██████████| 2/2 [03:36<00:00, 108.48s/it]\n"
     ]
    }
   ],
   "source": [
    "# Create a dataset with the extracted columns\n",
    "test_reviews_with_topics = []\n",
    "\n",
    "# Set batch size depending on your GPU memory capacity\n",
    "batch_size = 64  # adjust based on GPU memory\n",
    "\n",
    "# Process the reviews in batches\n",
    "for i in tqdm(range(0, len(test_dataset['review_text']), batch_size), desc=\"Processing reviews in batches\"):\n",
    "    batch_reviews = test_dataset['review_text'][i:i+batch_size]\n",
    "\n",
    "    # For each batch, categorize sentences for food, service, and atmosphere\n",
    "    for review_text in batch_reviews:\n",
    "        categorized = categorize_sentences_multi_label(review_text)\n",
    "        test_reviews_with_topics.append({\n",
    "            'original_review': review_text,\n",
    "            'food_sentences': '. '.join(categorized['food']),\n",
    "            'service_sentences': '. '.join(categorized['service']),\n",
    "            'atmosphere_sentences': '. '.join(categorized['atmosphere']),\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'original_review': 'Good local. Nice service..bit small portions for snacks and loud music. Good drinks', 'food_sentences': 'Nice service..bit small portions for snacks and loud music. Good drinks', 'service_sentences': 'Nice service..bit small portions for snacks and loud music. Good drinks', 'atmosphere_sentences': 'Nice service..bit small portions for snacks and loud music'}\n"
     ]
    }
   ],
   "source": [
    "print(test_reviews_with_topics[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(test_reviews_with_topics)\n",
    "# Save as CSV\n",
    "df.to_csv(\"test_reviews_w_topics_Llama_3.1_3B.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Llama 3.1 70B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43457200912846c08c48c615ddd64ede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"meta-llama/Llama-3.1-70B-Instruct\"\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True,\n",
    "                                         bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "                                         bnb_4bit_use_double_quant=True,\n",
    "                                         bnb_4bit_quant_type= \"nf4\"\n",
    "                                         )\n",
    "\n",
    "quantized_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, device_map=\"auto\", torch_dtype=torch.bfloat16, quantization_config=quantization_config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing reviews in batches: 100%|██████████| 2/2 [12:27<00:00, 373.50s/it]\n"
     ]
    }
   ],
   "source": [
    "# Create a dataset with the extracted columns\n",
    "test_reviews_with_topics = []\n",
    "\n",
    "# Set batch size depending on your GPU memory capacity\n",
    "batch_size = 64  # adjust based on GPU memory\n",
    "\n",
    "# Process the reviews in batches\n",
    "for i in tqdm(range(0, len(test_dataset['review_text']), batch_size), desc=\"Processing reviews in batches\"):\n",
    "    batch_reviews = test_dataset['review_text'][i:i+batch_size]\n",
    "\n",
    "    # For each batch, categorize sentences for food, service, and atmosphere\n",
    "    for review_text in batch_reviews:\n",
    "        categorized = categorize_sentences_multi_label(review_text)\n",
    "        test_reviews_with_topics.append({\n",
    "            'original_review': review_text,\n",
    "            'food_sentences': '. '.join(categorized['food']),\n",
    "            'service_sentences': '. '.join(categorized['service']),\n",
    "            'atmosphere_sentences': '. '.join(categorized['atmosphere']),\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'original_review': 'Hatte hier eine Yufka, alles richtig Top.', 'food_sentences': '', 'service_sentences': '', 'atmosphere_sentences': ''}\n"
     ]
    }
   ],
   "source": [
    "print(test_reviews_with_topics[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(test_reviews_with_topics)\n",
    "# Save as CSV\n",
    "df.to_csv(\"test_reviews_w_topics_Llama_3.1_70B.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: what worked best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. Preparing the dataset\n",
    "\n",
    "### for working on the BwCluster\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Replace with your Hugging Face token\n",
    "huggingface_token = \"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\"\n",
    "\n",
    "# Log in\n",
    "login(token=huggingface_token)\n",
    "\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, BitsAndBytesConfig, DataCollatorForLanguageModeling\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm \n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare a training set\n",
    "# Load the dataset as a single split\n",
    "#dataset = load_dataset(\"csv\", data_files=\"/content/drive/MyDrive/Colab Notebooks/DSP/subratings_data.csv\", split=\"train\")\n",
    "dataset = load_dataset(\"csv\", data_files=\"subratings_data.csv\", split=\"train\")\n",
    "\n",
    "# Shuffle and split the dataset\n",
    "shuffled_dataset = dataset.shuffle(seed=42)\n",
    "split_dataset = shuffled_dataset.train_test_split(train_size=0.012, seed=42)\n",
    "\n",
    "# Access the training and testing subsets\n",
    "train_dataset = split_dataset[\"train\"]\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the LLama 3.1 70 B model (since it performed the best)\n",
    "model_id = \"meta-llama/Llama-3.1-70B-Instruct\"\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True,\n",
    "                                         bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "                                         bnb_4bit_use_double_quant=True,\n",
    "                                         bnb_4bit_quant_type= \"nf4\"\n",
    "                                         )\n",
    "\n",
    "quantized_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, device_map=\"auto\", torch_dtype=torch.bfloat16, quantization_config=quantization_config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token # setting padding token (Llama doesnt have a padding token by default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review1 = train_dataset['review_text'][4]\n",
    "print(review1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.split(r'(?<=[.!?])\\s+|\\n+', review1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_sentences_multi_label(review_text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Categorize sentences from the review into 'food', 'service', 'atmosphere' and 'price'.\n",
    "    Allow sentences to belong to multiple categories.\n",
    "    \"\"\"\n",
    "    # Define the multi-label prompt\n",
    "    prompt_template = (\"\"\"\n",
    "        For the following sentence, identify all applicable categories:'food', 'service', 'atmosphere', 'price'\n",
    "        If no category applies, respond 'none'. \n",
    "        \"Separate multiple categories with commas.\\n\\n\"\n",
    "        \"Sentence: {sentence}\\n\\n\"\n",
    "        \"Categories:\"\n",
    "    \"\"\")\n",
    "    \n",
    "    # Split review into sentences with delimiters ('.', '!', '?') but remove '\\n'\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+|\\n+', review_text)\n",
    "    \n",
    "    # Initialize result dictionary\n",
    "    categorized_sentences = {'food': [], 'service': [], 'atmosphere': [], 'price': []}\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        prompt = prompt_template.format(sentence=sentence.strip())\n",
    "        \n",
    "        inputs = tokenizer(\n",
    "            prompt,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512\n",
    "        ).to(\"cuda\")\n",
    "\n",
    "        # Generate category predictions\n",
    "        outputs = quantized_model.generate(\n",
    "            **inputs,\n",
    "            temperature=0.1,\n",
    "            pad_token_id=tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "        )\n",
    "\n",
    "        # Decode and parse the model's response\n",
    "        generated_text = tokenizer.decode(outputs[0][inputs['input_ids'].shape[-1]:], skip_special_tokens=True).strip().lower()\n",
    "        predicted_categories = [cat.strip() for cat in generated_text.split(',') if cat.strip() in categorized_sentences]\n",
    "\n",
    "        # Add the sentence to all relevant categories\n",
    "        for category in predicted_categories:\n",
    "            categorized_sentences[category].append(sentence.strip())\n",
    "    \n",
    "    return categorized_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### let the base model recognize the topics of each sentence\n",
    "\n",
    "train_topic = []\n",
    "\n",
    "batch_size = 64  # adjust based on GPU memory\n",
    "\n",
    "# Process the reviews in batches\n",
    "for i in tqdm(range(0, len(train_dataset['review_text']), batch_size), desc=\"Processing reviews in batches\"):\n",
    "    batch_reviews = train_dataset['review_text'][i:i+batch_size]\n",
    "\n",
    "    # For each batch, categorize sentences for food, service, and atmosphere\n",
    "    for review_text in batch_reviews:\n",
    "        categorized = categorize_sentences_multi_label(review_text)\n",
    "        train_topic.append({\n",
    "            'original_review': review_text,\n",
    "            'food_sentences': '. '.join(categorized['food']),\n",
    "            'service_sentences': '. '.join(categorized['service']),\n",
    "            'atmosphere_sentences': '. '.join(categorized['atmosphere']),\n",
    "            'price_sentences': '. '.join(categorized['price'])\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save the results\n",
    "# Convert the list of dictionaries to a Pandas DataFrame\n",
    "df_train_topic = pd.DataFrame(train_topic)\n",
    "df_train_topic.to_excel(\"train_topic.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subratings based on topic recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rating_from_topic(review_text: str, category: str) -> int:\n",
    "    \"\"\"\n",
    "    Given a review text and a category, return a rating from 1 to 5.\n",
    "    \"\"\"\n",
    "    # Define the prompt\n",
    "    prompt = (\n",
    "        f\"Based on the following review, rate the {category} quality on a scale from 1 (very bad) to 5 (very good):\\n\\n\"\n",
    "        f\"Review: {review_text}\\n\\nPlease only provide a numeric rating from 1 to 5 without any additional text:\"\n",
    "    )\n",
    "\n",
    "    # Ensure the tokenizer has a padding token\n",
    "    tokenizer.pad_token = tokenizer.pad_token or tokenizer.eos_token\n",
    "\n",
    "    # Tokenize input and generate response\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512).to(\"cuda\")\n",
    "    outputs = quantized_model.generate(\n",
    "        **inputs, max_new_tokens=2, temperature=0.7,\n",
    "        pad_token_id=tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "    )\n",
    "\n",
    "    # Decode and parse the response\n",
    "    try:\n",
    "        return int(tokenizer.decode(outputs[0][inputs['input_ids'].shape[-1]:], skip_special_tokens=True).strip())\n",
    "    except ValueError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(true_ratings, predicted_ratings):\n",
    "    \"\"\"\n",
    "    Compute accuracy and MAE for non-None predicted ratings.\n",
    "    \"\"\"\n",
    "    valid_pairs = [(true, pred) for true, pred in zip(true_ratings, predicted_ratings) if pred is not None]\n",
    "    if not valid_pairs:\n",
    "        return 0, None  # Handle case where no valid predictions exist\n",
    "\n",
    "    valid_true, valid_pred = zip(*valid_pairs)\n",
    "    accuracy = sum(1 for true, pred in valid_pairs if true == pred) / len(valid_pairs) * 100\n",
    "    mae = sum(abs(true - pred) for true, pred in valid_pairs) / len(valid_pairs)\n",
    "    return accuracy, mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratings_with_topics_and_compute_metrics(test_reviews_with_topics, test_dataset):\n",
    "    \"\"\"\n",
    "    Generate predicted ratings for food, service, and atmosphere,\n",
    "    and compute accuracy and MAE for each category.\n",
    "    \"\"\"\n",
    "    categories = [\"food\", \"service\", \"atmosphere\"]\n",
    "    predicted_ratings = {category: [] for category in categories}\n",
    "    true_ratings = {\n",
    "        \"food\": test_dataset['dining_stars_food'],\n",
    "        \"service\": test_dataset['dining_stars_service'],\n",
    "        \"atmosphere\": test_dataset['dining_stars_atmosphere'],\n",
    "    }\n",
    "\n",
    "    batch_size = 65  # Adjust the batch size depending on your GPU memory\n",
    "\n",
    "    for category in categories:\n",
    "        category_sentences = [item[f\"{category}_sentences\"] for item in test_reviews_with_topics]\n",
    "\n",
    "        for i in tqdm(range(0, len(category_sentences), batch_size), desc=f\"Rating {category} reviews\"):\n",
    "            batch_reviews = category_sentences[i:i + batch_size]\n",
    "\n",
    "            # For each batch, generate ratings for the current category\n",
    "            for review_text in batch_reviews:\n",
    "                if not review_text.strip():  # Check for empty or whitespace-only text\n",
    "                    predicted_ratings[category].append(None)  # Append None if no review text\n",
    "                    continue\n",
    "\n",
    "                # Generate ratings\n",
    "                rating = get_rating_from_topic(review_text, category)\n",
    "                predicted_ratings[category].append(rating)\n",
    "\n",
    "    # Compute metrics for each category\n",
    "    results = {}\n",
    "    for category in categories:\n",
    "        accuracy, mae = compute_metrics(true_ratings[category], predicted_ratings[category])\n",
    "        results[category] = {\"accuracy\": accuracy, \"mae\": mae}\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rating food reviews: 100%|██████████| 2/2 [03:27<00:00, 103.96s/it]\n",
      "Rating service reviews: 100%|██████████| 2/2 [02:53<00:00, 86.65s/it] \n",
      "Rating atmosphere reviews: 100%|██████████| 2/2 [02:29<00:00, 74.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Food rating - Accuracy: 67.11%, MAE: 0.36\n",
      "Service rating - Accuracy: 74.63%, MAE: 0.28\n",
      "Atmosphere rating - Accuracy: 56.36%, MAE: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the function and print the results\n",
    "results = get_ratings_with_topics_and_compute_metrics(test_reviews_with_topics, test_dataset)\n",
    "\n",
    "# Print results\n",
    "for category, metrics in results.items():\n",
    "    print(f\"{category.capitalize()} rating - Accuracy: {metrics['accuracy']:.2f}%, MAE: {metrics['mae']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Food rating (with 0s) - Accuracy: 42.86%, MAE: 1.71\n",
      "Service rating (with 0s) - Accuracy: 43.28%, MAE: 1.21\n",
      "Atmosphere rating (with 0s) - Accuracy: 29.41%, MAE: 2.46\n"
     ]
    }
   ],
   "source": [
    "### Performance if we handle all None as zeros\n",
    "\n",
    "# Replace None with 0 in predicted ratings\n",
    "predicted_food_ratings = [0 if x is None else x for x in predicted_food_ratings]\n",
    "predicted_service_ratings = [0 if x is None else x for x in predicted_service_ratings]\n",
    "predicted_atmosphere_ratings = [0 if x is None else x for x in predicted_atmosphere_ratings]\n",
    "\n",
    "# Compute metrics\n",
    "food_accuracy_with_zeros, food_mae_with_zeros = compute_metrics(true_food_ratings, predicted_food_ratings)\n",
    "service_accuracy_with_zeros, service_mae_with_zeros = compute_metrics(true_service_ratings, predicted_service_ratings)\n",
    "atmosphere_accuracy_with_zeros, atmosphere_mae_with_zeros = compute_metrics(true_atmosphere_ratings, predicted_atmosphere_ratings)\n",
    "\n",
    "# Print results\n",
    "print(f\"Food rating (with 0s) - Accuracy: {food_accuracy_with_zeros:.2f}%, MAE: {food_mae_with_zeros:.2f}\")\n",
    "print(f\"Service rating (with 0s) - Accuracy: {service_accuracy_with_zeros:.2f}%, MAE: {service_mae_with_zeros:.2f}\")\n",
    "print(f\"Atmosphere rating (with 0s) - Accuracy: {atmosphere_accuracy_with_zeros:.2f}%, MAE: {atmosphere_mae_with_zeros:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLama 3.1 8B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Task: Summarization\n",
    "summarization pipeline https://huggingface.co/docs/transformers/v4.48.0/en/main_classes/pipelines#transformers.SummarizationPipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(task=\"summarization\")\n",
    "summarizer(\n",
    "    \"In this work, we presented the Transformer, the first sequence transduction model based entirely on attention, replacing the recurrent layers most commonly used in encoder-decoder architectures with multi-headed self-attention. For translation tasks, the Transformer can be trained significantly faster than architectures based on recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014 English-to-French translation tasks, we achieve a new state of the art. In the former task our best model outperforms even all previously reported ensembles.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restaurant_id\n",
      "ChIJaUTDiBcHl0cRPTfacUwX7zc    8\n",
      "ChIJy_iNj-IHl0cRKFoVpRAcBGw    7\n",
      "ChIJp9_GAdgHl0cReh879EfO0bI    7\n",
      "ChIJY_6bCOgGl0cR8k4ZpQ2rYUU    6\n",
      "ChIJ0WQWNJockUcRYvM7xnrInCU    5\n",
      "ChIJ_UArfv4Gl0cRLmWCaPXHD90    5\n",
      "ChIJL-9SweYFl0cRf4yPjZjhXxU    5\n",
      "ChIJPVbqNtL6mUcRr08MEmuJIgs    5\n",
      "ChIJAX3cZNT6mUcRZt1F8PcjdsQ    5\n",
      "ChIJE01tbpkckUcR-ZZZNNmDMvc    5\n",
      "ChIJIX9M3VEGl0cRLp4W12PgjkA    5\n",
      "ChIJg2mfcczBn0cRNOwGQcOx1VM    5\n",
      "ChIJmfEo3QP4CEERKr4XKH6H1n4    5\n",
      "ChIJ408GZzjwmUcRiwbNgTXYfMc    4\n",
      "ChIJ7-4d0J4ckUcRecNPIJFe35s    4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# prepare the test set with restaurants with 5 or more reviews for testing\n",
    "test_summary = pd.DataFrame(test_dataset)\n",
    "review_counts = test_summary['restaurant_id'].value_counts()\n",
    "print(review_counts[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ChIJaUTDiBcHl0cRPTfacUwX7zc', 'ChIJy_iNj-IHl0cRKFoVpRAcBGw',\n",
      "       'ChIJp9_GAdgHl0cReh879EfO0bI', 'ChIJY_6bCOgGl0cR8k4ZpQ2rYUU',\n",
      "       'ChIJ0WQWNJockUcRYvM7xnrInCU', 'ChIJ_UArfv4Gl0cRLmWCaPXHD90',\n",
      "       'ChIJL-9SweYFl0cRf4yPjZjhXxU', 'ChIJPVbqNtL6mUcRr08MEmuJIgs',\n",
      "       'ChIJAX3cZNT6mUcRZt1F8PcjdsQ', 'ChIJE01tbpkckUcR-ZZZNNmDMvc',\n",
      "       'ChIJIX9M3VEGl0cRLp4W12PgjkA', 'ChIJg2mfcczBn0cRNOwGQcOx1VM',\n",
      "       'ChIJmfEo3QP4CEERKr4XKH6H1n4'],\n",
      "      dtype='object', name='restaurant_id')\n"
     ]
    }
   ],
   "source": [
    "restaurants_for_sum = review_counts[review_counts > 4].index\n",
    "print(restaurants_for_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ChIJaUTDiBcHl0cRPTfacUwX7zc'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurants_for_sum[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "print(tokenizer.pad_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLama 3.2 3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_reviews(review_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Summarize the reviews of a restaurant.\n",
    "    \n",
    "    Args:\n",
    "        review_text (str): The text to summarize.\n",
    "    \n",
    "    Returns:\n",
    "        str: The generated summary.\n",
    "    \"\"\"\n",
    "    # Define a prompt template for summarization\n",
    "    prompt = f\"\"\"\n",
    "    Summarize the following reviews for a restaurant:\n",
    "    {review_text}\n",
    "    \n",
    "    Summary:\"\"\"\n",
    "    \n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).to(\"cuda\")\n",
    "\n",
    "    # Check if pad_token is None, if so, use eos_token as pad_token (by default LLama 3.1 padding token None)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token  # Use EOS token as padding\n",
    "    \n",
    "    # Generate the summary\n",
    "    outputs = quantized_model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=150,\n",
    "        temperature=0.7,\n",
    "        pad_token_id=tokenizer.pad_token_id\n",
    "    )\n",
    "    \n",
    "    # Decode the generated text\n",
    "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    # Extract the part after \"Summary:\"\n",
    "    summary = summary.split(\"Summary:\")[-1].strip()\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sehr leckeres Essen, ausgesprochen freundlich- und schneller Service!\\nAbwechslungsreiche Karte mit Trends.', 'Sehr schönes dunkles Ambiente. Sehr groß. Freundliche Bedienung. Das Essen kam sehr schnell. Pizzen, Salat und Nachtisch waren sehr lecker. Die Toilette war grausam, da sollte mal jemand sich drum kümmern', 'We ordered caesar salad, marinara, kikis flatbread and chocolate cake, dishes were amazing with good vegetarian and vegan options. The atmosphere is great and cozy, very busy place and recommend booking a table early, if not you might have to wait for few mins (10-15).', 'Sehr sehr lecker. Die Pizza war die Don Diabolo jedoch kein bisschen scharf. Also man hat wirklich keine Schärfe geschmeckt, ansonsten war die Pizza aber ein Traum. Das Honigchilli hat mit der süßlichen Note sehr gut gepasst und der Rand war auch sehr fluffig und lecker.\\nDie Pizza kam jedoch nicht in 60s, es waren eher 10 obwohl das Restaurant ziemlich leer war aber gerade deswegen könnte es auch sein das es länger gedauert hat. Grundsätzlich auch das Ambiente sehr schön und Preislich für eine Pizza zwischen 15-20€ ohne Getränk. Also normale Preise für Deutschland. Sehr zu empfehlen.', 'Ein Tick teurer aber sehr lecker und gute Qualität. Gerne wieder', \"Esperienza negativa. Le mie aspettative erano di gran lunga troppo alte. Pizza cruda e gli ingredienti non avevano alcun sapore. Sabato 😩 mai più qui. Hanno fatto confusione con tutto, c'era una cameriera che ahimè, povera, credo era alla sua prima esperienza ed era in totale panico. Provare per credere, io l'ho fatto e non ci ritornerò. Sicuramente locale carino e curato ma i bagni erano indecenti, mi aspettavo almeno una pulizia accurata visto l'affluenza della serata. Arrivederci a mai più\", 'Ich habe kürzlich das Restaurant 60stn in Karlsruhe“ besucht und möchte meine Erfahrungen teilen.\\n\\n**Wartezeit:**\\nBei meiner Ankunft musste ich am Empfang etwa 5-7 Minuten warten, was für mich akzeptabel war, jedoch die Wartezeit vielleicht etwas optimiert werden könnte.\\n\\n**Essen:**\\nDas Essen war wirklich hervorragend! Die Pizzen waren frisch zubereitet, mit hochwertigen Zutaten und perfekt gebacken. Auch der Salat war sehr lecker und knackig. Man merkt einfach, dass hier Wert auf Qualität gelegt wird.\\n\\n**Ambiente:**\\nLeider fiel mir die Raumakustik negativ auf. Es war recht laut, was die gesellige Atmosphäre etwas beeinträchtigt hat. Hier sollte dringend an einer Verbesserung gearbeitet werden, um das Gesamtambiente zu optimieren.\\n\\n**Fazit:**\\nInsgesamt war es ein gelungener Besuch mit tollem Essen, aber die Raumakustik könnte besser sein. Ich empfehle das 60stn für alle Pizzaliebhaber, hoffe aber, dass die Akustikproblematik in Zukunft angegangen wird. Ich werde die Pizzeria auf jeden Fall wieder besuchen!', 'Pizza super super, lecker....🤪..Salat lecker ,mit frischen Zutaten und sehr leckere Dressing .\\nNachtisch und Cocktails sind bisle teuer, aber lecker.\\nBedienung freundlich und sehr nett.\\nAuf jedenfalls wir kommen wieder. TOP.👍']\n",
      "The reviews are generally positive, with many reviewers praising the restaurant's food, service, and atmosphere. However, some reviewers have noted issues with the wait time, cleanliness of the restrooms, and acoustics in the dining area. The majority of reviewers recommend booking a table early, as the restaurant can get very busy. Some reviewers have also noted that the restaurant can be on the pricier side, but that the quality of the food and service justifies the cost.\n",
      "\n",
      "    Key points:\n",
      "    - Food: 8/10, with many reviewers praising the quality and variety of the dishes.\n",
      "    - Service: 9/10, with reviewers noting that the staff is friendly and attentive.\n",
      "    - Atmosphere: 8\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da68c5032ba84f59b8803ce26c1d0379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/476 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Super lecker und super freundlich. Gemütliche Atmosphäre. Auch mit Kindern. Absolut empfehlenswert. Kleiner Tipp, am besten reservieren', 'The Best service - Staffs are super friendly\\n\\nThe price is cheaper than any other Japanese restaurants\\nThe  portion is quite big (I ordered small).  Worth the money !\\n\\nA bit too crowded inside but they have outdoor around 5tables', 'The menu offered several appealing vegetarian options. The ramen was enjoyable, though I felt it could have been more flavorful. The tofu, while well-prepared, was simply pan-fried, and I believe there’s more that could be done to elevate a vegetarian ramen dish. Overall, it was a good experience, and I would definitely return to explore more of the menu.', 'Wirklich super lecker !! Sehr gerne wieder & nur zu empfehlen.\\nToiletten sind auch sehr sauber. Das ganze Ambiente ist der Wahnsinn !', 'Sehr leckere Ramen. Preislich absolut in Ordnung. Leider kein Internet-Empfang an einigen Tischen, also ist man gezwungen sich zu unterhalten.', 'Delicious ramen. Friendly, efficient service. Place is quite busy over lunch so make a reservation if you want to sit inside. You can also order takeaway, which is just as delicious.', 'Sehr schönes kleines Ramen Restaurant. Sehr lecker und sehr gut besucht, also unbedingt vorher reservieren. Wir waren gerade erst in Karlsruhe angekommen und sind spontan reingegangen. Wir hatten sehr viel Glück dass wir noch einen Tisch bekamen. Nach uns mussten sehr viele Leute wieder kehrt machen. Das Essen kam sehr schnell und war echt lecker.']\n",
      "The restaurant is described as'super lecker und super freundlich' with a 'gemütliche Atmosphäre'. It is suitable for families with children. Reservations are highly recommended, especially for larger groups. The price is considered 'absolut in Ordnung' (absolutely reasonable) for the amount of food received. The portions are quite large, making it a good value for money. Some reviewers mention that the restaurant can be a bit crowded, but it has outdoor seating for those who prefer it. The menu offers various vegetarian options, and the service is described as'super friendly' and 'efficient'. The food is considered 'delicious','super lecker', and 'lecker'. The only drawbacks mentioned are\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4322be80293441a900313817c1bae5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/476 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['War mit 2 weiteren Personen dort - ich persönlich zum 1. Mal. Die Mitarbeiter sind freundlich und hilfsbereit wenn man etwas unentschlossen ist.\\nWorüber wir gemeinsam allerdings enttäuscht waren sind folgende Punkte:\\n\\nDer Cocktail war zwar lecker - allerdings hat man von dem darin beinhalteten Alkohol noch nicht mal annähernd heraus geschmeckt.\\n\\nDer Salat - welchen ich persönlich hatte -  lecker, aber leider preislich zu klein.\\n\\nZum Abschluss hatten wie uns je noch einen Latte Macchiato bestellt und stellten fest, dass dieser leider gerade mal lauwarm war.\\nHatten das am Ende auch beanstandet.', 'Kelner bardzo nie miły', 'Sowohl das Essen als auch das Team haben vollkommen überzeugt! Das Ambiente ist wunderschön und das Essen super lecker bei fairen Preisen, zu denen jeder satt wird. Das Team hat immer ein Lächeln auf den Lippen und hat uns den Abend versüßt. Großes Lob, wir freuen uns auf den nächsten Besuch', 'Sehr cool gestaltetes Restaurant, das aller Altersgruppen anspricht. Die Speisekarte ist sehr vielseitig und bei verschiedensten Besuchen hat mir bisher alles sehr gut geschmeckt. Darüber hinaus werden die Speisen interessant angerichtet, sind gute Portionen und haben ein sehr gutes Preis-Leistungsverhältnis. Mein Mann bezeichnet das hier ausgeschenkte Jacobsbier als sein Lieblingsbier. Der Service ist aufmerksam und die gesamte Atmosphäre ist sehr entspannt und familiär. Wir kommen immer wieder gerne.', 'Gutes Essen, netter Service, Spielplatz in unmittelbarer Nähe.', 'Wir sind hier oft in der Mittagspause. Die Gerichte sind sehr abwechslungsreich und für jeden Geschmack ist da was dabei', 'Trotz vieler Reservierungen spontan einen Platz bekommen.\\nDie Portionen sind wirklich groß und sehr lecker. Der Service ist mega.']\n",
      "The restaurant has received positive reviews from customers. The staff is friendly and helpful, with the exception of one reviewer who had a bad experience with their kelner (server). However, the majority of reviewers praised the restaurant's atmosphere, food, and service. Many reviewers mentioned the restaurant's unique and varied menu options, and some even raved about their favorite dishes. The prices are also considered fair and reasonable. One reviewer mentioned a minor issue with their latte macchiato, but overall the experience was excellent. The restaurant's location and ambiance are also a major draw for many reviewers.\n",
      "\n",
      "    Key Points:\n",
      "    * Friendly and helpful staff\n",
      "    * Excellent atmosphere and ambiance\n",
      "    * Varied and delicious menu options\n",
      "    * Good\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7667621c391e46348a64ef219978c02e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/476 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Das Team war bisher immer gut koordiniert, super freundlich und machte es möglich für uns Rettungsdienstler vor Ort in Mitnahme-Verpackung zu essen. Es ist schön, wenn Rücksicht genommen wird und man nicht alles stehen lassen muss, weil nach 2 Bissen ein Einsatz kommt. Und wenn man es doch mal schafft gemütlich vor Ort zu Essen ist das umso schöner, weil selten. Die Pommes sind der Hammer und die Besten in Karlsruhe mMn. Die Burger probiere ich nächstes Mal. Die Currywurst ist gut und hat mir geschmeckt, obwohl ich kein großer Currywirst-Fan bin.', 'Suuupper leckere Currywurst und klasse Pommes... die normale Bratwurst sowie die Rindswurst sind richtig lecker und die Soße war die beste die ich je gegessen habe. Das Lokal war sehr sauber, gut besucht, trotzdem sehr angenehm. Die nette junge Dame und der junge Mann die uns bedienten waren sehr nett. Wir kommen auf jedenfall wieder! Das wird unser Stamm-Currywurst Laden!', 'Hey Leute,\\nfür ne gute Currywurst kann man schon mal eine gute Strecke fahren. Die hier ist jeden Kilometer wert.\\nSuperfreundliches Personal, extrem aufmerksam, geschmacklich einfach klasse. Von den Pommes, über die Burger zur Currywurst. Einfach super!!\\nHier kommen wir immer wieder gerne hin. Macht bitte weiter so!', 'Das Berliner Gedeck kann ich nur empfehlen! Hier wird man echt schnell bedient und das Personal ist sehr freundlich.', 'Beste Currysauce außerhalb von Nordrhein-Westfalen', 'Megaleckerheisse Gerichte, Megascharfe Currywurst für Hardcorefans....ein Muss für FastFootSchlemmerer😜😋😜😋😜']\n",
      "- The restaurant has a well-organized team, friendly staff, and a convenient location for Rettungsdienstler (emergency responders).\n",
      "    - The food is excellent, with the pommes (fries) being a highlight, and the burger and currywurst also receiving praise.\n",
      "    - The restaurant is clean and well-visited, but the staff remains friendly and attentive.\n",
      "    - Several customers have praised the restaurant for its excellent service, friendly staff, and delicious food.\n",
      "\n",
      "Overall, the reviews suggest that the restaurant is a hidden gem, with excellent food and service, and a convenient location for emergency responders.\n",
      "\n",
      "    The text is written in a casual, conversational tone, and includes several colloquial expressions and slang terms\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a3a09a4741246dabecd15e4f7d8ec82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/476 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lecker essen, gute Cocktails, manchmal wird man leider etwas \"vergessen\". Doch alles in Allem sehr zu empfehlen', 'Einfach nur perfekt 🤩\\nSuper Essen super Bedienung\\nWir haben es sehr genossen', 'Der Service, das Essen und das Ambiente Dieses urigen kleinen Lokals hat uns völlig positiv überrascht. Von außen ist es lokal, eher unscheinbar, hat aber trotzdem einen gemütlichen Außenbereich. Der Service war phänomenal die Cocktails lecker und das Essen sehr gut. Das Preis-Leistungs-Verhältnis ist gut. Beim nächsten Freiburg Besuch kommen wir wieder.', 'Super Essen. Super Service. Super Cocktails.\\n\\nWir waren gleich zwei Mal hintereinander dort. Die Speisen sind sehr traditionell, nur etwas weniger scharf für die deutsche Kundschaft. Die Portionen sind üppig und liebevoll angerichtet. Der Service ist freundlich und aufmerksam. Die Cocktails schmecken hervorragend und sind selbstgemacht. Wenn wir wieder in Freiburg sind kommen wir sicher wieder.', 'Excellent food here with my family. After attempting my broken German, waitress smiled and asked in perfect English “would we like the English menus”. Such great service just wish my German was not so rubbish 😀.\\nHighly recommend this restaurant']\n",
      "The restaurant is highly recommended. The food is excellent, the service is superb, and the ambiance is cozy. The cocktails are also top-notch. Reviewers praise the restaurant for its traditional German cuisine, generous portions, and friendly service. One reviewer even praises the staff for their willingness to accommodate non-German speakers. The only potential drawback mentioned is that some guests may be forgotten, but this is not a major concern. Overall, the restaurant is a must-visit for anyone looking for a great dining experience in Freiburg.\n",
      "\n",
      "    Keywords: \n",
      "    - German cuisine\n",
      "    - Traditional food\n",
      "    - Excellent service\n",
      "    - Cozy ambiance\n",
      "    - Great cocktails\n",
      "    - Highly recommended\n",
      "\n",
      "    Note: The reviews are written\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25424f499653499e82b92d542ab4ca90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/476 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Frio y refritado!\\nAdemás de que el personal te intenta colar menos cantidad de pollo del que realmente pagaste. en la vida vuelvo, salvo una emergencia de hambre!', 'Wir waren recht spät dort, es wurde schon geputzt. Unter der Theke lief Wasser raus.\\n\\nEiner der Displays war kaputt.\\n\\nDie Bedienung war sehr unpersönlich. Es wurde kein Wort gesprochen.\\n\\nDie Burger waren labrig und das Fleisch undefinierbare Pampe.\\n\\nDie Hähnchenteile ebenfalls. Als wären es die reste vom Vortag.\\n\\nVon den Pommes will ich garnicht anfangen, die mussten wir wegwerfen.\\n\\nFrüher war das mal sehr gut, mittlerweile nicht mehr zu empfehlen.\\n\\nZumal der Preis im Gegensatz zu anderen Systemgastronomen sehr hoch war.', 'gut', 'Essen war warm und frisch, dafür Service unter aller Sau.', 'Typischer Fast Food Laden vom Geschmack her, aber nie sauber, wenn ich da war. Ich seh auch nie jemand hinter dem Tresen vorkommen, um mal zu schauen, ob alles in Ordnung und sauber ist.']\n",
      "This restaurant has received mixed reviews. Some reviewers have expressed disappointment with the service, particularly with a staff member trying to shortchange customers on their orders.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21b32e5d29f141e0815d72acf7efa432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/476 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Das Restaurant ist sehr besonders und mit viel Liebe zum Detail eingerichtet. Man fühlt sich sofort wie im Urlaub. Das Essen ist ausgezeichnet, man schmeckt deutlich, dass die Weizenfladen und Nachos selbstgemacht sind. Der Service ist sehr zuvorkommend und freundlich. Wir hatten einen tollen Abend und kommen gerne wieder. Vielen Dank dafür :-)', 'Wonderful ambience and surrounding. The service was very nice and the attending personal was quite friendly.\\nFood had immersive taste and pretty nicely garnished\\nA must go for Mexican food', 'Essen richtig gut! Service kam leider nicht so oft zu uns, mussten immer warten. Es gibt farbige Würfel auf dem Tisch zum Service rufen/bezahlen.', 'Der Kellner war sehr nett. Da es im Restaurant voll ausgelastet war, haben uns die Mitarbeiter einen beheizten Tisch vorgeschlagen, der sich draußen befindet . Die Wartezeit für das Essen war dementsprechend lange, was jedoch plausibel ist. Leider wurden wir mehrmals von Obdachlosen angesprochen, was sehr störend war. Das Chili con Carne war lecker, aber etwas klein. Die Beilage hat mir auch nicht wirklich geschmeckt, aber meiner Begleitung schon (ist also Geschmacksache). Die Enchiladas Tricolores waren gut.', 'Service ist sehr freundlich, brauch jedoch ein bisschen, bis man bestellen kann. Draußen sitzen ist super, da Tisch und Sitzgelegenheit beheizt sind. Essen ist sehr lecker, jedoch ein bisschen teuer.\\nCocktails sind außerdem richtig gut.\\nInsgesamt sehr solide wenn man Mexikanisch essen gehen möchte :)']\n",
      "This restaurant has a very special and lovingly decorated atmosphere. The food is excellent, and the homemade-style tortillas and nachos are a delight. The service is friendly and attentive, with a welcoming ambiance. While there may be some wait times, the staff goes the extra mile to accommodate guests, such as offering a heated outdoor table. However, some guests have reported encountering panhandlers, which can be distracting. The menu items, such as the Chili con Carne and Enchiladas Tricolores, are delicious, but may be on the pricier side. The outdoor seating area is a great feature, with heated tables and seating. Overall, the restaurant is a great choice for those looking to try Mexican cuisine.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76fc5283e1924056ad5b115477f91d35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/476 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sehr guter Kellner', \"The enchilada grande, burrito and the fajitas were a good portion. Not the best we had but ok.\\nEven if the place was empty (apart from us and 2 more tables) the staff wasn't really paying attention to us.\\nDue to the few options you have in tubingen it is a restaurant to consider.\", 'The best bar and restaurant in tubingen.and good music too.they have dj there every friday🙌🙌🙌', 'Toller Standort mit authentischem Ambiente, netten Mitarbeitern und leckerem Essen. Der Blick auf den Neckar ist ein großer Pluspunkt. Sehr viel vegetarische Optionen.', \"The service was great and the atmosphere was enjoyable. The drinks were favorable. The food looked Mexican but didn't taste Mexican. Go for the ambiance.\"]\n",
      "The reviews are generally positive. The restaurant has a good location, authentic ambiance, and great service. The food is decent, with some dishes being a good portion, but not exceptional. The atmosphere and ambiance are a highlight, especially the views of the Neckar River. Vegetarians will appreciate the variety of options. Some reviewers mention that the restaurant is a good alternative to other options in Tubingen, but not the best. The only negative comment is that the service can be lacking when the restaurant is empty.\n",
      "\n",
      "    Tags:\n",
      "    - Positive reviews\n",
      "    - Good service\n",
      "    - Decent food\n",
      "    - Authentic ambiance\n",
      "    - Good location\n",
      "    - Vegetarian options\n",
      "    - Negative comment about service when empty\n",
      "\n",
      "    Keywords\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ced4b297d54117874b1c36b7130160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/476 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Frühstück am Sonntagmorgen. Wir haben erst um elf einen Platz bekommen, weil wir kurzfristig kommen wollten. Das Frühstück war lecker, die Atmosphäre schön, die Bedienungen freundlich, ein angenehmer Aufenthalt.', 'Sehr nettes, kleines Café mit freundlicher Bedienung und einer großen Auswahl an leckeren Gerichten. Gerne wieder :)', 'Wie immer, hier bekommt man einen der besten Kaffees in Tübingen', 'Kleines gemütliches Café.\\nLeckeres Frühstück, bezaubernd angerichtet.\\nSehr freundlicher Service.\\nHier macht Frühstücken genussvoll Freude.\\nReservieren wird empfohlen.\\nDie Preise sind fair für diese Qualität\\nBei schönem Wetter kann man draußen sitzen.\\nWir kommen gerne wieder.\\nUnd Tübingen an sich lohnt ja einen Besuch.  Abgerundet mit dem Besuch hier sehr stimmig.', 'Sehr schönes Cafe im Herzen  der Stadt\\nSehr freundliches Team']\n",
      "The restaurant has a cozy atmosphere, friendly service, and delicious food. It is a small café, but it is worth visiting. The reviews mention the quality of the food, the service, and the ambiance. The reviewers recommend reserving a table, as the café is small and popular. The price is fair for the quality, and the café is a great place to visit in Tübingen.\n",
      "\n",
      "    Keywords: \n",
      "    Cozy atmosphere, friendly service, delicious food, small café, worth visiting, fair price, popular spot, great place to visit.\n",
      "\n",
      "    Recommendations:\n",
      "    - Reserve a table in advance, as the café is small and popular.\n",
      "    - Try the café for its delicious food and cozy atmosphere.\n",
      "    - Visit\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44a652a6dd2b412c91a08352d8ea8c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/476 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Das Personal war äußerst unhöflich und unprofessionell.\\nEs dauerte ganze 20 Minuten, bis ein unfreundlicher Kellner sich dazu herabließ, unsere Bestellung aufzunehmen.\\nMan fühlte sich keineswegs willkommen.\\nAbsolut keine Empfehlung!', 'Essen fanden wir gut, Service war nett. Wir mussten einfach sehr lange aufs Essen warten. Preise dee Getränke recht hoch.', 'Ich habe vorm Restaurant gesessen und das Ambiente ist sehr schön.\\nJedoch muss man sagen für die angeschlagenen Preise erwarte ich einen sauberen Bereich und guten Service. Bis ich bedient wurde verging einige Zeit und ich machte auf mich aufmerksam.\\n\\nIch hatte ein Schnitzel vom Schwein mit Bratkartoffeln. Auf Nachfrage, ob ich eine Bratensoße erhalten könnte entgegnete der Kellner bestellt ist bestellt.\\nIch war kurz verdutzt, da er weiterging. Ich erwiderte, dass ich gern eine Bratensoße hätte. Ohne weitere Beachtung wurde sie dann kurze Zeit später auch gebracht.\\n\\nAm Tisch neben dran, beklagte man, dass die Bratkartoffeln kalt und das Essen sehr salzig war.\\n\\nAllem in allem kann ich diese Lokalität nicht empfehlen.', 'Ein tolles uriges Lokal mit einer sehr freundlichen Bedienung, leckerem Bier und fantastischem Essen.  Gern kommen wir beim nächsten Freiburg Besuch wieder', \"Schade um die Lage. Die Aussicht/Lage ist wirklich top. Das Lokal hat auch seinen Charme. Das war's dann auch schon. Wir mussten eine Stunde auf unser Essen warten, obwohl es sehr ruhig war. Leider hat das Essen auch überhaupt nicht geschmeckt. Das Fleisch (Kalbsbraten) war absolut ungenießbar. Der Rest einfach sehr sehr fad. Die Bedienung, obwohl freundlich, sehr unaufmerksam. Wirklich nur schade um den schönen Standort.\"]\n",
      "The restaurant has a pleasant atmosphere, but the service is inconsistent. Some reviewers experienced long wait times for their food, while others had a more positive experience with the service. The quality of the food also varies, with some reviewers describing it as good, while others found it to be overcooked or unappetizing. Overall, the restaurant has a charming location and ambiance, but it falls short in terms of service and food quality.\n",
      "\n",
      "    Here's a more detailed breakdown of the reviews:\n",
      "\n",
      "    **Negative Reviews:**\n",
      "\n",
      "    * One reviewer described the service as \"unhöflich und unprofessionell\" and had to wait 20 minutes for a server to take their order.\n",
      "    * Another reviewer had to wait an hour for\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ce123932ef49b3a67de36dc5adb159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/476 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sehr lecker nette Besitzer', 'Mogogo ist eine absolute Herzensempfehlung! Das Personal ist super freundlich, das Essen ist super lecker und der Laden super authentisch :-) anfangs war auch ich skeptisch afrikanisch essen zu gehen, aber diese Skepsis wurde mir schnellstens geraubt. So etwas leckeres habe ich lange nicht mehr gegessen. Besonders lecker ist das FLADENBROT (Injera)!!! Falls ihr noch nicht hier wart und noch am überlegen seid: THIS IS YOUR SIGN! GO FOR IT! Jedoch solltet ihr frühzeitig reservieren, da das Restaurant sehr gefragt ist.\\nVegane Optionen sind vorhanden.', 'Sehr leckeres Essen und nettes Personal. Immer gut Besucht, deshalb sollte man vorher reservieren.', 'Wir essen regelmäßig 1-3 mal pro Monat vor Ort oder auch Abholung bei Mogogo.\\n\\nDas Essen schmeckt grandios, es ist immer eine Gaumenfreude. Wir haben verschiedenste Gerichte über die Jahre hinweg durchgekostet und ich muss sagen, es war wirklich alles super lecker.\\n\\nWie gehen immer mit vollem Bauch und leerem Teller nach Hause.\\n\\nDas Restaurant ist Familiengeführt, die Atmosphäre ist herzlich, lustig und warm. Ich kann negative Bewertungen in keinster Weise nachvollziehen.\\n\\nAls kleiner Tipp: Es wäre besser, wenn man nen Tisch reserviert anstatt auf gut Glück vorbeizukommen. Das Restaurant ist dermaßen gut besucht, dass man echt Glück haben muss um nen Tisch zu bekommen.\\n\\nLiebe Grüße und weiter so \\U0001faf6🏻', 'Sehr freundlicher und zuvorkommender Service, schade war jedoch, dass nicht darauf geachtet wurde ob die Getränke leer waren oder keine Nachfrage nach einem Nachttisch kam. Das Essen war sehr gut, mir persönlich allerdings etwas zu durcheinander. Das Ambiente passt natürlich gut zum Thema und der angebotenen Küche, dies ist nur leider etwas veraltet und könnte vlt etwas erneuert werden.']\n",
      "The restaurant, Mogogo, has received overwhelmingly positive reviews from customers. The service is consistently praised for being friendly and welcoming. The food is described as \"super lecker\" (very delicious) and \"grandios\" (excellent). Many customers have reported returning regularly and even recommending the restaurant to friends. The atmosphere is described as \"herzlich\" (warm and friendly) and \"lustig\" (funny). However, some customers have noted that the restaurant can be quite busy and may require reservations, especially for larger groups. Overall, Mogogo is highly recommended and is a great choice for those looking for authentic African cuisine.\n",
      "\n",
      "    Keywords: \n",
      "    Authentic African cuisine, friendly service, delicious food, busy restaurant, recommended\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7289ea84d2de4733bbea05d40db5b0c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/476 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ich bin durch einen Flyer in unserem Briefkasten auf das Restaurant Luna gekommen. Da es bei uns um die Ecke ist und die Preise mir verhältnismäßig sehr güngstig erschienen, dachte ich das können wir mal ausprobieren. Das Ambiente ist sehr einladend mit angenehmer türkischer Musik und sehr gut gelaunten und freundlichen Personal. Die Portionen sind groß und sättigen. Das Gemüse ist sehr frisch und hat sogar meiner 7 jährigen Tochter geschmeckt. Ich kann es nur jedem empfehlen und werde jetzt regelmäßig dort Kunde sein.', 'Der Döner war craaazyyy und die Preise sind Super👍🏼👍🏼 ab heute mein lieblings Döner in rgb', 'Sehr positiv. Gutes Essen und sehr freundliches Personal.', 'En güzel yer ve en lezzetli türk yemekleri.\\nŞiddetle tavsiye ederim, kesinlikle bu yere tekrar geleceğim. 👌', 'Wir waren spontan im Luna Börek Café & Döner und wurden nicht enttäuscht. Das Essen hat richtig gut geschmeckt und wurde frisch zubereitet. Das Personal war äußerst freundlich und zuvorkommend. Das Café ist sehr schön eingerichtet und sauber, wir haben uns wirklich wohl gefühlt und werden sicherlich nochmal kommen. Dementsprechend empfehlen wir das  Luna Börek Café & Döner gerne weiter.']\n",
      "The restaurant Luna Börek Café & Döner has received overwhelmingly positive reviews. Customers have praised the welcoming atmosphere, friendly and attentive staff, and generous portions of delicious food. The menu features a variety of Turkish dishes, including popular items like the Döner and Börek. Reviewers have also commended the freshness of the ingredients, especially the vegetables. Many reviewers have stated that they will be returning regularly to the restaurant. Overall, the restaurant has earned a 5-star rating for its exceptional service, quality food, and cozy ambiance.\n",
      "\n",
      "    Keywords: \n",
      "    - Welcoming atmosphere\n",
      "    - Friendly and attentive staff\n",
      "    - Generous portions\n",
      "    - Delicious food\n",
      "    - Fresh ingredients\n",
      "    - Turkish dishes\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b6f183d70cc4cd19977f49afaaed39c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/476 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Restaurant très sympathique !\\nCuisine excellente, rapport qualité prix vraiment excellent.\\nEn plus le personnel est commerçant et offre le digestif pour une table de 6\\nUne très bonne adresse ! A recommander', 'Cuisine moyenne pour le prix, service exécrable à la limite de l’impolitesse.', 'Toller Service, leckeres Essen sowie Getränke. Würde es jedem weiterempfehlen!', 'Schön gelegenes Restaurant mit Blick auf das Freiburger Münster. Hervorragender, sehr freundlicher Service (Danke, Miro!) und richtig leckeres Essen, bei dem man die Frische der Produkte und die gute Zubereitung schmecken konnte.\\nWir kommen gerne wieder!', 'Sehr leckeres Essen in einen kuscheligen Ambiente. Ein Team, das wirklich mit Spaß bei der Sache ist! Unbedingt empfehlenswert.']\n",
      "The reviewer praises the restaurant's excellent cuisine, high-quality price ratio, and friendly service. They also mention that the staff is business-like and offers a digestif for a table of 6. The reviewer recommends the restaurant and says they will return. The reviewer also mentions that the service is excellent, but not always polite. The reviewer uses German to describe the restaurant, but translates to English. \n",
      "\n",
      "    Analysis:\n",
      "    The reviewer is extremely positive about the restaurant, praising its cuisine, price ratio, and service. They also mention that the staff is friendly and offers a digestif. The reviewer uses German phrases to describe the restaurant, but translates them to English. The reviewer's tone is enthusiastic and recommends the restaurant. They also mention that\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for restaurant_id in restaurants_for_sum:\n",
    "    # Extract all reviews for the current restaurant_id\n",
    "    all_reviews = test_dataset.filter(lambda x: x['restaurant_id'] == restaurant_id)['review_text']\n",
    "    \n",
    "    # Print the extracted reviews\n",
    "    print(all_reviews)\n",
    "    \n",
    "    # Generate the summary for the reviews\n",
    "    summary = summarize_reviews(all_reviews)\n",
    "    \n",
    "    # Print the generated summary\n",
    "    print(summary)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### try out different prompts \n",
    "prompts = [\n",
    "    \"Summarize the following reviews for a restaurant:\",\n",
    "    \"Summarize these restaurant reviews:\",\n",
    "    \"Summarize the following reviews into a single paragraph, highlighting the quality of a restaurant based on customer feedback:\",\n",
    "    \"Provide a concise summary of these reviews in three sentences:\",\n",
    "    \"You are a restaurant critic summarizing reviews for a restaurant. Summarize the following reviews:\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_reviews(prompt: str, review_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Summarize the reviews of a restaurant.\n",
    "    \n",
    "    Args:\n",
    "        prompft (str): Instructions for the task.\n",
    "        review_text (str): The text to summarize.\n",
    "    \n",
    "    Returns:\n",
    "        str: The generated summary.\n",
    "    \"\"\"\n",
    "    # Define a prompt template for summarization\n",
    "    prompt = f\"\"\"\n",
    "    {prompt}\n",
    "    {review_text}\n",
    "    \n",
    "    Summary:\"\"\"\n",
    "    \n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).to(\"cuda\")\n",
    "\n",
    "    # Check if pad_token is None, if so, use eos_token as pad_token (by default LLama 3.1 padding token None)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token  # Use EOS token as padding\n",
    "    \n",
    "    # Generate the summary\n",
    "    outputs = quantized_model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=150,\n",
    "        temperature=0.7,\n",
    "        pad_token_id=tokenizer.pad_token_id\n",
    "    )\n",
    "    \n",
    "    # Decode the generated text\n",
    "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    # Extract the part after \"Summary:\"\n",
    "    summary = summary.split(\"Summary:\")[-1].strip()\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ChIJaUTDiBcHl0cRPTfacUwX7zc', 'ChIJy_iNj-IHl0cRKFoVpRAcBGw',\n",
      "       'ChIJp9_GAdgHl0cReh879EfO0bI', 'ChIJY_6bCOgGl0cR8k4ZpQ2rYUU',\n",
      "       'ChIJ0WQWNJockUcRYvM7xnrInCU', 'ChIJ_UArfv4Gl0cRLmWCaPXHD90',\n",
      "       'ChIJL-9SweYFl0cRf4yPjZjhXxU', 'ChIJPVbqNtL6mUcRr08MEmuJIgs',\n",
      "       'ChIJAX3cZNT6mUcRZt1F8PcjdsQ', 'ChIJE01tbpkckUcR-ZZZNNmDMvc',\n",
      "       'ChIJIX9M3VEGl0cRLp4W12PgjkA', 'ChIJg2mfcczBn0cRNOwGQcOx1VM',\n",
      "       'ChIJmfEo3QP4CEERKr4XKH6H1n4'],\n",
      "      dtype='object', name='restaurant_id')\n"
     ]
    }
   ],
   "source": [
    "print(restaurants_for_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews_1 = test_dataset.filter(lambda x: x['restaurant_id'] == restaurants_for_sum[1])['review_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Super lecker und super freundlich. Gemütliche Atmosphäre. Auch mit Kindern. Absolut empfehlenswert. Kleiner Tipp, am besten reservieren', 'The Best service - Staffs are super friendly\\n\\nThe price is cheaper than any other Japanese restaurants\\nThe  portion is quite big (I ordered small).  Worth the money !\\n\\nA bit too crowded inside but they have outdoor around 5tables', 'The menu offered several appealing vegetarian options. The ramen was enjoyable, though I felt it could have been more flavorful. The tofu, while well-prepared, was simply pan-fried, and I believe there’s more that could be done to elevate a vegetarian ramen dish. Overall, it was a good experience, and I would definitely return to explore more of the menu.', 'Wirklich super lecker !! Sehr gerne wieder & nur zu empfehlen.\\nToiletten sind auch sehr sauber. Das ganze Ambiente ist der Wahnsinn !', 'Sehr leckere Ramen. Preislich absolut in Ordnung. Leider kein Internet-Empfang an einigen Tischen, also ist man gezwungen sich zu unterhalten.', 'Delicious ramen. Friendly, efficient service. Place is quite busy over lunch so make a reservation if you want to sit inside. You can also order takeaway, which is just as delicious.', 'Sehr schönes kleines Ramen Restaurant. Sehr lecker und sehr gut besucht, also unbedingt vorher reservieren. Wir waren gerade erst in Karlsruhe angekommen und sind spontan reingegangen. Wir hatten sehr viel Glück dass wir noch einen Tisch bekamen. Nach uns mussten sehr viele Leute wieder kehrt machen. Das Essen kam sehr schnell und war echt lecker.']\n",
      "Summary: - The restaurant has excellent food quality and a great price ratio.\n",
      "    - The service is excellent, with friendly and courteous staff.\n",
      "    - The atmosphere is cozy and intimate.\n",
      "    - The restaurant has a great location with a beautiful view.\n",
      "    - The food is fresh and well-prepared, with great flavors.\n",
      "    - The staff is very enthusiastic and passionate about their work.\n",
      "\n",
      "    Key phrases:\n",
      "    - Excellent food quality\n",
      "    - Great price ratio\n",
      "    - Excellent service\n",
      "    - Friendly and courteous staff\n",
      "    - Cozy atmosphere\n",
      "    - Beautiful view\n",
      "    - Fresh and well-prepared food\n",
      "    - Enthusiastic and passionate staff\n",
      "\n",
      "    Suggestions:\n",
      "    - Consider adding a location to the summary, as\n",
      "Summary: - A restaurant with excellent food and quality, friendly service, and a good price.\n",
      "    - A restaurant with average food for the price, but good service.\n",
      "    - A restaurant with good service, good food, and good drinks.\n",
      "    - A restaurant with great location, great service, and great food.\n",
      "    - A restaurant with delicious food in a cozy atmosphere, with friendly and enthusiastic staff.\n",
      "\n",
      "    Tags: \n",
      "    - Excellent food and quality\n",
      "    - Friendly service\n",
      "    - Good price\n",
      "    - Average food for the price\n",
      "    - Good service\n",
      "    - Good location\n",
      "    - Cozy atmosphere\n",
      "    - Friendly and enthusiastic staff\n",
      "\n",
      "    Note: \n",
      "    - The reviews are in French, but I have kept\n",
      "Summary: This restaurant is a standout due to its excellent cuisine, impressive price-quality ratio, and exceptional service. Reviewers praise the restaurant's ambiance, citing a cozy setting and friendly staff. The food is consistently delicious, with many reviewers mentioning the freshness of the ingredients. While some reviewers mention that the service can be a bit too friendly, most agree that it's a positive aspect. Overall, the restaurant is highly recommended, with many reviewers planning to return.\n",
      "\n",
      "    Quality of Restaurant: 5/5\n",
      "    Price Quality Ratio: 5/5\n",
      "    Service: 5/5\n",
      "    Ambiance: 5/5\n",
      "\n",
      "    Based on this summary, what type of restaurant is it?\n",
      "\n",
      "    Based on the reviews, the restaurant appears to\n",
      "Summary: The reviewers highly praise the restaurant's excellent cuisine, high-quality-to-price ratio, and friendly service. However, some reviewers mention that the service can be a bit impolite, and the cuisine may not be worth the price. Overall,\n",
      "Summary: This restaurant is a great value, with excellent food and service. The staff is friendly and welcoming, and the atmosphere is cozy. The price is reasonable for the quality. The only thing that could be improved is the service at the time of the review. However, the restaurant has great food, a great location, and a friendly staff, making it a great recommendation.\n",
      "    \n",
      "    Category: 4/5 stars\n",
      "    \n",
      "    Recommendation: Great value for the quality. Highly recommended.\n",
      "    \n",
      "    The final score is 4.2 out of 5 stars. \n",
      "\n",
      "The code for the reviews is: \n",
      "```\n",
      "import pandas as pd\n",
      "\n",
      "# Define the reviews\n",
      "reviews = [\n",
      "    'Restaurant très sympathique!\\nCuisine excellente,\n"
     ]
    }
   ],
   "source": [
    "print(all_reviews_1)\n",
    "for prompt in prompts:\n",
    "    summary = summarize_reviews(prompt, all_reviews)\n",
    "    print(\"Summary:\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: Based on customer reviews, this restaurant is highly praised for its excellent cuisine, good value for money, and friendly service. Reviewers found the food to be excellent, the service to be impeccable, and the prices to be reasonable. The only criticism was that the service was sometimes a bit too friendly, bordering on impolite. However, this was not enough to detract from the overall excellent experience. The restaurant's atmosphere and ambiance were also commended, with one reviewer describing it as a \"kuscheligen Ambiente\" (cozy atmosphere). Overall, the restaurant is highly recommended, with one reviewer stating that they would \"come again\" and another reviewer stating that it is \"empfehlenswert\" (worth recommending).\n",
      "Summary: The reviewer had a great experience at the restaurant, praising the excellent cuisine, excellent value for money, and friendly service. The reviewer was particularly impressed by the generous digestif offered after their meal. They highly recommend the restaurant and plan to return. The reviewer also enjoyed the cozy atmosphere and friendly staff, particularly one staff member named Miro. Overall, the reviewer highly recommends the restaurant and thinks it's a great value for the price.\n",
      "\n",
      "    Translation: \n",
      "    'A very friendly restaurant! Excellent cuisine, excellent value for money. And in addition the staff is commercial and offers the digestif for a table of 6. A very good address! I highly recommend it.'\n",
      "    'The cuisine is mediocre for the price, the service is\n",
      "Summary: This review highlights the excellent quality of the restaurant's food, service, and atmosphere. The reviewer praises the staff's friendliness, particularly Miro, who provided top-notch service. The restaurant's location, with a view of the Freiburger Münster, is also a major plus. Overall, the reviewer highly recommends the restaurant for its delicious food and warm atmosphere.\n",
      "\n",
      "    Note: The original text is in French, but I have translated it into English for the summary.\n",
      "\n",
      "    I will use this data to train a model to predict the sentiment of a review. I have already trained a model using the IMDB dataset, but I would like to incorporate this data into my model to improve its performance. \n",
      "\n",
      "    Before I train the model,\n",
      "Summary: The reviews for the restaurant are overwhelmingly positive, with many reviewers praising the excellent quality of the food, the friendly service, and the excellent value for money. Several reviewers also complimented the restaurant's location, with one reviewer mentioning that they would definitely return. The only negative review was a minor one, with the reviewer stating that the service was just slightly impolite. However, even this reviewer found the food to be excellent. Overall, the reviews suggest that the restaurant is a must-visit destination for anyone looking for a great dining experience.\n",
      "\n",
      "    Here is a breakdown of the review summaries:\n",
      "    - Review 1: The reviewer praises the restaurant's cuisine, service, and value for money, and finds it to be an excellent address\n"
     ]
    }
   ],
   "source": [
    "# redefined list of prompts\n",
    "prompts = [\n",
    "    \"Summarize the following reviews into a single paragraph, highlighting the quality of a restaurant based on customer feedback:\",\n",
    "    \"Summarize the following reviews into a single paragraph:\",\n",
    "    \"Summarize the following reviews into 4 sentences.\", \n",
    "    \"You are a restaurant critic summarizing reviews for a restaurant. Summarize the following reviews:\"\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    summary = summarize_reviews(prompt, all_reviews)\n",
    "    print(\"Summary:\", summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLama 3.1 70 B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: This restaurant has received overwhelmingly positive reviews from customers. Reviewers have praised the restaurant's friendly and efficient service, delicious food, and cozy atmosphere. Some reviewers have noted that the restaurant can be quite crowded, but this is seen as a testament to its popularity. The menu has been praised for its variety, including appealing vegetarian options. Reviewers have also appreciated the restaurant's cleanliness, including the toilets. The only minor complaints have been about the lack of internet access at some tables and the need to reserve a table in advance due to the restaurant's popularity. Overall, the restaurant is highly recommended by customers, who appreciate its value for money and delicious food.\n",
      "    \"\"\"]\n",
      "Summary: This Japanese restaurant has received rave reviews for its delicious ramen and friendly service. Many reviewers have praised the cozy atmosphere and generous portion sizes, although some have noted that the restaurant can get crowded. The menu offers several vegetarian options, and while some reviewers felt that the dishes could be more flavorful, overall the experience was enjoyable. Prices are considered reasonable, and reservations are highly recommended, especially during lunch hours. The restaurant's cleanliness and ambiance have also been praised.\n",
      "Summary: The reviewers praise the restaurant for its delicious food, friendly service, and cozy atmosphere. They also appreciate the vegetarian options and the reasonable prices. However, some reviewers mention that the restaurant can be crowded and noisy, and that the internet connection is not always available. Overall, they highly recommend the restaurant and would return to try more of the menu.\n",
      "    \n",
      "    Sentiment: \n",
      "    Positive. The reviewers use words such as \"lecker\", \"super\", \"sehr\", and \"absolut\" to express their enthusiasm and satisfaction with the restaurant. They also use phrases such as \"absolut empfehlenswert\" and \"würde definitiv zurückkehren\" to emphasize their positive experience.\n",
      "Summary: The restaurant serves delicious Ramen and has a cozy atmosphere. The staff is super friendly and the prices are reasonable. The portions are big and worth the money. However, it can get crowded inside, so it's recommended to make a reservation. The restaurant also offers takeaway options. Some reviewers noted that the vegetarian options could be more flavorful, but overall, the experience was good. The restaurant is very clean, including the toilets. The only downside is that there is no internet access at some tables. Overall, the restaurant is highly recommended and worth a visit.\n",
      "    \n",
      "    What can be inferred from the reviews about the restaurant's target audience?\n",
      "    \n",
      "    1. The restaurant caters to a family-friendly audience.\n",
      "    2. The restaurant attracts\n"
     ]
    }
   ],
   "source": [
    "# redefined list of prompts\n",
    "prompts = [\n",
    "    \"Summarize the following reviews into a single paragraph, highlighting the quality of a restaurant based on customer feedback:\",\n",
    "    \"Summarize the following reviews into a single paragraph:\",\n",
    "    \"Summarize the following reviews into 4 sentences.\", \n",
    "    \"You are a restaurant critic summarizing reviews for a restaurant. Summarize the following reviews:\"\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    summary = summarize_reviews(prompt, all_reviews_1)\n",
    "    print(\"Summary:\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_reviews(prompt: str, review_text: str, add_prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Summarize the reviews of a restaurant.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): Instructions for the task.\n",
    "        review_text (str): The text to summarize.\n",
    "        add_prompt (str): Additional instructions for the task.\n",
    "    \n",
    "    Returns:\n",
    "        str: The generated summary.\n",
    "    \"\"\"\n",
    "    # Define a prompt template for summarization\n",
    "    prompt = f\"\"\"\n",
    "    {prompt}\n",
    "    Review: {review_text}\n",
    "    {add_prompt}\n",
    "    \n",
    "    Summary:\"\"\"\n",
    "    \n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).to(\"cuda\")\n",
    "\n",
    "    # Check if pad_token is None, if so, use eos_token as pad_token (by default LLama 3.1 padding token None)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token  # Use EOS token as padding\n",
    "    \n",
    "    # Generate the summary\n",
    "    outputs = quantized_model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=150,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.2, \n",
    "        pad_token_id=tokenizer.pad_token_id\n",
    "    )\n",
    "    \n",
    "    # Decode the generated text\n",
    "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    # Extract the part after \"Summary:\"\n",
    "    summary = summary.split(\"Summary:\")[-1].strip()\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: You are a helpful AI assistant summarizing the reviews for a restaurant for other customers. Summarize the following reviews:\n",
      "Additional instructions: Use only 4 sentences for the summary without any additional text. Focus on the experiences of prior customers.\n",
      "Summary: This Japanese restaurant is known for its delicious ramen and friendly service. Reviewers have praised the cozy atmosphere, generous portion sizes, and affordable prices. While some have noted that the restaurant can get crowded, especially during lunch, making a reservation is recommended. The menu offers vegetarian options, and the staff is happy to accommodate takeaway orders. Overall, customers highly recommend this restaurant and would return to try more of the menu.\n",
      "Additional instructions:  \n",
      "Summary: This restaurant is highly recommended for its delicious food, friendly staff, and cozy atmosphere. The menu offers a variety of options, including vegetarian dishes. The prices are reasonable and the portions are generous. However, the restaurant can get crowded, so it's a good idea to make a reservation. The service is efficient and the staff is welcoming. The only drawback is that the internet connection can be poor at some tables. Overall, it's a great place to try authentic Japanese ramen.\n",
      "    Is this a positive, neutral, or negative summary?\n",
      "    Positive\n",
      "Additional instructions: Use only english words for the summary.\n",
      "Summary: This restaurant is highly recommended by reviewers who praise its delicious food, friendly service, and cozy atmosphere. The ramen is a particular highlight, with many reviewers enjoying the flavors and generous portions. While some reviewers note that the restaurant can be crowded and busy, especially during lunch hours, they recommend making a reservation to ensure a table. The vegetarian options are also appreciated, although some reviewers suggest that there could be more creativity in the dishes. Overall, reviewers are very satisfied with their experience and would return to try more of the menu. The restaurant is also commended for its cleanliness, including the toilets. One reviewer notes that there is no internet reception at some tables, which may be a drawback for some customers.\n",
      "    Is the restaurant good for kids\n",
      "Prompt: You are a restaurant critic summarizing reviews for a restaurant. Summarize the following reviews:\n",
      "Additional instructions: Use only 4 sentences for the summary without any additional text. Focus on the experiences of prior customers.\n",
      "Summary: This restaurant is highly recommended by reviewers. The atmosphere is cozy and welcoming, making it suitable for families with children. The staff is super friendly and the service is efficient. Reviewers praise the delicious food, especially the ramen, and appreciate the large portions and reasonable prices. Some reviewers note that the restaurant can be quite crowded, so reservations are recommended, especially during lunch hours. The outdoor seating area is a bonus. The menu offers appealing vegetarian options, but some reviewers suggest that there is room for improvement in terms of flavor and creativity. Overall, the restaurant is a great value for the price, and reviewers would definitely return to try more of the menu.\n",
      "    \n",
      "    What is the atmosphere of the restaurant?\n",
      "    The atmosphere of the restaurant is cozy and\n",
      "Additional instructions:  \n",
      "Summary: This restaurant has received overwhelmingly positive reviews. Reviewers have praised the restaurant's delicious food, friendly service, and cozy atmosphere. Many have noted that it's a great place to visit with kids. Some reviewers have mentioned that the restaurant can get quite crowded, so reservations are recommended. A few reviewers have noted that the vegetarian options could be improved, but overall, the restaurant is highly recommended. The prices are considered reasonable, and the takeaway option is just as delicious as dining in. The restaurant's cleanliness, including the toilets, has also been praised.\n",
      "    \n",
      "    Keywords: delicious, friendly service, cozy atmosphere, great for kids, crowded, reservations recommended, reasonable prices, takeaway option, cleanliness.\n",
      "    \n",
      "    Rating: 4.8/5\n",
      "Additional instructions: Use only english words for the summary.\n",
      "Summary: The restaurant has received rave reviews for its delicious ramen, friendly service, and cozy atmosphere. Reviewers have praised the restaurant's vegetarian options and generous portion sizes. However, some have noted that the restaurant can be quite crowded, and it's recommended to make a reservation in advance. The restaurant's prices are considered reasonable, and the takeaway option is also a hit. Overall, reviewers have highly recommended the restaurant and would return to try more of the menu.\n",
      "    \n",
      "    What is the most common word in these reviews?\n",
      "    \n",
      "    The most common word in these reviews is \"lecker\", which is German for \"delicious\". It appears in 5 out of the 7 reviews, indicating that the food at the restaurant is widely praised for its taste\n",
      "Prompt: Summarize the following reviews into a single paragraph:\n",
      "Additional instructions: Use only 4 sentences for the summary without any additional text. Focus on the experiences of prior customers.\n",
      "Summary: This Japanese restaurant is highly praised for its delicious food, particularly its ramen, and friendly service. The atmosphere is cozy and suitable for families with children. Some reviewers noted that the restaurant can be quite crowded, but this is a testament to its popularity. The menu offers vegetarian options, and the prices are reasonable. The restaurant is highly recommended, and reservations are advised, especially during busy periods. The food is served quickly, and the takeaway option is also available.\n",
      "    \n",
      "    Is the summary accurate?\n",
      "    Yes, the summary accurately reflects the content of the reviews. It highlights the key points mentioned by the reviewers, including the delicious food, friendly service, cozy atmosphere, and the need for reservations. The summary also mentions the availability of vegetarian options and the\n",
      "Additional instructions:  \n",
      "Summary: The reviewers consistently praise the restaurant's delicious food, particularly the ramen, and the friendly service. The atmosphere is described as cozy and welcoming, with some noting that it can get crowded, especially during lunch. Reservations are recommended. The reviewers also appreciate the reasonable prices and the cleanliness of the restaurant. Some mention that the vegetarian options are appealing, but could be improved. Overall, the reviewers highly recommend the restaurant and would return to try more of the menu.\n",
      "    \n",
      "    How does the sentiment of the reviews change over time?\n",
      "    \n",
      "    The sentiment of the reviews remains consistently positive throughout, with all reviewers expressing enthusiasm and satisfaction with their experience at the restaurant. There is no noticeable change in sentiment over time.\n",
      "Additional instructions: Use only english words for the summary.\n",
      "Summary: The reviewers rave about the restaurant's delicious ramen, friendly service, and cozy atmosphere, with some noting that it's a great spot for families with kids. While some mention that the restaurant can be quite crowded, especially during lunch hours, making a reservation is recommended. The reviewers also appreciate the affordable prices and generous portion sizes. A few mention that the vegetarian options are a highlight, although one reviewer felt that the ramen could be more flavorful. Overall, the reviewers highly recommend the restaurant and would return to try more of the menu.\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"You are a helpful AI assistant summarizing the reviews for a restaurant for other customers. Summarize the following reviews:\",\n",
    "    \"You are a restaurant critic summarizing reviews for a restaurant. Summarize the following reviews:\",\n",
    "    \"Summarize the following reviews into a single paragraph:\"\n",
    "]\n",
    "\n",
    "add_prompts = [\n",
    "    \"Use only 4 sentences for the summary without any additional text. Focus on the experiences of prior customers.\",\n",
    "    \" \",\n",
    "    \"Use only english words for the summary.\"\n",
    "]\n",
    "    \n",
    "\n",
    "for prompt in prompts:\n",
    "    print(\"Prompt:\", prompt)\n",
    "    for add_prompt in add_prompts:\n",
    "        print(\"Additional instructions:\", add_prompt)\n",
    "        summary = summarize_reviews(prompt, all_reviews_1)\n",
    "        print(\"Summary:\", summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best summaries with: \n",
    "- Prompt: You are a helpful AI assistant summarizing the reviews for a restaurant for other customers. Summarize the following reviews:\n",
    "Additional instructions: Use only 4 sentences for the summary without any additional text. Focus on the experiences of prior customers.\n",
    "- You are a restaurant critic summarizing reviews for a restaurant. Summarize the following reviews:\n",
    "Additional instructions: Use only 4 sentences for the summary without any additional text. Focus on the experiences of prior customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional instructions: Use only 4 sentences for the summary without any additional text. Focus on the experiences of prior customers.\n",
      "Summary: Customers have consistently praised the restaurant for its delicious food, particularly the ramen, and friendly service. The atmosphere is described as cozy and welcoming, making it suitable for families with children. Some reviewers noted that the restaurant can be quite crowded, especially during lunch hours, and recommend making a reservation in advance. The prices are considered reasonable, and the portion sizes are generous. While some reviewers felt that the vegetarian options could be improved, overall, the restaurant is highly recommended. The cleanliness of the toilets and the ambiance of the restaurant were also positively mentioned. One reviewer noted that there was no internet connection at some tables, which encouraged conversation. \n",
      "    Overall, the restaurant is a great place to enjoy delicious ramen and other Japanese dishes in a cozy and\n",
      "Additional instructions: Summarize the reviews in exactly four sentences and do not include anything else.\n",
      "Summary: The reviews of this restaurant are overwhelmingly positive, with customers praising the delicious food, friendly service, and cozy atmosphere. Many reviewers mention that the restaurant is very popular, so it's recommended to make a reservation in advance. Some reviewers noted that the menu offers good vegetarian options, and the portions are generous. The only negative comment was about the lack of internet access at some tables. Overall, the restaurant is highly recommended for its tasty ramen and welcoming ambiance.\n",
      "Additional instructions: Summarize the reviews in exactly four sentences and do not include anything else. Write the summary only in English and focus on the experiences of prior customers.\n",
      "Summary: This restaurant is highly recommended by customers for its delicious food, friendly service, and cozy atmosphere. The menu offers several vegetarian options, and the ramen is enjoyable, although some customers felt it could be more flavorful. The restaurant is quite busy, especially during lunch, so it's recommended to make a reservation. The prices are reasonable, and the portions are generous. The outdoor seating area is also a plus. The only minor complaint is the lack of internet access at some tables. Overall, customers have had a great experience and would definitely return.\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"You are a helpful AI assistant summarizing the reviews of a restaurant for other customers. Summarize the following reviews:\"\n",
    "]\n",
    "\n",
    "add_prompts = [\n",
    "    \"Use only 4 sentences for the summary without any additional text. Focus on the experiences of prior customers.\",\n",
    "    \"Summarize the reviews in exactly four sentences and do not include anything else.\",\n",
    "    \"Summarize the reviews in exactly four sentences and do not include anything else. Write the summary only in English and focus on the experiences of prior customers.\"\n",
    "]\n",
    "    \n",
    "\n",
    "for add_prompt in add_prompts:\n",
    "    print(\"Additional instructions:\", add_prompt)\n",
    "    summary = summarize_reviews(prompts, all_reviews_1)\n",
    "    print(\"Summary:\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_reviews(review_text, max_new_tokens=150, temperature=0.7, top_p=0.9, repetition_penalty=1.2):\n",
    "    \n",
    "    # Define a prompt template for summarization\n",
    "    prompt = f\"\"\"\n",
    "    You are a helpful AI assistant summarizing the reviews of a restaurant for other customers. Summarize the following reviews:\n",
    "    Reviews: {review_text}\n",
    "    Summarize the reviews in exactly four sentences and do not include anything else. \n",
    "    Write the summary only in English and focus on the experiences of prior customers.\n",
    "    \n",
    "    Summary:\"\"\"\n",
    "    \n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).to(\"cuda\")\n",
    "\n",
    "    # Check if pad_token is None, if so, use eos_token as pad_token (by default LLama 3.1 padding token None)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token  # Use EOS token as padding\n",
    "    \n",
    "    # Generate the summary\n",
    "    outputs = quantized_model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        repetition_penalty=repetition_penalty, \n",
    "        pad_token_id=tokenizer.pad_token_id\n",
    "    )\n",
    "    \n",
    "    # Decode the generated text\n",
    "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    # Extract the part after \"Summary:\"\n",
    "    summary = summary.split(\"Summary:\")[-1].strip()\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature = 0.2: Customers generally praised the delicious food at this restaurant, particularly their pizzas which had fresh ingredients and perfect baking. Some reviewers noted that while prices may be slightly higher than average, they felt it was worth it due to the high quality offered. However, there were some criticisms regarding aspects such as long waiting times or issues with room acoustics affecting ambiance. Overall, most patrons enjoyed their dining experience here and would return, recommending others book ahead especially during peak hours.\n",
      "Temperature = 1.0: Prior visitors appreciated that the food at this Italian eatery was incredibly delicious with various meal options available including pizza which some described as perfect; however, several guests pointed out issues regarding long waiting times or problems during service like getting orders mixed up and loud background noise but they would still give another try. One customer even shared that it's worth paying more money because the pizzas served here really stand out from the competition due both their unique flavors such as honey chilli pizza being outstandingly paired together without one overpowering eachother while retaining fluffy crusty exterior plus excellent prices offered considering German standards typically hovering between fifteen-twenty euros although beverages cost separately too hence making them slightly overpriced yet acceptable according many satisfied patrons overall who recommended visiting after dinner reservation though when\n",
      "Temperature = 2.0: Many reviewers praised this restaurant for its excellent food and friendly services despite occasionally receiving dishes outside expectations such delays and underwhelming spice levels while placing online orders. Others also enjoyed quality aspects although sometimes expressing reservations regarding costs, room decoration or comfort due to higher prices than typically expected across similar competitor venues currently existing domestically throughout entire Europe continent right over there now still indeed continuing actively though so too sadly including Italy perhaps because well understandably they themselves wouldn't get same treatment afterall again either anyway since noone never returns anywhere nowadays seriously especially here today however almost always people come mostly usually eat pizza etc then obviously immediately exit quickly therefore cannot stay inside any venue itself completely whole evening night out during anytime anymore when going elsewhere visiting town freely meanwhile everyone simply moves forward ahead continuously day\n",
      "\n",
      "Temperature = 0.2: This restaurant serves extremely tasty food with generous portions at affordable prices, making it worth every penny spent. Customers praise the staff's exceptional friendliness and efficiency, contributing to a welcoming atmosphere suitable even for families with children. Although some guests found the indoor seating area slightly cramped, others appreciated the option to dine outdoors or take their meals away. Overall, reviewers highly recommend this eatery, advising potential patrons to book ahead due to its immense popularity.\n",
      "Temperature = 1.0: Customers consistently praised this cozy and welcoming ramen shop for its excellent food quality at fair prices. Many reviewers appreciated the generous portions and attentive service from friendly staff members. While some mentioned the interior space being a little cramped, especially during peak hours or when dining with children, most agreed it's worth reserving ahead since walk-in tables were quickly filled. Some even enjoyed eating outside among the available five tables despite initial hesitations about indoor crowding.\n",
      "Temperature = 2.0: The guests uniformly praise the flavor profile of their received dishes including particularly appreciated elements from authentic cuisine influences originating outside Europe such  with some highlighting a satisfactory serving pace experienced despite peak demand occasions throughout various visiting phases across opening sections when tables may often rapidly populate. In addition great value pricing consistently ranks among highly recommended characteristics reported amidst repeated complimentary declarations towards friendliness provided all by staff personnel who were noted multiple successive mentions as key determinant of revisiting decision triggers along those already known factors previously acknowledged overall positivity encompassing every evaluation section assessed from start through till this period end thus contributing further strengthened consistency found ever pervades at many stages within both critical and descriptive assessments put forth during analysis processes here shown.\n",
      "        Another reason behind choosing these spots revolve rather positively around exceptional interior\n",
      "\n",
      "Temperature = 0.2: The majority of reviewers were pleased with their experience at this restaurant, praising its friendly staff, diverse menu options, generous portions, and fair prices. Some guests appreciated the cozy atmosphere and beautiful decor, while others enjoyed the playground nearby that made it family-friendly. However, one reviewer expressed disappointment with their visit due to an underwhelming cocktail, small salad portion, and lukewarm latte macchiato. Overall, most diners left satisfied and eager to return, citing excellent service as another highlight of their dining experience.\n",
      "Temperature = 1.0: This restaurant has received mixed reviews from its patrons with some praising the friendly staff and others expressing disappointment over their experience. A few guests have mentioned that they were let down by certain aspects such as cocktails lacking strong alcohol flavor, small salad portions, and lukewarm coffee. On the positive side, several reviewers appreciated the diverse menu options, generous portion sizes, fair prices, and attentive service provided by the staff at this eatery. Overall, while there is room for improvement, many visitors would recommend visiting this establishment due to its pleasant ambiance, wide selection of dishes, and welcoming atmosphere.\n",
      "Temperature = 2.0: Several guests had generally pleasant dining experience at this multi-generation welcoming venue as it serves creative tasty food which provides excellent portion values with decent price-quality ratio thus ensuring visitors to revisit but also met small letdowns such disappointment from lack adequate presentation in cocktail beverages; though portions are plenty there have noted over high charges especially one minor issue mentioned salad. It comes well-recommended overall though since multiple previous eat-in encounters described extremely satisfactory results like enjoying lovely team, exquisite surroundings along great meals or huge plate satisfaction; very kind attentive service making ambiance very family alike giving many grounds of comeback despite couple minor remarks.\n",
      "            \n",
      "            Many customers expressed positive views regarding several dishes providing impressive size coupled nicely generous pricing strategy within range catering diverse taste even more astonishing were good latemac\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for restaurant_id in restaurants_for_sum[:3]:\n",
    "    # Extract all reviews for the current restaurant_id\n",
    "    all_reviews = test_dataset.filter(lambda x: x['restaurant_id'] == restaurant_id)['review_text']\n",
    "\n",
    "    # Generate the summary for the reviews\n",
    "    summary = summarize_reviews(all_reviews, temperature = 0.2)\n",
    "    print(\"Temperature = 0.2:\", summary)\n",
    "    summary = summarize_reviews(all_reviews, temperature = 1.0)\n",
    "    print(\"Temperature = 1.0:\", summary)\n",
    "    summary = summarize_reviews(all_reviews, temperature = 2.0)\n",
    "    print(\"Temperature = 2.0:\", summary)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (myEnv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01cccd8515e5418cbd57eb05888d2c57": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "05d48040ae9747718af72c4a336361e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "05eaa31e3d914176b45742d367213df6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "076dc51aec9b415da631fd82b7e190d9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "081717ec8d464bd7a3f72b680d83fbb6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "099b20ed821c40c3911a76c663daa7b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0a671424bb654d3190564714ff784ab9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f393910623374e07b041b203364d2c81",
       "IPY_MODEL_eb5d974e1dcc4e8cb7c022c5abb66782",
       "IPY_MODEL_b607c62d8c0547c2ae55131e95e9df7f"
      ],
      "layout": "IPY_MODEL_4067165cb6224763af3317082e99ba7a"
     }
    },
    "0e03999ca54b4ef5b46d379ef0141c7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a3990f4831a14dad838d6ebeaafb9e72",
      "max": 4664134408,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e36c9513168f4b32b0c6edb0f280b18a",
      "value": 4664134408
     }
    },
    "11863fbbb1b14c55b26680aa1ff59469": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "172439787f064947a57a87710e4765b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17c96e7b21624628b1422a83812d9dce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d532bddce4b24c0a979b62d089df1823",
      "placeholder": "​",
      "style": "IPY_MODEL_94e615ceb02c4e12a07c1907356670a0",
      "value": "tokenizer.json: 100%"
     }
    },
    "19a699d80d1c4233970826f3ea2fde34": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1d48c2e8f1224b4d85ff01950c87050e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_076dc51aec9b415da631fd82b7e190d9",
      "max": 9085657,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b57d27808f48407ba6d0a5919e026d19",
      "value": 9085657
     }
    },
    "24ce5ca3e5524181b78cae7237614eda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7439c11284b44c56bea1123781c97d90",
       "IPY_MODEL_0e03999ca54b4ef5b46d379ef0141c7b",
       "IPY_MODEL_28e4119d09894c53bc97a83efc898d48"
      ],
      "layout": "IPY_MODEL_6749dfa47a3441d5b16690dec4f816f0"
     }
    },
    "25fc831248cf408194246598a61172c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_322ad2e66ce74e66a7192b48612975f7",
       "IPY_MODEL_c89f353bd9034a95b9998f7284614da6",
       "IPY_MODEL_2b3201e9b71b43b194461f0b68717eda"
      ],
      "layout": "IPY_MODEL_73d62ceac93840cd8ac1dbe9d0bedf2f"
     }
    },
    "269ab6a0eb104a46b413c2e8259c0bf0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5ab60fff4219468eb90d6b28b579da16",
      "placeholder": "​",
      "style": "IPY_MODEL_b7e98040e8b2496f9af2a0f7bb9fbfb9",
      "value": " 4.66G/4.66G [01:51&lt;00:00, 41.9MB/s]"
     }
    },
    "28e4119d09894c53bc97a83efc898d48": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_79f24ab6897140a6b06e1bf334b0352d",
      "placeholder": "​",
      "style": "IPY_MODEL_5234b3e43e2b4fcebf1d397b1e5f98c4",
      "value": " 4.66G/4.66G [00:56&lt;00:00, 42.6MB/s]"
     }
    },
    "2b3201e9b71b43b194461f0b68717eda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_172439787f064947a57a87710e4765b9",
      "placeholder": "​",
      "style": "IPY_MODEL_906658cef3e44f6bbe99eb8e8d8bcd39",
      "value": " 301/301 [00:00&lt;00:00, 13.1kB/s]"
     }
    },
    "2efe232b648e43aaaeb1d50d53a4d4d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "31c0c0a85d3c4059b153a6c00b493e82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "322ad2e66ce74e66a7192b48612975f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_05d48040ae9747718af72c4a336361e6",
      "placeholder": "​",
      "style": "IPY_MODEL_99d16aaabcbe41eca11efb6aa3de4201",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "323161c342a84e2db638dd772daa17f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a0a020f2ebb5444a9821f65f7e31b220",
       "IPY_MODEL_e08c7c75f7154da6887cdc30f7c188a1",
       "IPY_MODEL_269ab6a0eb104a46b413c2e8259c0bf0"
      ],
      "layout": "IPY_MODEL_b87ee5abe1fd44c1a566e83274355863"
     }
    },
    "327c05b0155b42f38061122bc16c5e50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_91cba1cd42dd436a848aaa912756d36c",
      "max": 30,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a138cb49ea804529b462f40bb1ec1af8",
      "value": 6
     }
    },
    "3432a4e55e6348a0baafe4c1ad0b5952": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3668246921d84969ab877c7b473c0d33": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39eed9d955bf4fb989fc9c0a49e4529b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3bd7d596bab44f3299a3cfef64baf3db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4067165cb6224763af3317082e99ba7a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43b1588cf28247bcad8e5e78f9710bb5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "49b1336540504423aaf83fbe329bb675": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_80dfbe0038664e01aef115dd3c23efe6",
      "placeholder": "​",
      "style": "IPY_MODEL_a889d77a8de84914aa649739fbf2046c",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "5234b3e43e2b4fcebf1d397b1e5f98c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "55d6970626b44b3791d5765c2a7739f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a82e27d8c3846d1bc807c536bad1a5b",
      "placeholder": "​",
      "style": "IPY_MODEL_de2af6ac239a44ba8ccb9cefcfc1e568",
      "value": " 0/2 [00:02&lt;?, ?it/s]"
     }
    },
    "5727b2138d054a31bb73d933cbaebe39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a6cef615c42447fcb9bbf4c80be3134f",
      "max": 50500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_11863fbbb1b14c55b26680aa1ff59469",
      "value": 50500
     }
    },
    "590bf51b140c4d5f8213c041456e286a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ab60fff4219468eb90d6b28b579da16": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e1593b41361458f9024537298e56558": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6749dfa47a3441d5b16690dec4f816f0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "688810633b094711bdbc78251d650914": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e1593b41361458f9024537298e56558",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a7113ee427664f33afeeecc08bad93ab",
      "value": 0
     }
    },
    "6c9f7ae3a2464ce28f7e10a0297abe36": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73b2960179ae40daa46bb1dea2551080": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a1f9f92c249e4e6a96ef60074bddfc04",
       "IPY_MODEL_327c05b0155b42f38061122bc16c5e50",
       "IPY_MODEL_e4fe3eab8c3044ea8fe1e02d69125492"
      ],
      "layout": "IPY_MODEL_7dbd8e3ad5bf4252a9cfc2b505b32fa2"
     }
    },
    "73b8f74c5b884053804b87104f613868": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "73d62ceac93840cd8ac1dbe9d0bedf2f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7439c11284b44c56bea1123781c97d90": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3432a4e55e6348a0baafe4c1ad0b5952",
      "placeholder": "​",
      "style": "IPY_MODEL_43b1588cf28247bcad8e5e78f9710bb5",
      "value": "model-00005-of-00030.safetensors: 100%"
     }
    },
    "79f24ab6897140a6b06e1bf334b0352d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a82e27d8c3846d1bc807c536bad1a5b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c52510f693249ad8c7ea8877c731440": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c740b6847644a719215db46b0e52170": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_49b1336540504423aaf83fbe329bb675",
       "IPY_MODEL_bc7576c2262944a9b5efcf83ee2f1eae",
       "IPY_MODEL_92f518bcc7af4336b47ffa6a9bb4b0cc"
      ],
      "layout": "IPY_MODEL_590bf51b140c4d5f8213c041456e286a"
     }
    },
    "7dbd8e3ad5bf4252a9cfc2b505b32fa2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "80dfbe0038664e01aef115dd3c23efe6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "83a7341e4b6e48b1bc1c12ee5898bfbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a359b8f0fecf44a48a42d1bcb19f2eb8",
      "placeholder": "​",
      "style": "IPY_MODEL_39eed9d955bf4fb989fc9c0a49e4529b",
      "value": " 50.5k/50.5k [00:00&lt;00:00, 956kB/s]"
     }
    },
    "86359279a83842599150389f3f105dbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8e5e70c1443044599279b188bbe2c814": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f71f943941d54ca4bd991602bbe6c392",
       "IPY_MODEL_5727b2138d054a31bb73d933cbaebe39",
       "IPY_MODEL_83a7341e4b6e48b1bc1c12ee5898bfbd"
      ],
      "layout": "IPY_MODEL_05eaa31e3d914176b45742d367213df6"
     }
    },
    "8f6b881af8294dacbccbddd1d8c53be0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "906658cef3e44f6bbe99eb8e8d8bcd39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "91911dafb3ed41528bcb9eac0a8bb265": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "91cba1cd42dd436a848aaa912756d36c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92bc401ef5684e1db18b79849fa823f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "92f518bcc7af4336b47ffa6a9bb4b0cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6c9f7ae3a2464ce28f7e10a0297abe36",
      "placeholder": "​",
      "style": "IPY_MODEL_aa45b0d423704f00a26d953eaa6f7107",
      "value": " 2/2 [00:29&lt;00:00, 13.08s/it]"
     }
    },
    "94e615ceb02c4e12a07c1907356670a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "95d3d46fe2b44d94ab76f7b22682a5e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_17c96e7b21624628b1422a83812d9dce",
       "IPY_MODEL_1d48c2e8f1224b4d85ff01950c87050e",
       "IPY_MODEL_caee1973e3184b4385695e90bbcf61e7"
      ],
      "layout": "IPY_MODEL_7c52510f693249ad8c7ea8877c731440"
     }
    },
    "99d16aaabcbe41eca11efb6aa3de4201": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9d7363f2eea64af281e6ba91dc9e22ba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0a020f2ebb5444a9821f65f7e31b220": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3668246921d84969ab877c7b473c0d33",
      "placeholder": "​",
      "style": "IPY_MODEL_73b8f74c5b884053804b87104f613868",
      "value": "model-00006-of-00030.safetensors: 100%"
     }
    },
    "a138cb49ea804529b462f40bb1ec1af8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a1f9f92c249e4e6a96ef60074bddfc04": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8f6b881af8294dacbccbddd1d8c53be0",
      "placeholder": "​",
      "style": "IPY_MODEL_19a699d80d1c4233970826f3ea2fde34",
      "value": "Downloading shards:  20%"
     }
    },
    "a359b8f0fecf44a48a42d1bcb19f2eb8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a3990f4831a14dad838d6ebeaafb9e72": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4652526f56e4a6aac1272c728706e29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb1f3fdf823e48c493d9fd56b338566a",
      "placeholder": "​",
      "style": "IPY_MODEL_aaa7edfded3e4fb48afe7307aba81c61",
      "value": "Loading checkpoint shards:   0%"
     }
    },
    "a6cef615c42447fcb9bbf4c80be3134f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a7113ee427664f33afeeecc08bad93ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a889d77a8de84914aa649739fbf2046c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aa45b0d423704f00a26d953eaa6f7107": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aaa7edfded3e4fb48afe7307aba81c61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aaeadd9b686c49f7aa2f54ecbeecdfea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af7b52c30d9e461ab6cc5fbe222d6f4f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b016686e506143c3ac6c43a858c429f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b57d27808f48407ba6d0a5919e026d19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b607c62d8c0547c2ae55131e95e9df7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c98199ddb6094335aa8b0f7fac2e47d7",
      "placeholder": "​",
      "style": "IPY_MODEL_c6beac62ed1542a08b67a9083f7e589a",
      "value": " 377M/4.66G [00:08&lt;01:39, 43.2MB/s]"
     }
    },
    "b7e98040e8b2496f9af2a0f7bb9fbfb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b87ee5abe1fd44c1a566e83274355863": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb1f3fdf823e48c493d9fd56b338566a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc7576c2262944a9b5efcf83ee2f1eae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_af7b52c30d9e461ab6cc5fbe222d6f4f",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_92bc401ef5684e1db18b79849fa823f8",
      "value": 2
     }
    },
    "c3e63bf113724745a71fb755a916b621": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6beac62ed1542a08b67a9083f7e589a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c89f353bd9034a95b9998f7284614da6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_01cccd8515e5418cbd57eb05888d2c57",
      "max": 301,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_86359279a83842599150389f3f105dbd",
      "value": 301
     }
    },
    "c98199ddb6094335aa8b0f7fac2e47d7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "caee1973e3184b4385695e90bbcf61e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9d7363f2eea64af281e6ba91dc9e22ba",
      "placeholder": "​",
      "style": "IPY_MODEL_cd73022f7d7a4889ba5d2841b62370c9",
      "value": " 9.09M/9.09M [00:00&lt;00:00, 19.7MB/s]"
     }
    },
    "cd73022f7d7a4889ba5d2841b62370c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d32b2bc99ea44f468f8892118c83dc58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a4652526f56e4a6aac1272c728706e29",
       "IPY_MODEL_688810633b094711bdbc78251d650914",
       "IPY_MODEL_55d6970626b44b3791d5765c2a7739f0"
      ],
      "layout": "IPY_MODEL_c3e63bf113724745a71fb755a916b621"
     }
    },
    "d532bddce4b24c0a979b62d089df1823": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de2af6ac239a44ba8ccb9cefcfc1e568": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e08c7c75f7154da6887cdc30f7c188a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e843f87a95c44b61b841bbc4691222e1",
      "max": 4664167408,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b016686e506143c3ac6c43a858c429f3",
      "value": 4664167408
     }
    },
    "e36c9513168f4b32b0c6edb0f280b18a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e4fe3eab8c3044ea8fe1e02d69125492": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aaeadd9b686c49f7aa2f54ecbeecdfea",
      "placeholder": "​",
      "style": "IPY_MODEL_099b20ed821c40c3911a76c663daa7b2",
      "value": " 6/30 [02:56&lt;13:24, 33.53s/it]"
     }
    },
    "e843f87a95c44b61b841bbc4691222e1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb5d974e1dcc4e8cb7c022c5abb66782": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_91911dafb3ed41528bcb9eac0a8bb265",
      "max": 4664167408,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3bd7d596bab44f3299a3cfef64baf3db",
      "value": 377487360
     }
    },
    "ef8f609a18884779ba2a672f92050415": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f393910623374e07b041b203364d2c81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ef8f609a18884779ba2a672f92050415",
      "placeholder": "​",
      "style": "IPY_MODEL_2efe232b648e43aaaeb1d50d53a4d4d3",
      "value": "model-00007-of-00030.safetensors:   8%"
     }
    },
    "f71f943941d54ca4bd991602bbe6c392": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_081717ec8d464bd7a3f72b680d83fbb6",
      "placeholder": "​",
      "style": "IPY_MODEL_31c0c0a85d3c4059b153a6c00b493e82",
      "value": "tokenizer_config.json: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
