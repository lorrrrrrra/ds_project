{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from urllib.parse import urlencode\n",
    "import googlemaps\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_basics = pd.read_csv(\"C:/Users/admin/Downloads/API_Basics.csv\")\n",
    "API_general = pd.read_csv(\"C:/Users/admin/Downloads/API_General.csv\")\n",
    "API_additional = pd.read_csv(\"C:/Users/admin/Downloads/API_Additional.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting information for the cities\n",
    "was already done, no need to change anda lso no need to run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API_basics[\"city\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# api_key = \"AIzaSyCmU1xOszaGFTFecpdG8aEb7AGOGDOvB9c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to get the city boundaries\n",
    "# def get_city_boundaries(city_name):\n",
    "#     # Initialize the Google Maps client\n",
    "#     gmaps = googlemaps.Client(key=api_key) # googlemaps package\n",
    "    \n",
    "#     # Get the city boundaries\n",
    "#     geocode_result = gmaps.geocode(city_name)\n",
    "\n",
    "#     # save the boundaries\n",
    "#     low_lat = geocode_result[0]['geometry']['bounds']['southwest']['lat']\n",
    "#     low_long = geocode_result[0]['geometry']['bounds']['southwest']['lng']\n",
    "#     high_lat = geocode_result[0]['geometry']['bounds']['northeast']['lat']\n",
    "#     high_long = geocode_result[0]['geometry']['bounds']['northeast']['lng']\n",
    "\n",
    "    \n",
    "#     return low_lat, low_long, high_lat, high_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cities = pd.DataFrame(columns=['city_id', 'name', 'country', 'low_lat_value', 'low_long_value', 'high_lat_value', 'high_long_value', 'number_restaurants'])\n",
    "\n",
    "# for index, city in enumerate(API_basics[\"city\"].unique(), start=0):\n",
    "#     low_lat, low_long, high_lat, high_long = get_city_boundaries(city)\n",
    "    \n",
    "#     city_df = pd.DataFrame({\n",
    "#         'city_id': [index],\n",
    "#         'name': [city],\n",
    "#         'country': 'Germany',  # Assuming country is Germany\n",
    "#         'low_lat_value': [low_lat],\n",
    "#         'low_long_value': [low_long],\n",
    "#         'high_lat_value': [high_lat],\n",
    "#         'high_long_value': [high_long],\n",
    "#         'number_restaurants': [None]\n",
    "#     })\n",
    "\n",
    "#     cities = pd.concat([cities, city_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cities['name'] = cities['name'].str.replace('ü', 'ue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, row in cities.iterrows():\n",
    "#     city_id = row['city_id']\n",
    "#     filtered_df = API_basics[API_basics['city_id'] == city_id]\n",
    "#     unique_restaurants_count = filtered_df['id'].nunique()\n",
    "#     cities.at[index, 'number_restaurants'] = unique_restaurants_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cities.to_csv('cities.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing API Tables for input into the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Basics\n",
    "- getting lat and long data works \n",
    "- we don't need the primarytypeDisplayName as we have the primaryType\n",
    "- I have not yet figured out, how to get the name from the json... :( maybe we can cut it after text and before languageCode? I think that will be the easiest solution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current structure of the table in the database\n",
    "# CREATE TABLE Restaurant_Basics (\n",
    "#     restaurant_id VARCHAR PRIMARY KEY,\n",
    "#     city_id INT REFERENCES Cities(city_id),\n",
    "#     name VARCHAR,\n",
    "#     primary_type VARCHAR,\n",
    "#     types VARCHAR,\n",
    "#     business_status BOOLEAN,\n",
    "#     pure_service_area BOOLEAN,\n",
    "#     address VARCHAR,\n",
    "#     lat_value FLOAT,\n",
    "#     long_value FLOAT\n",
    "# );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the city name into an id\n",
    "cities = pd.read_csv('cities.csv')\n",
    "city_dict = pd.Series(cities.city_id.values, index=cities.name).to_dict()\n",
    "\n",
    "API_basics['city'] = API_basics['city'].str.replace('ü', 'ue')\n",
    "API_basics['city_id'] = API_basics['city'].map(city_dict)\n",
    "API_basics.drop(\"city\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting lat and long data\n",
    "for index, row in API_basics.iterrows():\n",
    "    location_value = json.loads(row['location'].replace(\"'\", '\"'))\n",
    "    API_basics.at[index, 'lat_value'] = location_value['latitude']\n",
    "    API_basics.at[index, 'long_value'] = location_value['longitude']\n",
    "\n",
    "API_basics.drop(\"location\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the primaryTypeDisplayName\n",
    "API_basics.drop(\"primaryTypeDisplayName\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming the column name to better understand that this is not the \"finished\" name but rather the json file with the name in it\n",
    "API_basics.rename(columns = {'name': 'name_json'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting name and language code for name \n",
    "for index, row in API_basics.iterrows():\n",
    "    if row['name_json'][9] == \"'\":\n",
    "        try:\n",
    "            json_string = row['name_json'].replace(\"'\", '\"')\n",
    "            json_string = json_string.replace(r'\\\"', '\"')  \n",
    "            json_string = json_string.replace(\"'text'\", '\"text\"').replace(\"'languageCode'\", '\"languageCode\"').replace(\"'de'\", '\"de\"').replace(\"'en'\", '\"en')\n",
    "        \n",
    "            parsed_data = json.loads(json_string)\n",
    "            \n",
    "            # Extrahiere 'languageCode' und 'text' aus den JSON-Daten\n",
    "            API_basics.at[index, 'language_code_name'] = parsed_data['languageCode']\n",
    "            API_basics.at[index, 'name'] = parsed_data['text']\n",
    "    \n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error decoding JSON for index {index}: {row['name_json']}\")\n",
    "\n",
    "    \n",
    "    elif row['name_json'][9] == '\"':\n",
    "        try:\n",
    "            json_string = row['name_json'].replace(\"'text'\", '\"text\"').replace(\"'languageCode'\", '\"languageCode\"').replace(\"'de'\", '\"de\"').replace(\"'en'\", '\"en')\n",
    "            parsed_data = json.loads(json_string)\n",
    "\n",
    "            # Extrahiere 'languageCode' und 'text' aus den JSON-Daten\n",
    "            API_basics.at[index, 'language_code_name'] = parsed_data['languageCode']\n",
    "            API_basics.at[index, 'name'] = parsed_data['text']\n",
    "    \n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"b - Error decoding JSON for index {index}: {row['name']}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_basics['name'][7].replace(\"'\", '\"').replace('\"{', '{').replace('}\"', '}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = API_basics['name'][10].replace(\"'text'\", '\"text\"').replace(\"'languageCode'\", '\"languageCode\"').replace(\"'de'\", '\"de\"').replace(\"'en'\", '\"en\"')\n",
    "print(string)\n",
    "# print(re.sub(r\"(?<=:)([^,}]+)(?=\\s*[},])\", lambda match: match.group(0).replace(\"'\", \"\\\"\"), string))\n",
    "\n",
    "# re.sub(r\"(?<!\\\\)'\", '\"', json_string)\n",
    "# json.loads(string)\n",
    "\n",
    "json.loads('{\"text\": \"Bakery Schmid \\'cafe cult\\'\", \"languageCode\": \"en\"}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_basics['name'][10].replace(\"'text'\", '\"text\"').replace(\"'languageCode'\", '\"languageCode\"').replace(\"'de'\", '\"de\"').replace(\"'en'\", '\"en\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_basics['name'][10][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_and_language(input_string):\n",
    "    # Regulärer Ausdruck, um sowohl einfache als auch doppelte Anführungszeichen zu berücksichtigen\n",
    "    text_match = re.search(r\"(?:'text'|\\\"text\\\").*?[\\'\\\"]([^\\'\\\"]*)[\\'\\\"]\", input_string)\n",
    "    language_code_match = re.search(r\"(?:'languageCode'|\\\"languageCode\\\").*?[\\'\\\"]([^\\'\\\"]*)[\\'\\\"]\", input_string)\n",
    "    \n",
    "    if text_match and language_code_match:\n",
    "        # Extrahierter Text\n",
    "        text = text_match.group(1)\n",
    "        # Extrahierter languageCode\n",
    "        language_code = language_code_match.group(1)\n",
    "        return text, language_code\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_text_and_language(API_basics['name'][7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping duplicates (important as there are some!)\n",
    "duplicates = API_basics[API_basics.duplicated(subset=['name'], keep=False)]\n",
    "API_basics = API_basics.drop_duplicates(subset=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming columns to match the database, database columns are named in snake_case NOT camelCase \n",
    "API_basics = API_basics.rename(columns={'id': 'restaurant_id', 'primaryType': 'primary_type', 'primaryTypeDisplayName': 'primary_type_display', \n",
    "                                        'businessStatus': 'business_status', 'pureServiceAreaBusiness': 'pure_service_area',\n",
    "                                        'formattedAddress': 'address'})\n",
    "API_basics = API_basics[['restaurant_id', 'city_id', 'name', 'primary_type', 'primary_type_display', 'types', 'business_status', \n",
    "                        'pure_service_area', 'address', 'lat_value', 'long_value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_basics.to_csv('API_basics.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API general\n",
    "the only thing that is missing here are the opening hours, every other column is already processed and uploaded at the database (it would the best to save the opening hours as a json as we can then just input them in the table without changing its structure)\n",
    "\n",
    "\n",
    "-> my problem was that I didn't know which day corresponds to which as there are only 6 in the json..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current structure of the table in the database\n",
    "# CREATE TABLE restaurant_general (\n",
    "#     restaurant_id VARCHAR PRIMARY KEY,\n",
    "#     containing_places BOOLEAN,\n",
    "#     phone_number VARCHAR,\n",
    "#     website_uri VARCHAR,\n",
    "#     summary JSON,\n",
    "#     opening_hours JSON,\n",
    "#     price_level VARCHAR,\n",
    "#     price_range JSON,\n",
    "#     google_rating FLOAT,\n",
    "#     google_user_rating_count FLOAT\n",
    "# );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API_general['regularOpeningHours'][1]\n",
    "# result = re.sub(r\"'weekdayDescriptions':.*\", \"'weekdayDescriptions': []}\", API_general['regularOpeningHours'][0])\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, row in API_general.iterrows():\n",
    "#     if row\n",
    "#     string = re.sub(r\"'weekdayDescriptions':.*\", \"'weekdayDescriptions': []}\", row['regularOpeningHours'])\n",
    "#     json_string = string.replace(\"'\", '\"').replace(\"True\", \"true\")\n",
    "#     opening_hours = json.loads(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API_general['regularOpeningHours'][1] == np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_string = result.replace(\"'\", '\"').replace(\"True\", \"true\")\n",
    "# print(json_string)\n",
    "# json= json.loads(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'startPrice': {'currencyCode': 'EUR', 'units': '1'},\n",
       " 'endPrice': {'currencyCode': 'EUR', 'units': '10'}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(API_general['priceRange'][0].replace(\"'\", '\"'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_to_json(string):\n",
    "    if pd.notna(string):\n",
    "        try: \n",
    "            json_value = json.loads(string.replace(\"'\", '\"'))\n",
    "            return json_value\n",
    "        except Exception as e:\n",
    "            print(\"Fehler:\", e)\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Laid-back hotel featuring a bar, a restaurant & a terrace, plus meeting & event space.',\n",
       " 'languageCode': 'en'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_to_json(API_general['editorialSummary'][23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehler: Expecting ',' delimiter: line 1 column 98 (char 97)\n",
      "Fehler: Expecting ',' delimiter: line 1 column 97 (char 96)\n",
      "Fehler: Expecting ',' delimiter: line 1 column 101 (char 100)\n",
      "Fehler: Expecting ',' delimiter: line 1 column 69 (char 68)\n",
      "Fehler: Expecting ',' delimiter: line 1 column 81 (char 80)\n",
      "Fehler: Expecting ',' delimiter: line 1 column 97 (char 96)\n",
      "Fehler: Expecting ',' delimiter: line 1 column 100 (char 99)\n",
      "Fehler: Expecting ',' delimiter: line 1 column 44 (char 43)\n",
      "Fehler: Expecting ',' delimiter: line 1 column 98 (char 97)\n",
      "Fehler: Expecting ',' delimiter: line 1 column 98 (char 97)\n",
      "Fehler: Expecting ',' delimiter: line 1 column 17 (char 16)\n"
     ]
    }
   ],
   "source": [
    "API_general[\"price_range\"] = API_general[\"priceRange\"].apply(make_to_json)\n",
    "API_general[\"editorial_summary\"] = API_general[\"editorialSummary\"].apply(make_to_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(API_general[\"price_range\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['restaurant_id', 'containing_places', 'phone_number', 'website_uri',\n",
       "       'price_level', 'price_range', 'google_rating',\n",
       "       'google_user_rating_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "API_general.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming columns to match the database\n",
    "API_general = API_general.rename(columns={'id': 'restaurant_id', 'containingPlaces': 'containing_places', 'internationalPhoneNumber': 'phone_number', \n",
    "                                        'placesWebsiteUri': 'website_uri', 'priceLevel': 'price_level', \n",
    "                                        'userRatingCount': 'google_user_rating_count', 'rating': 'google_rating'})\n",
    "API_general = API_general[['restaurant_id', 'containing_places', 'phone_number', 'website_uri', 'price_level', 'price_range', 'google_rating', \n",
    "                        'google_user_rating_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_general.to_csv('API_general.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API additional\n",
    "should be all done and is already uploaded to the database on the server, but you can have a look at it whether it is correct or I made a mistake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_additional['accessibilityOptions'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting all of the keys in parking Options:\n",
    "all_keys = set()\n",
    "\n",
    "for entry in API_additional['parkingOptions']:\n",
    "    if not pd.isna(entry):  # Wenn der Eintrag nicht None oder leer ist\n",
    "        try:\n",
    "            # Lade den JSON-String in ein Dictionary\n",
    "            json_string = entry.replace(\"'\", '\"').replace(\"True\", \"true\").replace(\"False\", \"false\")\n",
    "            parking_dict = json.loads(json_string)\n",
    "            \n",
    "            # Füge die Schlüssel des Dictionaries zum Set hinzu\n",
    "            all_keys.update(parking_dict.keys())\n",
    "        except (json.JSONDecodeError, TypeError) as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "\n",
    "print(all_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_parking_info(parking_options_string):\n",
    "    try:\n",
    "        if not pd.isna(parking_options_string):\n",
    "            json_string = parking_options_string.replace(\"'\", '\"').replace(\"True\", \"true\").replace(\"False\", \"false\")\n",
    "            parking_dict = json.loads(json_string)\n",
    "    \n",
    "            # Extrahiere relevante Informationen, Standardwert False falls der Schlüssel nicht vorhanden ist\n",
    "            free_parking_lot = parking_dict.get('freeParkingLot', np.nan)\n",
    "            paid_parking_lot = parking_dict.get('paidParkingLot', np.nan)\n",
    "            free_street_parking = parking_dict.get('freeStreetParking', np.nan)\n",
    "            paid_street_parking = parking_dict.get('paidStreetParking', np.nan)\n",
    "            free_garage_parking = parking_dict.get('freeGarageParking', np.nan)\n",
    "            paid_garage_parking = parking_dict.get('paidGarageParking', np.nan)\n",
    "            valet_parking = parking_dict.get('valetParking', np.nan)\n",
    "\n",
    "        else:\n",
    "            free_parking_lot = np.nan\n",
    "            paid_parking_lot = np.nan\n",
    "            free_street_parking = np.nan\n",
    "            paid_street_parking = np.nan\n",
    "            free_garage_parking = np.nan\n",
    "            paid_garage_parking = np.nan\n",
    "            valet_parking = np.nan\n",
    "            \n",
    "    \n",
    "    except (json.JSONDecodeError, TypeError) as e:\n",
    "        print(f\"Error decoding JSON: {e}\")\n",
    "        return (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan)   \n",
    "    \n",
    "    return (free_parking_lot, paid_parking_lot, free_street_parking, paid_street_parking, free_garage_parking, paid_garage_parking, valet_parking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying method to get all options\n",
    "API_additional[['free_parking_lot', 'paid_parking_lot', 'free_street_parking', 'paid_street_parking', 'free_garage_parking', 'paid_garage_parking', 'valet_parking']] = API_additional['parkingOptions'].apply(extract_parking_info).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting all of the keys in parking Options:\n",
    "all_keys = set()\n",
    "\n",
    "for entry in API_additional['paymentOptions']:\n",
    "    if not pd.isna(entry):  \n",
    "        try:\n",
    "            # loading the json-string to a dict\n",
    "            json_string = entry.replace(\"'\", '\"').replace(\"True\", \"true\").replace(\"False\", \"false\")\n",
    "            parking_dict = json.loads(json_string)\n",
    "            \n",
    "            # adding the keys of the dict to the set\n",
    "            all_keys.update(parking_dict.keys())\n",
    "        except (json.JSONDecodeError, TypeError) as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "\n",
    "print(all_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_payment_info(payment_options_string):\n",
    "    try:\n",
    "        if not pd.isna(payment_options_string):\n",
    "            json_string = payment_options_string.replace(\"'\", '\"').replace(\"True\", \"true\").replace(\"False\", \"false\")\n",
    "            parking_dict = json.loads(json_string)\n",
    "    \n",
    "            # extract relevant information, nan if key is not there\n",
    "            accepts_debit_cards = parking_dict.get('acceptsDebitCards', np.nan)\n",
    "            accepts_credit_cards = parking_dict.get('acceptsCreditCards', np.nan)\n",
    "            accepts_cash_only = parking_dict.get('acceptsCashOnly', np.nan)\n",
    "            accepts_nfc = parking_dict.get('acceptsNfc', np.nan)\n",
    "\n",
    "        else:\n",
    "            accepts_debit_cards = np.nan\n",
    "            accepts_credit_cards = np.nan\n",
    "            accepts_cash_only = np.nan\n",
    "            accepts_nfc = np.nan\n",
    "            \n",
    "    \n",
    "    except (json.JSONDecodeError, TypeError) as e:\n",
    "        print(f\"Error decoding JSON: {e}\")\n",
    "        return (np.nan, np.nan, np.nan, np.nan)   \n",
    "    \n",
    "    return (accepts_debit_cards, accepts_credit_cards, accepts_cash_only, accepts_nfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying method to get all options\n",
    "API_additional[['accepts_debit_cards', 'accepts_credit_cards', 'accepts_cash_only', 'accepts_nfc']] = API_additional['paymentOptions'].apply(extract_payment_info).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting all of the keys in accessibility Options:\n",
    "all_keys = set()\n",
    "\n",
    "for entry in API_additional['accessibilityOptions']:\n",
    "    if not pd.isna(entry):  # Wenn der Eintrag nicht None oder leer ist\n",
    "        try:\n",
    "            # loading the json-string to a dict\n",
    "            json_string = entry.replace(\"'\", '\"').replace(\"True\", \"true\").replace(\"False\", \"false\")\n",
    "            parking_dict = json.loads(json_string)\n",
    "            \n",
    "            # adding the keys of the dict to the set\n",
    "            all_keys.update(parking_dict.keys())\n",
    "        except (json.JSONDecodeError, TypeError) as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "\n",
    "print(all_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_accessibility_info(accessibility_options_string):\n",
    "    try:\n",
    "        if not pd.isna(accessibility_options_string):\n",
    "            json_string = accessibility_options_string.replace(\"'\", '\"').replace(\"True\", \"true\").replace(\"False\", \"false\")\n",
    "            parking_dict = json.loads(json_string)\n",
    "    \n",
    "            # extract relevant information, nan if key is not there\n",
    "            wheelchair_accessible_restroom = parking_dict.get('wheelchairAccessibleRestroom', np.nan)\n",
    "            wheelchair_accessible_entrance = parking_dict.get('wheelchairAccessibleEntrance', np.nan)\n",
    "            wheelchair_accessible_parking = parking_dict.get('wheelchairAccessibleParking', np.nan)\n",
    "            wheelchair_accessible_seating = parking_dict.get('wheelchairAccessibleSeating', np.nan)\n",
    "\n",
    "        else:\n",
    "            wheelchair_accessible_restroom = np.nan\n",
    "            wheelchair_accessible_entrance = np.nan\n",
    "            wheelchair_accessible_parking = np.nan\n",
    "            wheelchair_accessible_seating = np.nan\n",
    "            \n",
    "    \n",
    "    except (json.JSONDecodeError, TypeError) as e:\n",
    "        print(f\"Error decoding JSON: {e}\")\n",
    "        return (np.nan, np.nan, np.nan, np.nan)   \n",
    "    \n",
    "    return (wheelchair_accessible_restroom, wheelchair_accessible_entrance, wheelchair_accessible_parking, wheelchair_accessible_seating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying method to get all options\n",
    "API_additional[['wheelchair_accessible_restroom', 'wheelchair_accessible_entrance', 'wheelchair_accessible_parking', 'wheelchair_accessible_seating']] = API_additional['accessibilityOptions'].apply(extract_accessibility_info).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_additional.drop(\"parkingOptions\", axis=1, inplace=True)\n",
    "API_additional.drop(\"paymentOptions\", axis=1, inplace=True)\n",
    "API_additional.drop(\"accessibilityOptions\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_additional.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming columns to match the database\n",
    "API_additional = API_additional.rename(columns={'id': 'restaurant_id', 'curbsidePickup': 'curbside_pickup', 'dineIn': 'dine_in', \n",
    "                                        'liveMusic': 'live_music', 'outdoorSeating': 'outdoor_seating', 'servesBeer': 'serves_beer', \n",
    "                                        'servesBreakfast': 'serves_breakfast', 'servesBrunch': 'serves_brunch', \n",
    "                                        'servesCocktails': 'serves_cocktails', 'servesCoffee': 'serves_coffee', 'servesDessert': 'serves_dessert', \n",
    "                                        'servesDinner': 'serves_dinner', 'servesLunch': 'serves_lunch',\n",
    "                                        'servesVegetarianFood': 'serves_vegetarian_food', 'servesWine': 'serves_wine', 'allowsDogs': 'allows_dogs',\n",
    "                                        'goodForChildren': 'good_for_children', 'goodForGroups': 'good_for_groups',\n",
    "                                        'goodForWatchingSports': 'good_for_watching_sports', 'menuForChildren': 'menu_for_children'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting duplicates\n",
    "API_additional = API_additional.drop_duplicates(subset=['restaurant_id'])\n",
    "\n",
    "# changing np.nan to NULL\n",
    "API_additional = API_additional.where(pd.notna(API_additional), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_additional.to_csv('API_additional.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
