{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c591b3c0-bc54-4335-b87c-65915f8919f3",
   "metadata": {},
   "source": [
    "# Topic recognition\n",
    "## 1. Preparing the dataset for fine-tuning with the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b81c9e2c-9c11-4715-9cd2-742603cfb21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### for working on the BwCluster\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Replace with your Hugging Face token\n",
    "huggingface_token = \"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\"\n",
    "\n",
    "# Log in\n",
    "login(token=huggingface_token)\n",
    "\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, BitsAndBytesConfig, DataCollatorForLanguageModeling\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm \n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2336ab0-6f1e-4e19-ac89-f6c322e9b7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['review_id', 'restaurant_id', 'review_date', 'scraping_date', 'stars', 'dining_stars_food', 'dining_stars_service', 'dining_stars_atmosphere', 'review_text'],\n",
       "    num_rows: 285\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Prepare a training set\n",
    "# Load the dataset as a single split\n",
    "#dataset = load_dataset(\"csv\", data_files=\"/content/drive/MyDrive/Colab Notebooks/DSP/subratings_data.csv\", split=\"train\")\n",
    "dataset = load_dataset(\"csv\", data_files=\"subratings_data.csv\", split=\"train\")\n",
    "\n",
    "# Shuffle and split the dataset\n",
    "shuffled_dataset = dataset.shuffle(seed=42)\n",
    "split_dataset = shuffled_dataset.train_test_split(train_size=0.012, seed=42)\n",
    "\n",
    "# Access the training and testing subsets\n",
    "train_dataset = split_dataset[\"train\"]\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51e1836e-05e9-4145-aff2-d0e89ea26454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc385848a7ec45af95f2b992047a447b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Load the LLama 3.1 70 B model (since it performed the best)\n",
    "model_id = \"meta-llama/Llama-3.1-70B-Instruct\"\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True,\n",
    "                                         bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "                                         bnb_4bit_use_double_quant=True,\n",
    "                                         bnb_4bit_quant_type= \"nf4\"\n",
    "                                         )\n",
    "\n",
    "quantized_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, device_map=\"auto\", torch_dtype=torch.bfloat16, quantization_config=quantization_config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token # setting padding token (Llama doesnt have a padding token by default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2c82d7f-9d78-48ee-96a7-5adb64d12eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrem überteuert in schönem Ambiente. Ich habe das Klassische Frühstück für 17 Euro bestellt. Auf der Karte steht Brot, Marmelade, Käse, Schinken, Obst, Ei. Und ein Kaffee inklusive. Für den Preis erwartet man eine schöne Platte der aufgeführten Sachen. Folgendes bekommt man:\n",
      "\n",
      "Es kommt ein winziger Dessertteller mit ein bisschen aufgeschnittenem Obst und Gemüse. Ein hartgekochtes Ei, eine (!) Schinkenscheibe, bisschen Marmelade und drei kleine Stückchen Camembert. Und den Kaffee natürlich. Dazu kommt ein großer Brotkorb mit trockenem Brot. Aber man fragt sich, womit man das Brot essen soll, wenn die eine Scheibe Schinken schon verputzt ist. Mit dem Apfel und der Kiwi? Ich zahle 17 Euro für ein bisschen aufgeschnittenes Obst. Unter einem Frühstück für 17 Euro und der Beschreibung auf der Karte stelle ich mir etwas anderes vor.\n",
      "\n",
      "Das Ambiente ist aber schön, das Personal freundlich und man kann gut draußen sitzen.\n"
     ]
    }
   ],
   "source": [
    "review1 = train_dataset['review_text'][4]\n",
    "print(review1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27a497f2-44b9-49b3-b5a8-00f151e70caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Extrem überteuert in schönem Ambiente.',\n",
       " 'Ich habe das Klassische Frühstück für 17 Euro bestellt.',\n",
       " 'Auf der Karte steht Brot, Marmelade, Käse, Schinken, Obst, Ei.',\n",
       " 'Und ein Kaffee inklusive.',\n",
       " 'Für den Preis erwartet man eine schöne Platte der aufgeführten Sachen.',\n",
       " 'Folgendes bekommt man:',\n",
       " 'Es kommt ein winziger Dessertteller mit ein bisschen aufgeschnittenem Obst und Gemüse.',\n",
       " 'Ein hartgekochtes Ei, eine (!) Schinkenscheibe, bisschen Marmelade und drei kleine Stückchen Camembert.',\n",
       " 'Und den Kaffee natürlich.',\n",
       " 'Dazu kommt ein großer Brotkorb mit trockenem Brot.',\n",
       " 'Aber man fragt sich, womit man das Brot essen soll, wenn die eine Scheibe Schinken schon verputzt ist.',\n",
       " 'Mit dem Apfel und der Kiwi?',\n",
       " 'Ich zahle 17 Euro für ein bisschen aufgeschnittenes Obst.',\n",
       " 'Unter einem Frühstück für 17 Euro und der Beschreibung auf der Karte stelle ich mir etwas anderes vor.',\n",
       " 'Das Ambiente ist aber schön, das Personal freundlich und man kann gut draußen sitzen.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(r'(?<=[.!?])\\s+|\\n+', review1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e8c4f63-b477-4abe-b190-73fc329628da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_sentences_multi_label(review_text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Categorize sentences from the review into 'food', 'service', 'atmosphere' and 'price'.\n",
    "    Allow sentences to belong to multiple categories.\n",
    "    \"\"\"\n",
    "    # Define the multi-label prompt\n",
    "    prompt_template = (\"\"\"\n",
    "        For the following sentence, identify all applicable categories:'food', 'service', 'atmosphere', 'price'\n",
    "        If no category applies, respond 'none'. \n",
    "        \"Separate multiple categories with commas.\\n\\n\"\n",
    "        \"Sentence: {sentence}\\n\\n\"\n",
    "        \"Categories:\"\n",
    "    \"\"\")\n",
    "    \n",
    "    # Split review into sentences with delimiters ('.', '!', '?') but remove '\\n'\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+|\\n+', review_text)\n",
    "    \n",
    "    # Initialize result dictionary\n",
    "    categorized_sentences = {'food': [], 'service': [], 'atmosphere': [], 'price': []}\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        prompt = prompt_template.format(sentence=sentence.strip())\n",
    "        \n",
    "        inputs = tokenizer(\n",
    "            prompt,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512\n",
    "        ).to(\"cuda\")\n",
    "\n",
    "        # Generate category predictions\n",
    "        outputs = quantized_model.generate(\n",
    "            **inputs,\n",
    "            temperature=0.1,\n",
    "            pad_token_id=tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "        )\n",
    "\n",
    "        # Decode and parse the model's response\n",
    "        generated_text = tokenizer.decode(outputs[0][inputs['input_ids'].shape[-1]:], skip_special_tokens=True).strip().lower()\n",
    "        predicted_categories = [cat.strip() for cat in generated_text.split(',') if cat.strip() in categorized_sentences]\n",
    "\n",
    "        # Add the sentence to all relevant categories\n",
    "        for category in predicted_categories:\n",
    "            categorized_sentences[category].append(sentence.strip())\n",
    "    \n",
    "    return categorized_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "911ce8b5-367e-41c4-976c-b65fac50f513",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing reviews in batches: 100%|██████████| 5/5 [1:18:48<00:00, 945.60s/it] \n"
     ]
    }
   ],
   "source": [
    "### let the base model recognize the topics of each sentence\n",
    "\n",
    "train_topic = []\n",
    "\n",
    "batch_size = 64  # adjust based on GPU memory\n",
    "\n",
    "# Process the reviews in batches\n",
    "for i in tqdm(range(0, len(train_dataset['review_text']), batch_size), desc=\"Processing reviews in batches\"):\n",
    "    batch_reviews = train_dataset['review_text'][i:i+batch_size]\n",
    "\n",
    "    # For each batch, categorize sentences for food, service, and atmosphere\n",
    "    for review_text in batch_reviews:\n",
    "        categorized = categorize_sentences_multi_label(review_text)\n",
    "        train_topic.append({\n",
    "            'original_review': review_text,\n",
    "            'food_sentences': '. '.join(categorized['food']),\n",
    "            'service_sentences': '. '.join(categorized['service']),\n",
    "            'atmosphere_sentences': '. '.join(categorized['atmosphere']),\n",
    "            'price_sentences': '. '.join(categorized['price'])\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c73a3414-9fd0-4f80-9e5e-4846e0ae813b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### save the results\n",
    "# Convert the list of dictionaries to a Pandas DataFrame\n",
    "df_train_topic = pd.DataFrame(train_topic)\n",
    "df_train_topic.to_excel(\"train_topic.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a42437-7894-4a71-aae0-f68792928a7d",
   "metadata": {},
   "source": [
    "## 2. Revision of data\n",
    "2 group members have revised the data and changed what was wrong by the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myEnv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
